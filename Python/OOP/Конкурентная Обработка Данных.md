---
date of creation: 2024-07-05T16:20:00
tags:
  - Competitiveness
  - OOP/Competitiveness
  - Python/Asynchrony
  - Asynchrony
  - Developing
  - IT/Python
read status: false
aliases:
  - Python ООП и конкурентность
---
---
# Конкурентная Обработка Данных




Конкурентная обработка данных подразумевает, что компьютер одновременно выполняет сразу несколько задач. В прошлом это означало, что процессору предлагалось переключаться между различными задачами по много раз в секунду. В современных системах это также может буквально означать выполнение двух или более задач одновременно на отдельных ядрах процессора.

По сути, конкурентность не имеет прямого отношения к теме объектно-ориентированного программирования, но имеющиеся в Python системы конкурентных вычислений предоставляют объектно-ориентированные интерфейсы, речь о которых шла в книге.

Мы рассмотрим следующие темы.

- **[[#Потоки|Потоки.]]**
- **[[#Многопроцессная обработка данных|Многопроцессная обработка данных.]]**
- **[[Фьючерсы.]]**
- **[[Библиотека AsyncIO.]]**
- **[[Контрольная задача обедающих философов.]]**

В тематическом исследовании будут рассмотрены способы ускорения тестирования модели и настройки гиперпараметров. Отказаться от вычислений, чтобы сократить время их выполнения, конечно же, нельзя, но зато можно воспользоваться современным многоядерным компьютером и все-таки достигнуть ускорения.

Организация конкурирующих процессов может стать непростой задачей. Казалось бы, основные концепции весьма просты, но когда последовательность изменений состояния непредсказуема, возникающие ошибки, как известно, трудно отследить. И все же для многих проектов конкурентная обработка данных является единственным способом получения необходимой производительности. Только представьте, что веб-сервер не смог бы ответить на запрос пользователя, пока не будет завершен запрос другого пользователя!

Здесь будет рассмотрена реализация конкурентных вычислений в Python и упомянуты некоторые наиболее распространенные ошибки, которых следует избегать.

Инструкции в языке Python выполняются в строгой последовательности. Чтобы рассматривать возможность конкурентного их выполнения, нужно сделать шаг в сторону от Python.





## История конкурентной обработки данных
---

Концептуально конкурентную обработку можно представить в виде группы людей, которые пытаются совместно работать над решением какой-либо задачи, будучи не в состоянии увидеть друг друга. Возможно, у них что-то со зрением, или же они разделены перегородками, или двери в их рабочем пространстве не позволяют видеть сквозь них. И все же эти люди могут обмениваться маркерами, заметками и незавершенной работой.

Представьте себе небольшую кулинарию в старом приморском курортном городе (на Атлантическом побережье США), с неудобной планировкой стойки. Два сэндвич-повара не видят и не слышат друг друга. Владелец может позволить себе платить двум прекрасным поварам, но не может сделать стойку, вмещающую более одного подноса. Из-за неудобств старинной планировки повара также не могут видеть и поднос. Им приходится заглядывать под свой рабочий стол, чтобы убедиться, что поднос на месте. Затем, убедившись, они аккуратно выкладывают на поднос свое произведение искусства с маринованными огурцами и картофельными чипсами. (Им не виден поднос, но они великолепные повара, способные точно выложить на него сэндвич и все ингредиенты.)

А вот хозяин видит поваров. За их работой могут наблюдать даже посетители. Это отличное шоу. Хозяин обычно раздает заказы каждому шеф-повару в строгой очередности. Но получается так, что под сэндвич и его торжественную подачу к столу может быть выставлен один-единственный поднос. Как уже говорилось, шеф-повара, прежде чем кто-то сможет насладиться вкусом их следующего творения, вынуждены ждать, когда можно будет увидеть поднос на месте.

И вот однажды один и з поваров (назовем его Майкл, но друзья зовут его просто Мо) уже почти приготовил заказ, но был вынужден сбегать к холодильнику за столь любимыми всеми посетителями маринованными огурчиками. Время на приготовление блюда, заказанного Мо, затянулось, и хозяин увидел, что другой шеф-повар, Константин, похоже, опережает Мо в готовности своего блюда на доли секунды. И хотя Мо вернулся с огурчиками и готов был закончить комплектацию сэндвича, хозяин допустил одно неловкое движение. В кулинарии действует весьма простое и понятное правило: сначала нужно проверить, на месте ли поднос, а уж затем положить на него сэндвич. И это правило известно всем. Когда хозяин перенес поднос из окошка под столом Мо к окошку под столом Константина, Мо положил свое творение - великолепный сэндвич « Рубен» туда, где должен был находиться поднос, и, к досаде всех присутствующих, продукт шлепнулся на пол.

Как же все-таки мог не сработать безотказный метод проверки подноса до выкладки сэндвича? Ведь он выдержал испытание многими напряженными обеденными часами, а всего лишь мелкий сбой в обычной последовательности событий привел к беспорядку. Пауза между проверкой наличия подноса и выкладкой на него сэндвича позволила хозяину изменить порядок вещей.

По сути, хозяин и шеф-повара стали состязаться в скорости действий. Предотвращение непредвиденных ситуаций - основная задача конкурентного программирования.

Одним из решений могло бы стать использование семафора - флага, предназначенного для предотвращения неожиданных изменений в состоянии подноса. Это своеобразная совместно используемая блокировка. Каждый шеф-повар вынужден перед выкладкой на поднос завладеть флагом; и, как только он его получит, можно будет пребывать в полной уверенности, что хозяин не передвинет поднос, пока шеф-повар не вернет флаг на маленькую подставку для флагов между постами шеф-поваров.

Для конкурентной работы требуется какой-либо метод синхронизации доступа к общим ресурсам. Одной из важнейших возможностей больших современных компьютеров является управление конкурентностью с помощью функций операционной системы, в совокупности называемых ядром.

Устаревшие компьютеры были компактными, имели одно ядро в одном процессоре и должны были чередовать все операции. Благодаря продуманной координации создавалось впечатление одновременной работы над несколькими задачами. Новые многоядерные компьютеры (и большие многопроцессорные
компьютеры) фактически способны выполнять операции одновременно, но диспетчеризация при этом немного усложняется.


Существует несколько способов реализации конкурентной обработки данных.

- Операционная система допускает одновременный запуск сразу нескольких программ. Имеющийся в Python модуль *subprocess* предоставляет уже готовый доступ к этим возможностям. А модулем многопроцессной обработки, *multiprocessing*, обеспечивается целый ряд приемлемых способов работы. Все это относительно легко запускается, но при этом каждая программа оказывается полностью изолированной от всех остальных программ. Как же тогда они могут обмениваться данными?
- Некоторые высокотехнологичные программные библиотеки позволяют одной программе иметь сразу несколько конкурирующих операционных потоков. Доступ к многопоточности предоставляет имеющийся в Python модуль *threading*. Приступить к работе с ним труднее, чем к работе с обычным модулем, и следует отметить, что у каждого потока имеется полный доступ к данным во всех других потоках. Возникает вопрос: а как тогда можно будет координировать обновления общих структур данных?

Кроме этих способов, имеются и более простые в использовании оболочки для базовых библиотек. Они предоставлены модулями **`concurrent.futures`** и **`asyncio`**.

В данной главе сначала будет рассмотрено использование в Python библиотеки **`threading`**, позволяющей многим операциям выполняться в многопоточном режиме в рамках одного процесса операционной системы. В этом нет ничего сложного, за исключением ряда трудностей, возникающих при работе с общими структурами данных.





## Потоки
---

==Поток представляет собой последовательность инструкций байт-кода Python==, выполнение которой может быть прервано и возобновлено. Замысел заключается в создании отдельных конкурирующих потоков, позволяющих выполнять вычисления во время ожидания программой результатов выполнения операций ввода-вывода.

==Например, сервер может приступить к обработке нового сетевого запроса, ожидая поступления данных из предыдущего запроса.== Или же интерактивная программа может отображать анимацию или выполнять вычисления, ожидая, пока пользователь нажмет клавишу. Следует понимать разницу в скорости работы: за минуту человек может набрать более 500 символов, а компьютер за секунду может выполнить миллиарды инструкций. То есть между обработкой нажатий отдельных клавиш даже при быстром наборе текста компьютер способен выполнить огромное количество операций.

Теоретически разработчик вполне способен управлять всеми этими переключениями между разными действиями в рамках самой создаваемой программы, но сделать это должным образом практически нереально. Лучше положиться на возможности языка Python и операционной системы, которые берут на себя самую сложную часть переключений, ==оставляя на долю программистов создание объектов, которые как бы действуют одновременно, но независимо друг от друга.== Именно такие объекты и называются **потоками**. Рассмотрим простой пример, начиная, как показано в следующем классе, с основного определения потоковой обработки данных:

```python
import math
import random
from threading import Thread, Lock
import time

THE_ORDERS = [
    "Reuben",
    "Ham and Cheese",
    "Monte Cristo",
    "Tuna Melt",
    "Cuban",
    "Grilled Cheese",
    "French Dip",
    "BLT",
]


class Chef(Thread):
    def __init__(self, name: str) -> None:
        super().__init__(name=name)
        self.total = 0

    def get_order(self) -> None:
        self.order = THE_ORDERS.pop(0)

    def prepare(self) -> None:
        """Simulate doing a lot of work with a BIG computation"""
        start = time.monotonic()
        target = start + 1 + random.random()
        for i in range(1_000_000_000):
            self.total += math.factorial(i)
            if time.monotonic() >= target:
                break
        print(f"{time.monotonic():.3f} {self.name} made {self.order}")

    def run(self) -> None:
        while True:
            try:
                self.get_order()
                self.prepare()
            except IndexError:
                break  # No more orders

```

Поток в выполняемом приложении должен расширить класс **`Thread`** и реализовать метод **`run`**. Любой код, выполняемый методом **`run`**, является отдельным потоком обработки данных, проходящим независимую диспетчеризацию. Описанный в коде поток ссылается на совместно используемый объект - глобальную переменную **`THE_ORDERS`**:

```python
import math
import random
from threading import Thread, Lock
import time

THE_ORDERS = [
    "Reuben",
    "Ham and Cheese",
    "Monte Cristo",
    "Tuna Melt",
    "Cuban",
    "Grilled Cheese",
    "French Dip",
    "BLT",
]
```

В данном случае заказы определены в виде простого фиксированного списка значений. В более крупном приложении они могли бы считываться из сокета или из объекта очереди. А вот так выглядит программа верхнего уровня, запускающая все на выполнение:

```python
Mo = Chef("Michael")
Constantine = Chef("Constantine")

if __name__ == "__main__":
    random.seed(42)
    Mo.start()
    Constantine.start()
```

При выполнении этого кода будут созданы два потока. Новые потоки не начнут выполняться, пока для объекта не будет вызван метод **`start()`**. Оба потока при запуске извлекают значение из списка заказов, а затем приступают к серьезным вычислениям, сообщая в конечном итоге о своем статусе. Результат выглядит так:

```shell
605962.421 Constantine made French Dip
605963.015 Michael made BLT
605963.718 Constantine made Grilled Cheese
605964.265 Michael made Cuban
605965.468 Constantine made Tuna Melt
605965.968 Michael made Monte Cristo
605967.078 Michael made Reuben
605967.390 Constantine made Ham and Cheese
```

Заметьте, бутерброды готовятся не в порядке их представления в списке **`THE_ORDERS`**. Каждый шеф-повар работает в своем собственном (произвольном) темпе. Изменение начального элемента приведет к сдвигу по времени и может слегка изменить порядок.

Главным в данном примере является совместное использование потоками структуры данных, а одновременность их выполнения - иллюзия, созданная продуманной диспетчеризацией с целью чередования выполнения двух шеф-поварских потоков.

В этом небольшом примере все, что делается с совместно используемой структурой данных, сводится всего лишь к извлечению элементов из списка. Если бы создавался свой собственный класс и реализовались более сложные изменения состояния, то при использовании потоков мог бы проявиться целый ряд весьма интересных и запутанных проблем.




### Проблемы, возникающие при использовании потоков
---

Пользу от применения потоков можно извлечь при условии четкого управления совместно используемой памятью, но нынешние Руthоn-программисты не склонны к этому варианту по ряду веских причин. Вскоре станет ясно, что Руthоn-сообществом все большее предпочтение отдается иным способам программирования обработки данных в конкурентном стиле. Но прежде чем переходить к альтернативным способам создания многопоточных приложений, все-таки рассмотрим некоторые трудности из числа тех, что возникают на пути использования потоков.



#### Совместно используемая память
---

Основная проблема работы с потоками также является и их основным преимуществом. У потоков имеется доступ ко всей памяти процесса и, следовательно, ко всем переменным. Игнорирование общего состояния может слишком легко превратиться в несогласованность.

Вам приходилось когда-нибудь быть в комнате, где у одной и той же люстры были два выключателя, на которые одновременно нажимали два разных человека? Каждый пользователь (поток) полагал, что в результате его действия будет включен свет (изменено значение переменной), но в результате, вопреки их ожиданиям, свет не загорался. А теперь представьте ситуацию, при которой эти два потока переводили бы средства между банковскими счетами или управляли бы круиз-контролем автомобиля.

Решением описанной проблемы в многопоточном программировании является *синхронизация* доступа к любому коду, выполняющему чтение значения совместно используемой переменной или (что особенно важно) запись в нее другого значения. Руthоn-библиотекой **`threading`** предлагается класс **`Lock`**, им можно воспользоваться с помощью инструкции **`with`** для создания контекста, в котором у одного потока имеется доступ к обновлению совместно используемых объектов.

В общем плане решение по синхронизации считается вполне работоспособным, но о его применении к совместно используемым данным в конкретном приложении очень легко забыть. Хуже того, ошибки, вызванные неверным использованием синхронизации, слишком сложно отследить, поскольку порядок, в котором потоки выполняют операции, не всегда одинаков и ошибка очень трудно поддается воспроизведению.

Обычно куда безопаснее осуществлять обмен данными между потоками принудительно, используя облегченную структуру, в которой уже соответствующим образом используются блокировки. Для этого в Python предлагается класс очереди - **`Queue`**. При этом запись в очередь выполняется несколькими потоками, а пользоваться результатами может только один поток. В результате получается аккуратный, многократно используемый, проверенный метод совместной работы со структурой данных несколькими потоками. Практически идентичен с описанным класс **`multiprocessing.Queue`**, который будет рассмотрен ниже, в разделе «Многопроцессная обработка данных».

Бывает так, что все эти недостатки перевешиваются одним-единственным преимуществом совместного использования памяти: быстротой. Если доступ к огромной структуре данных требуется сразу нескольким потокам, то совместно используемая память в состоянии довольно быстро обеспечить такой доступ. Но это преимущество обычно сводится на нет следующим фактом: ==в Python невозможно сделать так, чтобы два потока, работающие на разных ядрах процессора, выполняли вычисления в точности в одно и то же время.== Это подводит нас ко второй проблеме, связанной с использованием потоков.



#### Глобальная блокировка интерпретатора
---

Для эффективного управления памятью, сборкой мусора и вызовами машинного кода в собственных библиотеках в Python используется глобальная блокировка интерпретатора, или **[[GIL (Global Interpreter Lock)|GIL]]**(**global interpreter lock**). Ее невозможно отключить, и получается, что диспетчеризация потоков ограничена **GIL**: она не позволяет любым двум потокам выполнять вычисления в одно и то же время; их работа искусственно чередуется. Когда поток делает запрос к операционной системе, например для доступа к диску или сети, GIL-блокировка снимается, как только этот поток войдет в режим ожидания завершения этого запроса.

==Пренебрежительным отношением к GIL грешат в основном те, кто не понимает, что это такое и какие преимущества эта блокировка приносит Python.== Конечно, она может мешать многопоточному программированию, требующему больших вычислительных ресурсов, но на другие виды рабочих нагрузок чаще всего оказывает самое минимальное влияние. А при встрече с алгоритмом, требующим больших вычислительных затрат, помочь с управлением обработкой данных может пакет **`dask`**. Дополнительные сведения об этой альтернативе можно получить по адресу https://dask.org. Информационной подпиткой может также стать книга [Scalable Data Analysis in Python with Dask](https://www.oreilly.com/library/view/scaling-python-with/9781098119867/) М. Кашифа.

>[!tip]
>Проблемы, связанные с GIL- блокировкой в используемой большинством специалистов стандартной версии Pythoп, можно обойти с помощью ее выборочного отключения в **IronPython**. Подробности ослабления GIL-блокировки с целью выполнения интенсивной обработки данных в **`IronPython`** можно найти в книге [The Iron Python Cookbook](https://www.amazon.com/IronPython-Action-Michael-J-Foord/dp/1933988339).


##### Издержки использования потоков
---

Еще одним недостатком потоков, по сравнению с рассматриваемыми далее асинхронными подходами, являются издержки на обслуживание потока. Дело в том, что каждый поток занимает для записи своего состояния определенный объем памяти (как в процессе Python, так и в ядре операционной системы). На переключение между потоками также тратится (сравнительно небольшое) количество процессорного времени. Переключение происходит беспрепятственно, без какого-либо дополнительного программирования (нужно просто вызвать **`start()`**, и все будет сделано без вашего участия), но работа все равно должна быть где-то выполнена.

Эти издержки могут быть снижены при увеличении рабочей нагрузки за счет повторного использования потоков для выполнения не одного, а нескольких заданий. Для решения такой задачи в Python служит функция **`ThreadPool`**, которая ведет себя идентично пулу процессов. Он вскоре будет рассмотрен, поэтому отложим обсуждение до ознакомления с материалами других разделов данной главы.

А в следующем разделе займемся изучением основной альтернативы многопоточности. Возможность работы с подпроцессами операционной системы открывается благодаря потенциалу модуля **`multiprocessing`**.




## Многопроцессная обработка данных
---

Потоки работают в рамках одного процесса операционной системы, чем и обусловливается возможность их совместного доступа к общим объектам. На уровне процесса могут также выполняться конкурентные вычисления. В отличие от потоков каждый отдельно взятый процесс не может напрямую обращаться к переменным, созданным другими процессами. Польза от такой независимости выражается в том, что у любого процесса имеется своя собственная GIL-блокировка и свой собственный закрытый пул ресурсов. На современном многоядерном процессоре процесс может иметь собственное ядро, позволяющее одновременно работать с другими ядрами.

Изначально API многопроцессной обработки, **`multiprocessing`**, был разработан для имитации потокового API. Но он эволюционировал и в последних версиях Python стал еще надежнее поддерживать более широкий арсенал функций. Библиотека **`multiprocessing`** предназначена для тех случаев, когда задания с интенсивным использованием процессора должны выполняться параллельно при условии доступности нескольких ядер. Польза от многопроцессной обработки снижается, когда процессы тратят большую часть своего времени на ожидание ввода-вывода (например, при работе в сети, с диском, с базой данных или с клавиатурой), но очень хорошо проявляется при параллельных вычислениях.

При работе модуля **`multiprocessing`** запускаются новые процессы операционной системы. Получается, что для каждого процесса запускается полностью автономная копия интерпретатора Python. Например, попробуем распараллелить сложную вычислительную операцию, используя конструкции, аналогичные предоставляемым АРI-интерфейсом **`threading`**:

```python
from multiprocessing import Process, cpu_count
import time
import os


class MuchCPU(Process):
    def run(self) -> None:
        print(f"OS PID {os.getpid()}")

        s = sum(2 * i + 1 for i in range(100_000_000))


if __name__ == "__main__":
    workers = [MuchCPU() for f in range(cpu_count())]

    t = time.perf_counter()
    for p in workers:
        p.start()
    for p in workers:
        p.join()
    print(f"work took {time.perf_counter() - t:.3f} seconds")
```

Код этого примера просто заставляет центральный процессор вычислять сумму из 100 миллионов нечетных чисел. Похоже, полезной эту работу назвать довольно сложно, но она может согреть ваш ноутбук в холодную погоду!

АРI-интерфейс вам должен быть знаком: здесь реализуется подкласс **`Process`** (вместо **`Thread`**) и метод **`run`**. Данный метод перед выполнением интенсивной (хотя и бестолковой) работы выводит на экран *идентификатор процесса операционной системы* (**`PID`**), являющийся уникальным номером, присваиваемым каждому процессу на компьютере.

Особое внимание следует обратить на фрагмент [[Код для самотестирования на Python|if _name_ == "_main_"]]: это защита кода на уровне модуля, предотвращающая запуск модуля в случае его импорта, а не запуска в качестве программы. Этот прием рекомендуется применять повсеместно, но при использовании модуля multiprocessing без него просто не обойтись. Следуя внутренней логике, модулю multiproces sing, возможно, придется повторно импортировать ваш прикладной модуль в каждый из новых процессов, чтобы создать класс и выполнить метод run ( ) . Если в этот самый момент позволить выполняться всему модулю, он начнет рекурсивно