---
date of creation: 2024-07-05T16:20:00
tags:
  - Competitiveness
  - OOP/Competitiveness
  - Python/Asynchrony
  - Asynchrony
  - Developing
  - IT/Python
read status: false
aliases:
  - Python ООП и конкурентность
---
---
# Конкурентная Обработка Данных




Конкурентная обработка данных подразумевает, что компьютер одновременно выполняет сразу несколько задач. В прошлом это означало, что процессору предлагалось переключаться между различными задачами по много раз в секунду. В современных системах это также может буквально означать выполнение двух или более задач одновременно на отдельных ядрах процессора.

По сути, конкурентность не имеет прямого отношения к теме объектно-ориентированного программирования, но имеющиеся в Python системы конкурентных вычислений предоставляют объектно-ориентированные интерфейсы, речь о которых шла в книге.

Мы рассмотрим следующие темы.

- **[[#Потоки|Потоки.]]**
- **[[#Многопроцессная обработка данных|Многопроцессная обработка данных.]]**
- **[[#Фьючерсы|Фьючерсы.]]**
- **[[#Библиотека **`AsyncIO`**|Библиотека AsyncIO.]]**
- **[[Контрольная задача обедающих философов.]]**

В тематическом исследовании будут рассмотрены способы ускорения тестирования модели и настройки гиперпараметров. Отказаться от вычислений, чтобы сократить время их выполнения, конечно же, нельзя, но зато можно воспользоваться современным многоядерным компьютером и все-таки достигнуть ускорения.

Организация конкурирующих процессов может стать непростой задачей. Казалось бы, основные концепции весьма просты, но когда последовательность изменений состояния непредсказуема, возникающие ошибки, как известно, трудно отследить. И все же для многих проектов конкурентная обработка данных является единственным способом получения необходимой производительности. Только представьте, что веб-сервер не смог бы ответить на запрос пользователя, пока не будет завершен запрос другого пользователя!

Здесь будет рассмотрена реализация конкурентных вычислений в Python и упомянуты некоторые наиболее распространенные ошибки, которых следует избегать.

Инструкции в языке Python выполняются в строгой последовательности. Чтобы рассматривать возможность конкурентного их выполнения, нужно сделать шаг в сторону от Python.





## История конкурентной обработки данных
---

Концептуально конкурентную обработку можно представить в виде группы людей, которые пытаются совместно работать над решением какой-либо задачи, будучи не в состоянии увидеть друг друга. Возможно, у них что-то со зрением, или же они разделены перегородками, или двери в их рабочем пространстве не позволяют видеть сквозь них. И все же эти люди могут обмениваться маркерами, заметками и незавершенной работой.

Представьте себе небольшую кулинарию в старом приморском курортном городе (на Атлантическом побережье США), с неудобной планировкой стойки. Два сэндвич-повара не видят и не слышат друг друга. Владелец может позволить себе платить двум прекрасным поварам, но не может сделать стойку, вмещающую более одного подноса. Из-за неудобств старинной планировки повара также не могут видеть и поднос. Им приходится заглядывать под свой рабочий стол, чтобы убедиться, что поднос на месте. Затем, убедившись, они аккуратно выкладывают на поднос свое произведение искусства с маринованными огурцами и картофельными чипсами. (Им не виден поднос, но они великолепные повара, способные точно выложить на него сэндвич и все ингредиенты.)

А вот хозяин видит поваров. За их работой могут наблюдать даже посетители. Это отличное шоу. Хозяин обычно раздает заказы каждому шеф-повару в строгой очередности. Но получается так, что под сэндвич и его торжественную подачу к столу может быть выставлен один-единственный поднос. Как уже говорилось, шеф-повара, прежде чем кто-то сможет насладиться вкусом их следующего творения, вынуждены ждать, когда можно будет увидеть поднос на месте.

И вот однажды один и з поваров (назовем его Майкл, но друзья зовут его просто Мо) уже почти приготовил заказ, но был вынужден сбегать к холодильнику за столь любимыми всеми посетителями маринованными огурчиками. Время на приготовление блюда, заказанного Мо, затянулось, и хозяин увидел, что другой шеф-повар, Константин, похоже, опережает Мо в готовности своего блюда на доли секунды. И хотя Мо вернулся с огурчиками и готов был закончить комплектацию сэндвича, хозяин допустил одно неловкое движение. В кулинарии действует весьма простое и понятное правило: сначала нужно проверить, на месте ли поднос, а уж затем положить на него сэндвич. И это правило известно всем. Когда хозяин перенес поднос из окошка под столом Мо к окошку под столом Константина, Мо положил свое творение - великолепный сэндвич « Рубен» туда, где должен был находиться поднос, и, к досаде всех присутствующих, продукт шлепнулся на пол.

Как же все-таки мог не сработать безотказный метод проверки подноса до выкладки сэндвича? Ведь он выдержал испытание многими напряженными обеденными часами, а всего лишь мелкий сбой в обычной последовательности событий привел к беспорядку. Пауза между проверкой наличия подноса и выкладкой на него сэндвича позволила хозяину изменить порядок вещей.

По сути, хозяин и шеф-повара стали состязаться в скорости действий. Предотвращение непредвиденных ситуаций - основная задача конкурентного программирования.

Одним из решений могло бы стать использование семафора - флага, предназначенного для предотвращения неожиданных изменений в состоянии подноса. Это своеобразная совместно используемая блокировка. Каждый шеф-повар вынужден перед выкладкой на поднос завладеть флагом; и, как только он его получит, можно будет пребывать в полной уверенности, что хозяин не передвинет поднос, пока шеф-повар не вернет флаг на маленькую подставку для флагов между постами шеф-поваров.

Для конкурентной работы требуется какой-либо метод синхронизации доступа к общим ресурсам. Одной из важнейших возможностей больших современных компьютеров является управление конкурентностью с помощью функций операционной системы, в совокупности называемых ядром.

Устаревшие компьютеры были компактными, имели одно ядро в одном процессоре и должны были чередовать все операции. Благодаря продуманной координации создавалось впечатление одновременной работы над несколькими задачами. Новые многоядерные компьютеры (и большие многопроцессорные
компьютеры) фактически способны выполнять операции одновременно, но диспетчеризация при этом немного усложняется.


Существует несколько способов реализации конкурентной обработки данных.

- Операционная система допускает одновременный запуск сразу нескольких программ. Имеющийся в Python модуль *subprocess* предоставляет уже готовый доступ к этим возможностям. А модулем многопроцессной обработки, *multiprocessing*, обеспечивается целый ряд приемлемых способов работы. Все это относительно легко запускается, но при этом каждая программа оказывается полностью изолированной от всех остальных программ. Как же тогда они могут обмениваться данными?
- Некоторые высокотехнологичные программные библиотеки позволяют одной программе иметь сразу несколько конкурирующих операционных потоков. Доступ к многопоточности предоставляет имеющийся в Python модуль *threading*. Приступить к работе с ним труднее, чем к работе с обычным модулем, и следует отметить, что у каждого потока имеется полный доступ к данным во всех других потоках. Возникает вопрос: а как тогда можно будет координировать обновления общих структур данных?

Кроме этих способов, имеются и более простые в использовании оболочки для базовых библиотек. Они предоставлены модулями **`concurrent.futures`** и **`asyncio`**.

В данной главе сначала будет рассмотрено использование в Python библиотеки **`threading`**, позволяющей многим операциям выполняться в многопоточном режиме в рамках одного процесса операционной системы. В этом нет ничего сложного, за исключением ряда трудностей, возникающих при работе с общими структурами данных.





## Потоки
---

==Поток представляет собой последовательность инструкций байт-кода Python==, выполнение которой может быть прервано и возобновлено. Замысел заключается в создании отдельных конкурирующих потоков, позволяющих выполнять вычисления во время ожидания программой результатов выполнения операций ввода-вывода.

==Например, сервер может приступить к обработке нового сетевого запроса, ожидая поступления данных из предыдущего запроса.== Или же интерактивная программа может отображать анимацию или выполнять вычисления, ожидая, пока пользователь нажмет клавишу. Следует понимать разницу в скорости работы: за минуту человек может набрать более 500 символов, а компьютер за секунду может выполнить миллиарды инструкций. То есть между обработкой нажатий отдельных клавиш даже при быстром наборе текста компьютер способен выполнить огромное количество операций.

Теоретически разработчик вполне способен управлять всеми этими переключениями между разными действиями в рамках самой создаваемой программы, но сделать это должным образом практически нереально. Лучше положиться на возможности языка Python и операционной системы, которые берут на себя самую сложную часть переключений, ==оставляя на долю программистов создание объектов, которые как бы действуют одновременно, но независимо друг от друга.== Именно такие объекты и называются **потоками**. Рассмотрим простой пример, начиная, как показано в следующем классе, с основного определения потоковой обработки данных:

```python
import math
import random
from threading import Thread, Lock
import time

THE_ORDERS = [
    "Reuben",
    "Ham and Cheese",
    "Monte Cristo",
    "Tuna Melt",
    "Cuban",
    "Grilled Cheese",
    "French Dip",
    "BLT",
]


class Chef(Thread):
    def __init__(self, name: str) -> None:
        super().__init__(name=name)
        self.total = 0

    def get_order(self) -> None:
        self.order = THE_ORDERS.pop(0)

    def prepare(self) -> None:
        """Simulate doing a lot of work with a BIG computation"""
        start = time.monotonic()
        target = start + 1 + random.random()
        for i in range(1_000_000_000):
            self.total += math.factorial(i)
            if time.monotonic() >= target:
                break
        print(f"{time.monotonic():.3f} {self.name} made {self.order}")

    def run(self) -> None:
        while True:
            try:
                self.get_order()
                self.prepare()
            except IndexError:
                break  # No more orders

```

Поток в выполняемом приложении должен расширить класс **`Thread`** и реализовать метод **`run`**. Любой код, выполняемый методом **`run`**, является отдельным потоком обработки данных, проходящим независимую диспетчеризацию. Описанный в коде поток ссылается на совместно используемый объект - глобальную переменную **`THE_ORDERS`**:

```python
import math
import random
from threading import Thread, Lock
import time

THE_ORDERS = [
    "Reuben",
    "Ham and Cheese",
    "Monte Cristo",
    "Tuna Melt",
    "Cuban",
    "Grilled Cheese",
    "French Dip",
    "BLT",
]
```

В данном случае заказы определены в виде простого фиксированного списка значений. В более крупном приложении они могли бы считываться из сокета или из объекта очереди. А вот так выглядит программа верхнего уровня, запускающая все на выполнение:

```python
Mo = Chef("Michael")
Constantine = Chef("Constantine")

if __name__ == "__main__":
    random.seed(42)
    Mo.start()
    Constantine.start()
```

При выполнении этого кода будут созданы два потока. Новые потоки не начнут выполняться, пока для объекта не будет вызван метод **`start()`**. Оба потока при запуске извлекают значение из списка заказов, а затем приступают к серьезным вычислениям, сообщая в конечном итоге о своем статусе. Результат выглядит так:

```shell
605962.421 Constantine made French Dip
605963.015 Michael made BLT
605963.718 Constantine made Grilled Cheese
605964.265 Michael made Cuban
605965.468 Constantine made Tuna Melt
605965.968 Michael made Monte Cristo
605967.078 Michael made Reuben
605967.390 Constantine made Ham and Cheese
```

Заметьте, бутерброды готовятся не в порядке их представления в списке **`THE_ORDERS`**. Каждый шеф-повар работает в своем собственном (произвольном) темпе. Изменение начального элемента приведет к сдвигу по времени и может слегка изменить порядок.

Главным в данном примере является совместное использование потоками структуры данных, а одновременность их выполнения - иллюзия, созданная продуманной диспетчеризацией с целью чередования выполнения двух шеф-поварских потоков.

В этом небольшом примере все, что делается с совместно используемой структурой данных, сводится всего лишь к извлечению элементов из списка. Если бы создавался свой собственный класс и реализовались более сложные изменения состояния, то при использовании потоков мог бы проявиться целый ряд весьма интересных и запутанных проблем.




### Проблемы, возникающие при использовании потоков
---

Пользу от применения потоков можно извлечь при условии четкого управления совместно используемой памятью, но нынешние Руthоn-программисты не склонны к этому варианту по ряду веских причин. Вскоре станет ясно, что Руthоn-сообществом все большее предпочтение отдается иным способам программирования обработки данных в конкурентном стиле. Но прежде чем переходить к альтернативным способам создания многопоточных приложений, все-таки рассмотрим некоторые трудности из числа тех, что возникают на пути использования потоков.



#### Совместно используемая память
---

Основная проблема работы с потоками также является и их основным преимуществом. У потоков имеется доступ ко всей памяти процесса и, следовательно, ко всем переменным. Игнорирование общего состояния может слишком легко превратиться в несогласованность.

Вам приходилось когда-нибудь быть в комнате, где у одной и той же люстры были два выключателя, на которые одновременно нажимали два разных человека? Каждый пользователь (поток) полагал, что в результате его действия будет включен свет (изменено значение переменной), но в результате, вопреки их ожиданиям, свет не загорался. А теперь представьте ситуацию, при которой эти два потока переводили бы средства между банковскими счетами или управляли бы круиз-контролем автомобиля.

Решением описанной проблемы в многопоточном программировании является *синхронизация* доступа к любому коду, выполняющему чтение значения совместно используемой переменной или (что особенно важно) запись в нее другого значения. Руthоn-библиотекой **`threading`** предлагается класс **`Lock`**, им можно воспользоваться с помощью инструкции **`with`** для создания контекста, в котором у одного потока имеется доступ к обновлению совместно используемых объектов.

В общем плане решение по синхронизации считается вполне работоспособным, но о его применении к совместно используемым данным в конкретном приложении очень легко забыть. Хуже того, ошибки, вызванные неверным использованием синхронизации, слишком сложно отследить, поскольку порядок, в котором потоки выполняют операции, не всегда одинаков и ошибка очень трудно поддается воспроизведению.

Обычно куда безопаснее осуществлять обмен данными между потоками принудительно, используя облегченную структуру, в которой уже соответствующим образом используются блокировки. Для этого в Python предлагается класс очереди - **`Queue`**. При этом запись в очередь выполняется несколькими потоками, а пользоваться результатами может только один поток. В результате получается аккуратный, многократно используемый, проверенный метод совместной работы со структурой данных несколькими потоками. Практически идентичен с описанным класс **`multiprocessing.Queue`**, который будет рассмотрен ниже, в разделе «Многопроцессная обработка данных».

Бывает так, что все эти недостатки перевешиваются одним-единственным преимуществом совместного использования памяти: быстротой. Если доступ к огромной структуре данных требуется сразу нескольким потокам, то совместно используемая память в состоянии довольно быстро обеспечить такой доступ. Но это преимущество обычно сводится на нет следующим фактом: ==в Python невозможно сделать так, чтобы два потока, работающие на разных ядрах процессора, выполняли вычисления в точности в одно и то же время.== Это подводит нас ко второй проблеме, связанной с использованием потоков.



#### Глобальная блокировка интерпретатора
---

Для эффективного управления памятью, сборкой мусора и вызовами машинного кода в собственных библиотеках в Python используется глобальная блокировка интерпретатора, или **[[GIL (Global Interpreter Lock)|GIL]]**(**global interpreter lock**). Ее невозможно отключить, и получается, что диспетчеризация потоков ограничена **GIL**: она не позволяет любым двум потокам выполнять вычисления в одно и то же время; их работа искусственно чередуется. Когда поток делает запрос к операционной системе, например для доступа к диску или сети, GIL-блокировка снимается, как только этот поток войдет в режим ожидания завершения этого запроса.

==Пренебрежительным отношением к GIL грешат в основном те, кто не понимает, что это такое и какие преимущества эта блокировка приносит Python.== Конечно, она может мешать многопоточному программированию, требующему больших вычислительных ресурсов, но на другие виды рабочих нагрузок чаще всего оказывает самое минимальное влияние. А при встрече с алгоритмом, требующим больших вычислительных затрат, помочь с управлением обработкой данных может пакет **`dask`**. Дополнительные сведения об этой альтернативе можно получить по адресу https://dask.org. Информационной подпиткой может также стать книга [Scalable Data Analysis in Python with Dask](https://www.oreilly.com/library/view/scaling-python-with/9781098119867/) М. Кашифа.

>[!tip]
>Проблемы, связанные с GIL- блокировкой в используемой большинством специалистов стандартной версии Pythoп, можно обойти с помощью ее выборочного отключения в **IronPython**. Подробности ослабления GIL-блокировки с целью выполнения интенсивной обработки данных в **`IronPython`** можно найти в книге [The Iron Python Cookbook](https://www.amazon.com/IronPython-Action-Michael-J-Foord/dp/1933988339).


##### Издержки использования потоков
---

Еще одним недостатком потоков, по сравнению с рассматриваемыми далее асинхронными подходами, являются издержки на обслуживание потока. Дело в том, что каждый поток занимает для записи своего состояния определенный объем памяти (как в процессе Python, так и в ядре операционной системы). На переключение между потоками также тратится (сравнительно небольшое) количество процессорного времени. Переключение происходит беспрепятственно, без какого-либо дополнительного программирования (нужно просто вызвать **`start()`**, и все будет сделано без вашего участия), но работа все равно должна быть где-то выполнена.

Эти издержки могут быть снижены при увеличении рабочей нагрузки за счет повторного использования потоков для выполнения не одного, а нескольких заданий. Для решения такой задачи в Python служит функция **`ThreadPool`**, которая ведет себя идентично пулу процессов. Он вскоре будет рассмотрен, поэтому отложим обсуждение до ознакомления с материалами других разделов данной главы.

А в следующем разделе займемся изучением основной альтернативы многопоточности. Возможность работы с подпроцессами операционной системы открывается благодаря потенциалу модуля **`multiprocessing`**.




## Многопроцессная обработка данных
---

Потоки работают в рамках одного процесса операционной системы, чем и обусловливается возможность их совместного доступа к общим объектам. На уровне процесса могут также выполняться конкурентные вычисления. В отличие от потоков каждый отдельно взятый процесс не может напрямую обращаться к переменным, созданным другими процессами. Польза от такой независимости выражается в том, что у любого процесса имеется своя собственная GIL-блокировка и свой собственный закрытый пул ресурсов. На современном многоядерном процессоре процесс может иметь собственное ядро, позволяющее одновременно работать с другими ядрами.

Изначально API многопроцессной обработки, **`multiprocessing`**, был разработан для имитации потокового API. Но он эволюционировал и в последних версиях Python стал еще надежнее поддерживать более широкий арсенал функций. Библиотека **`multiprocessing`** предназначена для тех случаев, когда задания с интенсивным использованием процессора должны выполняться параллельно при условии доступности нескольких ядер. Польза от многопроцессной обработки снижается, когда процессы тратят большую часть своего времени на ожидание ввода-вывода (например, при работе в сети, с диском, с базой данных или с клавиатурой), но очень хорошо проявляется при параллельных вычислениях.

При работе модуля **`multiprocessing`** запускаются новые процессы операционной системы. Получается, что для каждого процесса запускается полностью автономная копия интерпретатора Python. Например, попробуем распараллелить сложную вычислительную операцию, используя конструкции, аналогичные предоставляемым АРI-интерфейсом **`threading`**:

```python
from multiprocessing import Process, cpu_count
import time
import os


class MuchCPU(Process):
    def run(self) -> None:
        print(f"OS PID {os.getpid()}")

        s = sum(2 * i + 1 for i in range(100_000_000))


if __name__ == "__main__":
    workers = [MuchCPU() for f in range(cpu_count())]

    t = time.perf_counter()
    for p in workers:
        p.start()
    for p in workers:
        p.join()
    print(f"work took {time.perf_counter() - t:.3f} seconds")
```

Код этого примера просто заставляет центральный процессор вычислять сумму из 100 миллионов нечетных чисел. Похоже, полезной эту работу назвать довольно сложно, но она может согреть ваш ноутбук в холодную погоду!

АРI-интерфейс вам должен быть знаком: здесь реализуется подкласс **`Process`** (вместо **`Thread`**) и метод **`run`**. Данный метод перед выполнением интенсивной (хотя и бестолковой) работы выводит на экран ==*идентификатор процесса операционной системы*== (**`PID`**), являющийся уникальным номером, присваиваемым каждому процессу на компьютере.

Особое внимание следует обратить на фрагмент [[Код для самотестирования на Python|if _name_ == "_main_"]]: ==это защита кода на уровне модуля, предотвращающая запуск модуля в случае его импорта, а не запуска в качестве программы.== Этот прием рекомендуется применять повсеместно, но при использовании модуля **`multiprocessing`** без него просто не обойтись. Следуя внутренней логике, модулю **`multiprocessing`**, возможно, придется повторно импортировать ваш прикладной модуль в каждый из новых процессов, чтобы создать класс и выполнить метод **`run()`**. Если в этот самый момент позволить выполняться всему модулю, он начнет рекурсивно создавать все новые и новые процессы до истощения ресурсов системы, что приведет к сбою компьютера.

Демонстратор в примере создает по одному процессу для каждого имеющегося в компьютере процессорного ядра, а затем сам запускается на выполнение и присоединяется к каждому из этих процессов. На MacBook Pro 2020 года выпуска с четырехъядерным процессором Intel Core i5 с тактовой частотой 2 ГГц выходные данные выглядят следующим образом:

```shell
% python src/processes_1.py
OS PID 15492
OS PID 15493
OS PID 15494
OS PID 15495
OS PID 15497
OS PID 15496
OS PID 15498
OS PID 15499
work took 20.711 seconds
```

В первых восьми строках вы видите выведенные на экран экземпляром **`MuchCPU`** идентификаторы процессов. В последней строке показано, что 100 миллионов сложений могут выполняться примерно за 20 секунд. В течение этих 20 секунд все восемь ядер работали на 100 %, а вентиляторы жужжали вовсю, пытаясь рассеять тепло.

Если в **`MuchCPU`** вместо подкласса **`multiprocessing.Process`** создать подкласс **`threading.Thread`**, вывод на экран будет таким:

```shell
% python src/processes_1.py
OS PID 15772
OS PID 15772
OS PID 15772
OS PID 15772
OS PID 15772
OS PID 15772
OS PID 15772
OS PID 15772
work took 69.316 seconds
```

Здесь потоки выполняются внутри одного и того же процесса операционной системы, что занимает в три раза больше времени. На дисплее видно, что ни одно из ядер особо загружено не было, а это наводит на мысль о несбалансированном распределении работы между различными ядрами. В целом замедление было связано с издержками на GIL-блокировки при чередовании ресурсоемкой вычислительной работы. Можно было бы, конечно, ожидать, что версия с одним процессом будет работать по меньшей мере в восемь раз дольше версии с восемью процессами.

Но простая арифметика здесь не действует в силу ряда факторов: порядка обработки в Python низкоуровневых инструкций, работы диспетчера процессов операционной системы и даже работы самого оборудования. То есть что-либо прогнозировать в этом плане довольно сложно и лучше будет запланировать проведение нескольких тестов производительности с использованием нескольких программных архитектур.

Запуск и остановка отдельно взятых экземпляров **`Process`** сопряжены с солидными издержками. ==Наиболее приемлемой сложившейся практикой является организация пула рабочих процессов и назначение им задач.== Именно этот прием и будет рассмотрен далее.




### Многопроцессные пулы
---

Поскольку операционная система строго разграничивает каждый процесс, межпроцессное взаимодействие требует особого внимания из-за потребности передачи данных между отдельно взятыми процессами. Одним из весьма распространенных приемов решения этой задачи является запись файла одним и возможность его считывания другим процессом. Когда такие два процесса осуществляют чтение и запись файла в одно и то же время, следует обеспечить ожидание считывающего процесса до выдачи данных записывающим процессом. Этого можно добиться за счет выстраивания средствами операционной системы *конвейерной структуры*. Находясь в оболочке операционной системы, можно ввести следующую команду: **`ps -ef | grep python`** - и передать выходные данные из команды **`ps`** в команду **`grep`**. Эти две команды выполняются одновременно. Для пользователей Windows PowerShell существуют аналогичные виды конвейерной обработки, использующие разные имена команд. (Примеры ищите по адресу https://learn.microsoft.com/en-us/powershell/scripting/learn/ps101/06-flow-control?view=powershell-7.4.)

Пакетом многопроцессной обработки **`multiprocessing`** предоставляются дополнительные способы реализации межпроцессного взаимодействия. Способ обмена данными между процессами может быть легко завуалирован пулами. Использование пула схоже с вызовом функции: данные передаются в функцию, выполняющуюся в другом процессе или процессах, а когда работа выполнена, полученное значение возвращается. Здесь важно осознавать объем выполняемой для этого работы: объекты одного процесса переводятся в рiсklе-формат и передаются в конвейер обработки операционной системы. Затем другой процесс извлекает данные из конвейера и восстанавливает их из рiсklе-формата. Запрошенная работа выполняется в подпроцессе, после чего выдается результат. Полученный результат переводится в рiсklе-формат и передается обратно в конвейер. И наконец, исходный процесс его возвращает, предварительно переведя в исходный вид из рiсklе-формата. В совокупности это называется переводом в сериализованный рiсklе-формат, передачей и десериализацией - восстановлением из рiсklе-формата. Дополнительные сведения можно найти в [[Строки, сериализация и пути к файлам]].

На сериализованный обмен данными между процессами затрачиваются время и память. Хотелось бы провести как можно больше полезных вычислений при наименьших затратах на сериализацию. Здесь требуется идеальное соотношение размера и сложности объектов, подлежащих обмену, поэтому получается, что разным конструкциям структур данных будут соответствовать разные уровни производительности.

>[!tip]
>Спрогнозировать производительность весьма непросто. Чтобы обеспечить эффективность конкурентной работы с данными, нужно от-профилировать приложение.

Если разобраться во всех тонкостях, то создать программный код, заставляющий работать все упомянутые механизмы обработки данных, не составит особого труда. Рассмотрим задачу вычисления всех простых множителей списка случайных чисел. Это обычная составляющая различных криптографических алгоритмов (не говоря уже о вскрытии подобных алгоритмов!).

Чтобы разложить на множители 232-значные числа, используемые некоторыми алгоритмами шифрования, требуются месяцы, а возможно, и годы вычислений. Следующую реализацию, несмотря на легкость ее прочтения, нельзя признать эффективной: на разложение с ее помощью даже 100-значного числа ушли бы годы. ==Но здесь она уместна, поскольку наша цель сейчас состоит в наблюдении за использованием большого объема процессорного времени для разложения на множители девятизначных чисел:==

```python
from __future__ import annotations
from math import sqrt, ceil
import random
from multiprocessing.pool import Pool


def prime_factors(value: int) -> list[int]:
    """
    >>> set(prime_factors(42))
    {2, 3, 7}
    >>> set(prime_factors(97))
    {97}
    """
    if value in {2, 3}:
        return [value]
    factors: list[int] = []
    for divisor in range(2, ceil(sqrt(value)) + 1):
        quotient, remainder = divmod(value, divisor)
        if not remainder:
            factors.extend(prime_factors(divisor))
            factors.extend(prime_factors(quotient))
            break
    else:
        factors = [value]
    return factors


if __name__ == "__main__":
    to_factor = [random.randint(100_000_000, 1_000_000_000) for i in range(40_960)]
    with Pool() as pool:
        results = pool.map(prime_factors, to_factor)
    primes = [
        value for value, factor_list in zip(to_factor, results) if len(factor_list) == 1
    ]
    print(f"9-digit primes {primes}")
```

Остановимся на простом для понимания рекурсивном алгоритме вычисления в лоб множителей, сконцентрировав все внимание на аспектах параллельной обработки данных. Здесь создается список **`to_factor`**, состоящий из 40 960 отдельных чисел. Затем создается экземпляр **`pool`** многопроцессного пула.

==По умолчанию в этом пуле создается отдельный процесс для каждого из ядер процессора того компьютера, на котором он запущен.==

Принадлежащий пулу метод **`map()`** принимает функцию и итерируемый объект. ==Пул переводит в рiсklе-формат каждое из значений в итерируемом объекте и передает его рабочему процессу, доступному в пуле, и он уже применяет к полученному значению функцию.== Когда данный процесс завершает свою работу, он переводит в рiсklе-формат получившийся список множителей и передает его обратно в пул. Затем рабочий процесс берется за следующую работу, если таковая в пуле имеется.

Как только все имеющиеся в пуле рабочие процессы завершат обработку данных (на что может уйти некоторое время), список результатов **`results`** передается обратно исходному процессу, до сих пор терпеливо ожидавшему завершения всей работы. Результаты выполнения функции **`map()`** будут выстроены в порядке следования запросов. Это придает смысл применению функции **`zip()`** для сопоставления исходного значения с вычисленными простыми множителями.

Зачастую рациональнее воспользоваться аналогичным методом **`map_async()`**, возвращающим результат без промедления, даже если процессы все еще работают. Но здесь уже переменная **`results`** будет не списком значений, а контрактом (или сделкой, или обязательством) возвращать список значений в будущем при вызове клиентом метода **`results.get()`**. У этого будущего объекта также имеются методы **`ready()`** и **`wait()`**, позволяющие проверить, все ли результаты получены. Такой вариант хорошо подходит для обработки данных, время завершения которой сильно варьируется.

Или же, если все значения, для которых нужно получить результаты, пока что неизвестны, можно воспользоваться методом **`apply_async()`** и поставить задание в очередь. Если в пуле есть еще не задействованный процесс, он будет немедленно запущен; в противном случае пул будет сохранять задание до тех пор, пока не появится свободный рабочий процесс.

Пулы также могут быть закрыты (**closed**), при этом они будут отказываться выполнять какие-либо последующие задачи, но продолжат обрабатывать все, что на данный момент находится в очереди. Они также могут быть завершены (**terminated**), что еще больше усложняет ситуацию, поскольку в запуске любых заданий, все еще находящихся в очереди, будет отказано, хотя всем выполняемым на данный момент заданиям по-прежнему будет разрешено завершиться.

Имеет смысл задействовать определенное количество рабочих процессов, и это количество оказывается ограничено рядом соображений.

- Вычисления могут одновременно проводиться только процессами **`cpu_count()`**, при этом в режиме ожидания может находиться любое количество других процессов. Если рабочая нагрузка сопряжена с высокой интенсивностью использования центрального процессора, то повлиять на скорость вычислений величина пула рабочих процессов не сможет. Но если в рабочей нагрузке велика доля операций ввода-вывода, большой пул ускоряет выполнение работы.
- Для слишком крупных структур данных на скорость их обработки положительно влияет сокращение имеющегося в пуле количества рабочих процессов, поскольку тем самым обеспечивается более эффективное использование оперативной памяти.
- Обмен данными между процессами - слишком затратная операция, поэтому при ее осуществлении целесообразнее будет воспользоваться данными, прошедшими легкую сериализацию.
- На создание новых процессов также тратится некоторое время, поэтому пул фиксированного размера помогает свести к минимуму негативное влияние подобных затрат.

Многопроцессный пул способен существенно повысить эффективность вычислений при относительно небольших усилиях с нашей стороны. На нас возлагается ответственность за определение такой функции, которая сможет вести вычисления в параллельном режиме, и за отображение аргументов этой функции с помощью экземпляра класса **`multiprocessing.Pool`**.

Многие приложения требуют от нас не только отображения значения параметра на совокупный результат. Для них простого **`pool.map()`** может быть недостаточно. Для более сложных потоков данных используются явно выстроенные очереди незавершенной работы и вычисляемых результатов. Сейчас перейдем к рассмотрению вопросов создания системы очередей.




### Очереди
---

Возросшие потребности в повышении уровня управления обменом данными между процессами вынуждают нас обратиться к очереди, например к структуре данных в виде очереди, **`queue`**. Существует несколько вариантов, предлагающих способы отправки сообщений от одного процесса к другому или же к нескольким другим процессам. В очередь, **`queue`**, можно поставить любой объект, который может быть переведен в рiсklе-формат, но следует учесть, что перевод в рiсklе-формат сопряжен с немалыми издержками, поэтому излишне укрупнять такие объекты нецелесообразно. Чтобы проиллюстрировать применение очередей, создадим небольшую поисковую систему для текстового контента, которая хранит все соответствующие записи в оперативной памяти.

Данная поисковая система выполняет сканирование всех файлов в текущем каталоге в параллельном режиме. Для каждого ядра центрального процессора выстраивается свой собственный процесс. Каждому процессу дается указание загрузить ряд файлов в оперативную память. Итак, рассмотрим функцию, выполняющую загрузку и поиск:

```python
from pathlib import Path
from typing import List, Iterator, Optional, Union, TYPE_CHECKING

if TYPE_CHECKING:
    Query_Q = Queue[Union[str, None]]
    Result_Q = Queue[List[str]]


def search(paths: list[Path], query_q: Query_Q, results_q: Result_Q) -> None:
    print(f"PID: {os.getpid()}, paths {len(paths)}")
    lines: list[str] = []
    for path in paths:
        lines.extend(l.rstrip() for l in path.read_text().splitlines())

    while True:
        if (query_text := query_q.get()) is None:
            break
        results = [l for l in lines if query_text in l]
        results_q.put(results)
```

Следует помнить, что функция **`search()`** запускается не в основном процессе, создавшем очереди, а в отдельно взятом (фактически же она запускается в отдельно взятых процессах **`cpu_count()`**). Каждый из этих процессов запускается со списком объектов **`pathlib.Path`** и двумя объектами **`multiprocessing.Queue`**; один служит для входящих запросов, а другой - для отправки исходящих результатов. Эти очереди автоматически переводят имеющиеся в них данные в рiсklе-формат и передают их по каналу в подпроцесс. Установка двух таких очередей выполняется в основном процессе, после чего они передаются по каналу в функцию поиска внутри дочерних процессов.

==Аннотации типов отражают способ возможного получения инструментальным средством `mуру` подробной информации о структуре данных в каждой очереди. Когда **`TYPE_CHECKING`** имеет значение **`True`**, это означает включение **`mуру`** в работу и требование с его стороны достаточного объема сведений, позволяющих убедиться, что имеющиеся в приложении объекты соответствуют описаниям объектов в каждой из очередей. Когда **`ТYPE_CHECKING`** имеет значение **`False`**, это означает применение для приложений обычной среды выполнения и невозможность предоставления структурных подробностей выстроенных в очереди сообщений.==

Функция **`search()`** выполняет две разные задачи.

1. При запуске функции открываются все файлы, представленные в списке объектов **`Path`**, и считывается их содержимое. Каждая строка текста в этих файлах накапливается в списке строк **`lines`**. У подобной подготовки данных относительно затратный характер, но она выполняется всего лишь раз.
2. Инструкция **`while`** задает основной цикл обработки событий с целью проведения поиска. В этом цикле для получения запроса из своей очереди используется метод **`query_q.get()`** , после чего выполняется поиск строк. Для постановки ответа в очередь результатов в цикле используется метод **`results_q.put()`**.

В случае обработки на основе использования очереди задействуется типовой паттерн проектирования, имеющийся у инструкции **`while`**. Процесс получает из очереди значение, содержащее некую работу для выполнения, выполняет эту работу, а затем помещает результат в другую очередь. На этапы обработки и очереди можно разложить весьма большие и сложные задачи, позволяя таким образом проводить одновременное выполнение этапов и получать больше результатов за меньшее время. Описанный метод помогает также адаптировать этапы обработки и количество рабочих процессов под наиболее эффективный режим использования процессора. Основная часть приложения создает соответствующий пул рабочих процессов и их очереди. Воспользуемся шаблоном проектирования Фасад (для получения дополнительной информации [[Новые Паттерны Проектирования|«Новые паттерны проектирования»]]). Идея заключается в том, чтобы для объединения очередей и пула рабочих процессов в один объект определить класс **`DirectorySearch`**.

Получаемый в результате объект будет способен выстраивать очереди и рабочие процессы, после чего приложение сможет взаимодействовать с ними, отправляя запрос и получая ответы.

```python
from fnmatch import fnmatch
import os


class DirectorySearch:
    def __init__(self) -> None:
        self.query_queues: list[Query_Q]
        self.results_queue: Result_Q
        self.search_workers: list[Process]

    def setup_search(self, paths: list[Path], cpus: Optional[int] = None) -> None:
        if cpus is None:
            cpus = cpu_count()
        worker_paths = [paths[i::cpus] for i in range(cpus)]
        self.query_queues = [Queue() for p in range(cpus)]
        self.results_queue = Queue()

        self.search_workers = [
            Process(target=search, args=(paths, q, self.results_queue))
            for paths, q in zip(worker_paths, self.query_queues)
        ]
        for proc in self.search_workers:
            proc.start()

    def teardown_search(self) -> None:
        # Signal process termination
        for q in self.query_queues:
            q.put(None)

        for proc in self.search_workers:
            proc.join()

    def search(self, target: str) -> Iterator[str]:
        print(f"search queues={self.query_queues}")
        for q in self.query_queues:
            q.put(target)

        for i in range(len(self.query_queues)):
            for match in self.results_queue.get():
                yield match
```

Метод **`setup_search()`** подготавливает рабочие подпроцессы. Операция нарезки **`[i::cpus]`** позволяет разбить этот список на несколько равных частей. Если количество центральных процессоров равно 8, размер шага будет равен 8 и будут использоваться 8 различных значений смещения от 0 до 7. Также для отправки данных в каждый рабочий процесс создается список объектов **`Queue`**. И наконец, создается единая очередь результатов. Все это передается во все рабочие подпроцессы. Каждый из них может поставить данные в очередь, и они будут собираться в одно целое в основном процессе.

После создания очередей и запуска рабочих процессов метод **`search()`** предоставляет цель всем рабочим процессам одновременно. Теперь все они могут приступать к просмотру своих обособленных коллекций данных с целью выдачи ответов.

Поскольку поиск ведется в довольно большом количестве каталогов, чтобы найти все Раth-объекты **`*.ру`** в заданном базовом каталоге, используется функция-генератор **`all_source()`** . Функция для поиска всех исходных файлов выглядит следующим образом:

```python
def all_source(path: Path, pattern: str) -> Iterator[Path]:
    for root, dirs, files in os.walk(path):
        for skip in {".tox", ".mypy_cache", "__pycache__", ".idea"}:
            if skip in dirs:
                dirs.remove(skip)
        yield from (Path(root) / f for f in files if fnmatch(f,                            pattern))
```

Для проверки дерева каталогов с исключением файловых каталогов, заполненных ненужными нам файлами, функция **`all_source()`** использует функцию **`os.walk()`**. В этой функции для сопоставления имени файла с шаблонами подстановочных знаков, применяемых оболочкой Linux, используется модуль **`fnmatch`**. Чтобы, к примеру, найти все файлы с именами, заканчивающимися на **`.ру`**, может использоваться параметр шаблона **`'*.ру'`**. С помощью данного приема задается начальное значение методу **`setup_search()`** класса **`DirectorySearch`**.

Метод **`teardown_search()`** класса **`DirectorySearch`** помещает в каждую очередь специальное значение завершения. Не забывайте, что каждый рабочий процесс является отдельным процессом, выполняющим инструкцию **`while`** внутри функции **`search()`** и считывающим данные из очереди запросов. Когда он считывает объект **`None`**, происходит выход из инструкции **`while`** и из функции. Затем для сбора всех дочерних процессов с их попутной мягкой очисткой можно воспользоваться функцией **`join()`**. (Если не запустить **`join()`**, в некоторых дистрибутивах Linux могут остаться [[Зомби-процесс|зомби-процессы]], то есть дочерние процессы, не воссоединившиеся должным образом со своим родителем из-за его сбоя; они потребляют системные ресурсы и зачастую требуют перезагрузки компьютера.) Теперь давайте посмотрим на код, позволяющий провести поиск:

```python
from multiprocessing import Process, Queue, cpu_count
import time


if __name__ == "__main__":
    ds = DirectorySearch()
    base = Path.cwd().parent
    all_paths = list(all_source(base, "*.py"))
    ds.setup_search(all_paths)
    for target in ("import", "class", "def"):
        start = time.perf_counter()
        count = 0
        for line in ds.search(target):
            # print(line)
            count += 1
        milliseconds = 1000 * (time.perf_counter() - start)
        print(
            f"Found {count} {target!r} in {len(all_paths)} files "
            f"in {milliseconds:.3f}ms"
        )
    ds.teardown_search()
```

Этот код создает объект **`DirectorySearch`**, **`ds`**, и предоставляет все исходные пути, начиная с родителя текущего рабочего каталога, через выражение **`base = Path.cwd().parent`**. После того как рабочие процессы подготовлены, объект ds выполняет поиск нескольких распространенных строк: **`"import"`** , **`"class"`** и **`"def"`** . Обратите внимание на закомментированную инструкцию **`print(line)`**, осуществляющую вывод подходящих результатов. Интерес для нас все еще представляет производительность. В самом начале первое чтение файла занимает доли секунды. Но после того, как все файлы прочитаны, время поиска резко возрастает. На MacBookРго со 134 файлами исходного кода выводимая на экран информация выглядит так:

```shell
python src/directory search.py
PID: 36566, paths 17
PID: 36567, paths 17
PID: 36570, paths 17
PID: 36571, paths 17
PID: 36569, paths 17
PID: 36568, paths 17
PID: 36572, paths 16
PID: 36573, paths 16
Found 579 'import' in 134 files in 111.561ms
Found 832 'class' in 134 files in 1.010ms
Found 1138 'def' in 134 files in 1.224ms
```

Поиск слова *импорт* занял около 111 миллисекунд (0,111 секунды). А почему он выполнялся гораздо медленнее двух других поисков? Дело в том, что при помещении первого запроса в очередь функция **`search()`** все еще читала файлы. На производительность первого запроса повлияли однократные начальные затраты на загрузку содержимого файла в память. Следующие два запроса выполняются примерно по одной миллисекунде каждый. Это поразительно! На ноутбуке были выполнены почти 1 ООО поисков в секунду с помощью всего лишь нескольких строк кода на Python.

Приведенный пример использования очередей для снабжения данными сразу нескольких рабочих процессов представляет собой ту самую версию конструкции с одним узлом, которая может быть развита до распределенной системы. Представьте, что поисковые запросы отправляются сразу на несколько хост-компьютеров, а затем их результаты соединяются. А теперь представьте, что в центрах обработки данных Google имеется доступ к целому парку компьютеров, и тогда сможете понять, за счет чего они способны так быстро возвращать результаты поиска!

Здесь это рассматриваться не будет, но стоит отметить, что модуль **`multiprocessing`** включает в себя диспетчерский класс, благодаря которому из предыдущего кода могут быть исключены повторяющиеся фрагменты. Есть даже версия диспетчера **`multiprocessing.Manager`**, способная управлять подпроцессами в удаленных системах в целях создания простейшего распределенного приложения. Читатели, заинтересовавшиеся дальнейшим изучением этой темы, могут ознакомиться с документацией по возможностям многопроцессной обработки, предоставляемым в Руthоn-приложениях.

```python
from pytest import *
from unittest.mock import Mock, sentinel, call
import directory_search

@fixture
def mock_query_queue():
    return Mock(
        get=Mock(side_effect=["xyzzy", None])
    )

@fixture
def mock_result_queue():
    return Mock(
        put=Mock()
    )

@fixture
def mock_paths(tmp_path):
    f1 = tmp_path / "file1"
    f1.write_text("not in file1\n")
    f2 = tmp_path / "file2"
    f2.write_text("file2 contains xyzzy\n")
    return [f1, f2]


def test_search(mock_paths, mock_query_queue, mock_result_queue):
    directory_search.search(mock_paths, mock_query_queue, mock_result_queue)
    assert mock_query_queue.get.mock_calls == [call(), call()]
    assert mock_result_queue.put.mock_calls == [
        call(['file2 contains xyzzy'])
    ]


@fixture
def mock_directory(tmp_path):
    f1 = tmp_path / "file1.py"
    f1.write_text("# file1.py\n")
    d1 = tmp_path / ".tox"
    d1.mkdir()
    f2 = tmp_path / ".tox" / "file2.py"
    f2.write_text("# file2.py\n")
    return tmp_path

def test_all_source(mock_directory):
    files = list(directory_search.all_source(mock_directory, "*.py"))
    assert files == [
        mock_directory / "file1.py"
    ]


@fixture
def mock_queue(monkeypatch):
    mock_instance = Mock(
        name="mock Queue",
        put=Mock(),
        get=Mock(return_value=["line with text"])
    )
    mock_queue_class = Mock(
        return_value=mock_instance
    )
    monkeypatch.setattr(directory_search, "Queue", mock_queue_class)
    return mock_queue_class


@fixture
def mock_process(monkeypatch):
    mock_instance = Mock(
        name="mock Process",
        start=Mock(),
        join=Mock()
    )
    mock_process_class = Mock(
        return_value=mock_instance
    )
    monkeypatch.setattr(directory_search, "Process", mock_process_class)
    return mock_process_class

def test_directory_search(mock_queue, mock_process, mock_paths):
    ds_instance = directory_search.DirectorySearch()
    ds_instance.setup_search(mock_paths, cpus=2)

    assert mock_queue.mock_calls == [call(), call(), call()]
    assert mock_process.mock_calls == [
        call(
            target=directory_search.search,
            args=(mock_paths[0::2], mock_queue.return_value, mock_queue.return_value)
        ),
        call(
            target=directory_search.search,
            args=(mock_paths[1::2], mock_queue.return_value, mock_queue.return_value)
        )
    ]
    assert mock_process.return_value.start.mock_calls == [call(), call()]
    assert ds_instance.query_queues == [mock_queue.return_value, mock_queue.return_value]
    assert ds_instance.results_queue == mock_queue.return_value
    assert ds_instance.search_workers == [mock_process.return_value, mock_process.return_value ]

    result = list(ds_instance.search("text"))

    assert result == ['line with text', 'line with text']
    assert mock_queue.return_value.put.mock_calls == [call("text"), call("text")]
    assert mock_queue.return_value.get.mock_calls == [call(), call()]

    ds_instance.teardown_search()
    assert mock_queue.return_value.put.mock_calls == [call("text"), call("text"), call(None), call(None)]
    assert mock_process.return_value.join.mock_calls == [call(), call()]
```


#### Сложности, связанные с многопроцессной обработкой данных
---

Проблемы возникают не только при работе с потоками, но и при использовании многопроцессной обработки, и часть этих проблем уже была рассмотрена. Это и слишком затратный обмен данными между процессами, и, как уже упоминалось, необходимость сериализации объектов при любом взаимодействии процессов как посредством очереди, так и с помощью конвейеров операционной системы или даже совместно используемой памяти. На слишком объемную сериализацию может уходить основная часть времени. Решению проблемы могут помочь объекты, находящиеся в совместно используемой памяти, ограничивая потребности в сериализации за счет исходной настройки этой памяти. Наибольшей эффективности при многопроцессной обработке удается достичь в случае передачи между процессами относительно небольших объектов, в отношении каждого из которых необходимо проделать весьма существенный объем работы.

Совместно используемая память позволяет избежать затрат на многократно повторяемую сериализацию и десериализацию. На объекты Python, подлежащие совместному использованию, накладываются многочисленные ограничения. Совместно используемая память может повысить производительность, но также может привести и к усложнению объектов Python.

Еще одной серьезной проблемой многопроцессной обработки, как и в случае с потоками, является трудность определения того, в каком из процессов осуществляется доступ к переменной или к методу. При многопроцессной обработке рабочие процессы наследуют большое количество данных от родительского процесса. Но это не совместный доступ к данным, а получение их разовой копии. Дочерний процесс может получить копию отображения или список, после чего внести в объект изменения. А родительский процесс так и не увидит изменений, внесенных дочерним процессом.

Существенным преимуществом многопроцессных вычислений является абсолютная независимость процессов. Здесь, ввиду отсутствия совместно используемых данных, не требуется четкого управления блокировками. Кроме того, операционной системой внутренние ограничения на количество открытых файлов устанавливаются на уровне процессов, что позволяет иметь большое количество ресурсоемких процессов. При разработке приложений с прицелом на конкурентные вычисления основное внимание уделяется максимальному использованию центрального процессора для выполнения максимально возможного объема работы за минимально возможное время. Наличие великого множества вариантов всегда требует тщательного исследования решаемой задачи с целью выявления из множества доступных решений наиболее приемлемого для ее выполнения.

>[!info]
>Понятие конкурентной обработки слишком широкое, и выбрать какой то один подходящий на все случаи жизни способ ее реализации просто невозможно. Следует искать наилучшее решение для каждой отдельно взятой задачи. Тут очень важно создавать такой код, который бы легко поддавался корректировке, нас тройке и оптимизации.

Итак, мы рассмотрели два основных инструмента, обеспечивающих конкурентные вычисления в Python: потоки и процессы. ==Потоки существуют в рамках одного процесса операционной системы, совместно использующего память и другие ресурсы.== ==Процессы независимы друг от друга, из-за чего взаимодействие процессов неизбежно влечет за собой накладные расходы. Оба подхода соответствуют концепции объединения конкурирующих рабочих процессов, ожидающих своего запуска в работу и обеспечивающих результаты в некий непредсказуемый момент в будущем.== Эта абстракция доступных в будущем результатов и является тем, что формируется в рассматриваемом далее модуле **`coпcurreпt.futures`**.





## Фьючерсы
---

Пришло время освоить асинхронный способ реализации конкурентных вычислений. Концепция фьючерса, или обещания, - весьма удобная абстракция, предназначенная для описания работы в конкурентном режиме. **Фьючерс** ==- объект, который служит оболочкой для вызова функции.== Этот вызов выполняется в фоновом режиме, в потоке или в отдельном процессе. У объекта фьючерса **`future`** - есть методы для проверки завершенности вычисления и получения результатов. Можно провести аналогию с вычислением, результаты которого будут получены в будущем, что позволяет в ожидании этих результатов заниматься чем-то еще.

Дополнительную информацию ищите по адресу https://hub.packtpub.com/asynchronous-programming-futures-and-promises/.

Имеющийся в Python модуль **`concurrent.futures`** обеспечивает в зависимости от требуемого типа конкурентных вычислений либо многопроцессную обработку, **`multiprocessing`**, либо многопоточность, **`threading`**. Фьючерсы не в состоянии полностью решать проблему случайного изменения совместно используемого состояния, но их применение позволяет структурировать создаваемый код таким образом, чтобы было легче отследить причину возникновения проблемы.

==Фьючерсы могут помочь управлять границами между различными потоками или процессами.== Подобно пулу многопроцессной обработки, они оказываются незаменимы для взаимодействий по типу �вызов - ответ•, при которых обработка выполняется в другом потоке (или процессе), а затем в какой-то момент в будущем, то есть во фьючерсе (недаром он так и назван), можно будет запросить у этого фьючерса результат. Он выступает в качестве оболочки для многопроцессных пулов и пулов потоков, но при этом предоставляет более понятный API и стимулирует создание более читабельного кода.

Рассмотрим еще один пример посложнее: поиск и анализ файлов. В предыдущем разделе была реализована версия Linuх-команды grep. А теперь создадим простую версию команды find, включающую в себя более подробный анализ исходного кода Python. Начнем с аналитической части, поскольку она занимает центральное место в работе и ее нужно выполнять в конкурентном режиме:

```python
from __future__ import annotations
import argparse
import ast
from concurrent import futures
from fnmatch import fnmatch
import os
from pathlib import Path
import sys
import time
from typing import Iterator, NamedTuple


class ImportResult(NamedTuple):
    path: Path
    imports: set[str]

    @property
    def focus(self) -> bool:
        return "typing" in self.imports


class ImportVisitor(ast.NodeVisitor):
    def __init__(self) -> None:
        self.imports: set[str] = set()

    def visit_Import(self, node: ast.Import) -> None:
        # print(ast.dump(node))
        for alias in node.names:
            self.imports.add(alias.name)

    def visit_ImportFrom(self, node: ast.ImportFrom) -> None:
        # print(ast.dump(node))
        if node.module:
            self.imports.add(node.module)


def find_imports(path: Path) -> ImportResult:
    tree = ast.parse(path.read_text())
    iv = ImportVisitor()
    iv.visit(tree)
    return ImportResult(path, iv.imports)
```

Здесь присутствует определение сразу нескольких компонентов. Для начала определяется именованный кортеж **`ImportResult`**, связывающий вместе объект **`Path`** и набор строк. У него есть свойство **`focus`**, занимающееся поиском в наборе строк конкретной строки **`"typing"`**. Вскоре вы поймете, почему эта строка так важна.

Класс **`ImportVisitor`** создан с использованием модуля **`ast`**, входящего в стандартную библиотеку. [[Абстрактное синтаксическое дерево (AST)]] ==- это прошедший синтаксический анализ исходный код, взятый обычно из формального языка программирования.== Ведь в конечном счете сам код Python - всего лишь набор символов. AST для кода Python занимается группировкой текста в значимые инструкции и выражения, имена переменных и операторы, то есть во все синтаксические компоненты языка. У осмотрщика имеется способ осмотра проанализированного кода. В коде предоставлены переопределения для двух методов класса **`NodeVisitor`**, поэтому будут использоваться только два вида инструкций **`import:import х и from х import у`**. Подробности работы структуры данных каждого узла выходят за рамки данного примера, но в документации по модулю **`ast`** в стандартной библиотеке можно найти описание уникальной структуры каждой языковой конструкции Python.

Функция **`find_imports()`** считывает некий исходный код, анализирует код Python, просматривает инструкции **`import`**, а затем возвращает **`ImportResult`** с исходным путем **`Path`** и набором имен, найденных просмотрщиком. Во многих отношениях это куда рациональнее простого сопоставления паттерна для **`"import"`**. К примеру, при использовании **`ast.NodeVisitor`** будут пропущены комментарии и проигнорирован текст внутри символьных строковых литералов, то есть решатся две задачи, которые сложно было бы выполнить с применением регулярных выражений.

В функции **`find_imports()`** нет ничего особенного, но заметьте, что она не обращается ни к каким глобальным переменным. Все взаимодействие с внешней средой передается в функцию или возвращается из нее. Это не техническое требование, а, скорее, способ, позволяющий сохранить рассудок при программировании с применением фьючерсов.

Но нам ведь нужно обработать сотни файлов в десятках каталогов. Наилучший подход к ее решению заключается в одновременном запуске множества однотипных задач с заполнением ядер центрального процессора большим количеством вычислений.

```python
def main(base: Path = Path.cwd()) -> None:
    print(f"\n{base}")
    start = time.perf_counter()
    with futures.ThreadPoolExecutor(24) as pool:
        analyzers = [
            pool.submit(find_imports, path) for path in                                        all_source(base, "*.py")
        ]
        analyzed = (worker.result() for worker in                                         futures.as_completed(analyzers))
    for example in sorted(analyzed):
        print(
            f"{'->' if example.focus else '':2s} "
            f"{example.path.relative_to(base)} {example.imports}"
        )
    end = time.perf_counter()
    rate = 1000 * (end - start) / len(analyzers)
    print(f"Searched {len(analyzers)} files in {base} at                        {rate:.3f}ms/file")
```

Здесь используется та же функция **`all_source()`**, показанная ранее в данной главе, в подразделе «Очереди», требуется базовый каталог, с которого можно начать поиск, и паттерн, например, **`"*.ру"`** для поиска всех файлов с расширением `.ру`. Также здесь создан **`ThreadPoolExecutor`**, назначенный переменной pool, с двумя десятками рабочих потоков, и все они ожидают своей активизации. Список Futurе-объектов создается в объекте analyzers с помощью генератора списков, применяющего метод **`pool.submit()`** к функции поиска **`find_imports()`** и пути **`Path`** из выходных данных **`all_source()`**.

Потоки в пуле тут же приступят к работе над отправленным списком задач. Каждый поток, завершая свою работу, сохраняет результаты в объекте **`Future`** и берет на себя дополнительную нагрузку.

Тем временем на первом плане приложением используется выражение генератора для вычисления метода **`result()`** каждого Future-oбъeктa. Следует обратить внимание, что просмотр фьючерсов посетителем осуществляется с помощью генератора **`futures.as_completed()`**. Функция начинает предоставлять завершившие вычисления Futurе-объекты по мере их появления. Из этого следует, что результаты моrут следовать не в порядке их первоначального представления. Существуют и другие способы просмотра фьючерсов. На тот случай, если это важно, можно, например, подождать, пока завершатся вычисления во всех фьючерсах, а затем просмотреть их в том порядке, в котором они были отправлены.

Результаты извлекаются из каждого Future-oбъeктa. Из аннотаций типов можно понять, что это будет объект **`ImportResult`** с **`Path`** и набором строк, представляющим имена импортируемых модулей. Результаты можно отсортировать, чтобы файлы отображались в каком-то целесообразном порядке.

На MacBookPro обработка каждого файла занимает около 1 689 миллисекунд (0,001689 секунды); 24 отдельных потока легко вписываются в единый процесс, не перегружая операционную систему. Увеличение числа потоков существенно не влияет на время выполнения, то есть, предположительно, любые оставшиеся без внимания узкие места связаны не с конкурентными вычислениями, а с исходным сканированием дерева каталогов и созданием пула потоков.

А что можно сказать в отношении функции **`focus`** класса **`ImportResult`**? Чем так уж знаменателен модуль **`typing`**? Когда в процессе написания данной книги вышла новая версия `mуру`, нам пришлось просмотреть аннотации типов в каждой главе. При этом определенную помощь оказало разделение модулей на требующие тщательной проверки, с одной стороны, и не нуждающиеся в пересмотре - с другой.

И это все, что требуется для разработки приложения на основе использования фьючерсов с привязкой к операциям ввода-вывода. По сути, здесь применяются те же потоки или процессы API, которые уже рассматривались, но при этом предоставляется более понятный интерфейс и облегчается понимание границ между функциями, выполняемыми в конкурентном режиме (только не нужно пытаться из фьючерса получить доступ к глобальным переменным !).

Во многих приложениях модуль **`concurrent.futures`** является тем самым местом, с которого можно начать разработку кода на Python. Модули более низкого порядка **`threading`** и **`multiprocessin`** предлагают для весьма сложных случаев ряд дополнительных конструкций.

Применение **`run_in_executor()`** позволяет приложению для распределения всей работы между несколькими процессами или несколькими потоками использовать классы **`ProcessPoolExecutor`** или **`ThreadPoolExecutor`** модуля **`concurrent.futures`**. Тем самым обеспечивается более существенная гибкость в рамках весьма приглядного, эргономичного API.

Иногда в конкурентных вычислениях нет никакой реальной нужды. В других же случаях просто нужна возможность переключения между ожиданием доступности данных и вычислениями. Способностью чередования обработки в рамках одного и того же потока обладают асинхронные функции Python, в числе которых функции, входящие в состав модуля **`asyncio`**. Именно такой вариант конкурентных вычислений и будет темой следующего раздела.





## Библиотека **`AsyncIO`**
---

