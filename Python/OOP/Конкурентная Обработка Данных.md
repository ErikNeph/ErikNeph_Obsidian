---
date of creation: 2024-07-05T16:20:00
tags:
  - Competitiveness
  - OOP/Competitiveness
  - Python/Asynchrony
  - Asynchrony
  - Developing
  - IT/Python
read status: true
aliases:
  - Python ООП и конкурентность
---
---
# Конкурентная Обработка Данных

Конкурентная обработка данных подразумевает, что компьютер одновременно выполняет сразу несколько задач. В прошлом это означало, что процессору предлагалось переключаться между различными задачами по много раз в секунду. В современных системах это также может буквально означать выполнение двух или более задач одновременно на отдельных ядрах процессора.

По сути, конкурентность не имеет прямого отношения к теме объектно-ориентированного программирования, но имеющиеся в Python системы конкурентных вычислений предоставляют объектно-ориентированные интерфейсы, речь о которых шла в книге.

Мы рассмотрим следующие темы.

- **[[#Потоки|Потоки.]]**
- **[[#Многопроцессная обработка данных|Многопроцессная обработка данных.]]**
- **[[#Фьючерсы|Фьючерсы.]]**
- **[[#Библиотека **`AsyncIO`**|Библиотека AsyncIO.]]**
- **[[#Контрольная задача обедающих философов|Контрольная задача обедающих философов.]]**

В тематическом исследовании будут рассмотрены способы ускорения тестирования модели и настройки гиперпараметров. Отказаться от вычислений, чтобы сократить время их выполнения, конечно же, нельзя, но зато можно воспользоваться современным многоядерным компьютером и все-таки достигнуть ускорения.

Организация конкурирующих процессов может стать непростой задачей. Казалось бы, основные концепции весьма просты, но когда последовательность изменений состояния непредсказуема, возникающие ошибки, как известно, трудно отследить. И все же для многих проектов конкурентная обработка данных является единственным способом получения необходимой производительности. Только представьте, что веб-сервер не смог бы ответить на запрос пользователя, пока не будет завершен запрос другого пользователя!

Здесь будет рассмотрена реализация конкурентных вычислений в Python и упомянуты некоторые наиболее распространенные ошибки, которых следует избегать.

Инструкции в языке Python выполняются в строгой последовательности. Чтобы рассматривать возможность конкурентного их выполнения, нужно сделать шаг в сторону от Python.


## История конкурентной обработки данных
---

Концептуально конкурентную обработку можно представить в виде группы людей, которые пытаются совместно работать над решением какой-либо задачи, будучи не в состоянии увидеть друг друга. Возможно, у них что-то со зрением, или же они разделены перегородками, или двери в их рабочем пространстве не позволяют видеть сквозь них. И все же эти люди могут обмениваться маркерами, заметками и незавершенной работой.

Представьте себе небольшую кулинарию в старом приморском курортном городе (на Атлантическом побережье США), с неудобной планировкой стойки. Два сэндвич-повара не видят и не слышат друг друга. Владелец может позволить себе платить двум прекрасным поварам, но не может сделать стойку, вмещающую более одного подноса. Из-за неудобств старинной планировки повара также не могут видеть и поднос. Им приходится заглядывать под свой рабочий стол, чтобы убедиться, что поднос на месте. Затем, убедившись, они аккуратно выкладывают на поднос свое произведение искусства с маринованными огурцами и картофельными чипсами. (Им не виден поднос, но они великолепные повара, способные точно выложить на него сэндвич и все ингредиенты.)

А вот хозяин видит поваров. За их работой могут наблюдать даже посетители. Это отличное шоу. Хозяин обычно раздает заказы каждому шеф-повару в строгой очередности. Но получается так, что под сэндвич и его торжественную подачу к столу может быть выставлен один-единственный поднос. Как уже говорилось, шеф-повара, прежде чем кто-то сможет насладиться вкусом их следующего творения, вынуждены ждать, когда можно будет увидеть поднос на месте.

И вот однажды один и з поваров (назовем его Майкл, но друзья зовут его просто Мо) уже почти приготовил заказ, но был вынужден сбегать к холодильнику за столь любимыми всеми посетителями маринованными огурчиками. Время на приготовление блюда, заказанного Мо, затянулось, и хозяин увидел, что другой шеф-повар, Константин, похоже, опережает Мо в готовности своего блюда на доли секунды. И хотя Мо вернулся с огурчиками и готов был закончить комплектацию сэндвича, хозяин допустил одно неловкое движение. В кулинарии действует весьма простое и понятное правило: сначала нужно проверить, на месте ли поднос, а уж затем положить на него сэндвич. И это правило известно всем. Когда хозяин перенес поднос из окошка под столом Мо к окошку под столом Константина, Мо положил свое творение - великолепный сэндвич « Рубен» туда, где должен был находиться поднос, и, к досаде всех присутствующих, продукт шлепнулся на пол.

Как же все-таки мог не сработать безотказный метод проверки подноса до выкладки сэндвича? Ведь он выдержал испытание многими напряженными обеденными часами, а всего лишь мелкий сбой в обычной последовательности событий привел к беспорядку. Пауза между проверкой наличия подноса и выкладкой на него сэндвича позволила хозяину изменить порядок вещей.

По сути, хозяин и шеф-повара стали состязаться в скорости действий. Предотвращение непредвиденных ситуаций - основная задача конкурентного программирования.

Одним из решений могло бы стать использование семафора - флага, предназначенного для предотвращения неожиданных изменений в состоянии подноса. Это своеобразная совместно используемая блокировка. Каждый шеф-повар вынужден перед выкладкой на поднос завладеть флагом; и, как только он его получит, можно будет пребывать в полной уверенности, что хозяин не передвинет поднос, пока шеф-повар не вернет флаг на маленькую подставку для флагов между постами шеф-поваров.

Для конкурентной работы требуется какой-либо метод синхронизации доступа к общим ресурсам. Одной из важнейших возможностей больших современных компьютеров является управление конкурентностью с помощью функций операционной системы, в совокупности называемых ядром.

Устаревшие компьютеры были компактными, имели одно ядро в одном процессоре и должны были чередовать все операции. Благодаря продуманной координации создавалось впечатление одновременной работы над несколькими задачами. Новые многоядерные компьютеры (и большие многопроцессорные
компьютеры) фактически способны выполнять операции одновременно, но диспетчеризация при этом немного усложняется.


Существует несколько способов реализации конкурентной обработки данных.

- Операционная система допускает одновременный запуск сразу нескольких программ. Имеющийся в Python модуль *subprocess* предоставляет уже готовый доступ к этим возможностям. А модулем многопроцессной обработки, *multiprocessing*, обеспечивается целый ряд приемлемых способов работы. Все это относительно легко запускается, но при этом каждая программа оказывается полностью изолированной от всех остальных программ. Как же тогда они могут обмениваться данными?
- Некоторые высокотехнологичные программные библиотеки позволяют одной программе иметь сразу несколько конкурирующих операционных потоков. Доступ к многопоточности предоставляет имеющийся в Python модуль *threading*. Приступить к работе с ним труднее, чем к работе с обычным модулем, и следует отметить, что у каждого потока имеется полный доступ к данным во всех других потоках. Возникает вопрос: а как тогда можно будет координировать обновления общих структур данных?

Кроме этих способов, имеются и более простые в использовании оболочки для базовых библиотек. Они предоставлены модулями **`concurrent.futures`** и **`asyncio`**.

В данной главе сначала будет рассмотрено использование в Python библиотеки **`threading`**, позволяющей многим операциям выполняться в многопоточном режиме в рамках одного процесса операционной системы. В этом нет ничего сложного, за исключением ряда трудностей, возникающих при работе с общими структурами данных.


## Потоки
---

==Поток представляет собой последовательность инструкций байт-кода Python==, выполнение которой может быть прервано и возобновлено. Замысел заключается в создании отдельных конкурирующих потоков, позволяющих выполнять вычисления во время ожидания программой результатов выполнения операций ввода-вывода.

==Например, сервер может приступить к обработке нового сетевого запроса, ожидая поступления данных из предыдущего запроса.== Или же интерактивная программа может отображать анимацию или выполнять вычисления, ожидая, пока пользователь нажмет клавишу. Следует понимать разницу в скорости работы: за минуту человек может набрать более 500 символов, а компьютер за секунду может выполнить миллиарды инструкций. То есть между обработкой нажатий отдельных клавиш даже при быстром наборе текста компьютер способен выполнить огромное количество операций.

Теоретически разработчик вполне способен управлять всеми этими переключениями между разными действиями в рамках самой создаваемой программы, но сделать это должным образом практически нереально. Лучше положиться на возможности языка Python и операционной системы, которые берут на себя самую сложную часть переключений, ==оставляя на долю программистов создание объектов, которые как бы действуют одновременно, но независимо друг от друга.== Именно такие объекты и называются **потоками**. Рассмотрим простой пример, начиная, как показано в следующем классе, с основного определения потоковой обработки данных:

```python
import math
import random
from threading import Thread, Lock
import time

THE_ORDERS = [
    "Reuben",
    "Ham and Cheese",
    "Monte Cristo",
    "Tuna Melt",
    "Cuban",
    "Grilled Cheese",
    "French Dip",
    "BLT",
]


class Chef(Thread):
    def __init__(self, name: str) -> None:
        super().__init__(name=name)
        self.total = 0

    def get_order(self) -> None:
        self.order = THE_ORDERS.pop(0)

    def prepare(self) -> None:
        """Simulate doing a lot of work with a BIG computation"""
        start = time.monotonic()
        target = start + 1 + random.random()
        for i in range(1_000_000_000):
            self.total += math.factorial(i)
            if time.monotonic() >= target:
                break
        print(f"{time.monotonic():.3f} {self.name} made {self.order}")

    def run(self) -> None:
        while True:
            try:
                self.get_order()
                self.prepare()
            except IndexError:
                break  # No more orders

```

Поток в выполняемом приложении должен расширить класс **`Thread`** и реализовать метод **`run`**. Любой код, выполняемый методом **`run`**, является отдельным потоком обработки данных, проходящим независимую диспетчеризацию. Описанный в коде поток ссылается на совместно используемый объект - глобальную переменную **`THE_ORDERS`**:

```python
import math
import random
from threading import Thread, Lock
import time

THE_ORDERS = [
    "Reuben",
    "Ham and Cheese",
    "Monte Cristo",
    "Tuna Melt",
    "Cuban",
    "Grilled Cheese",
    "French Dip",
    "BLT",
]
```

В данном случае заказы определены в виде простого фиксированного списка значений. В более крупном приложении они могли бы считываться из сокета или из объекта очереди. А вот так выглядит программа верхнего уровня, запускающая все на выполнение:

```python
Mo = Chef("Michael")
Constantine = Chef("Constantine")

if __name__ == "__main__":
    random.seed(42)
    Mo.start()
    Constantine.start()
```

При выполнении этого кода будут созданы два потока. Новые потоки не начнут выполняться, пока для объекта не будет вызван метод **`start()`**. Оба потока при запуске извлекают значение из списка заказов, а затем приступают к серьезным вычислениям, сообщая в конечном итоге о своем статусе. Результат выглядит так:

```shell
605962.421 Constantine made French Dip
605963.015 Michael made BLT
605963.718 Constantine made Grilled Cheese
605964.265 Michael made Cuban
605965.468 Constantine made Tuna Melt
605965.968 Michael made Monte Cristo
605967.078 Michael made Reuben
605967.390 Constantine made Ham and Cheese
```

Заметьте, бутерброды готовятся не в порядке их представления в списке **`THE_ORDERS`**. Каждый шеф-повар работает в своем собственном (произвольном) темпе. Изменение начального элемента приведет к сдвигу по времени и может слегка изменить порядок.

Главным в данном примере является совместное использование потоками структуры данных, а одновременность их выполнения - иллюзия, созданная продуманной диспетчеризацией с целью чередования выполнения двух шеф-поварских потоков.

В этом небольшом примере все, что делается с совместно используемой структурой данных, сводится всего лишь к извлечению элементов из списка. Если бы создавался свой собственный класс и реализовались более сложные изменения состояния, то при использовании потоков мог бы проявиться целый ряд весьма интересных и запутанных проблем.


### Проблемы, возникающие при использовании потоков
---

Пользу от применения потоков можно извлечь при условии четкого управления совместно используемой памятью, но нынешние Руthоn-программисты не склонны к этому варианту по ряду веских причин. Вскоре станет ясно, что Руthоn-сообществом все большее предпочтение отдается иным способам программирования обработки данных в конкурентном стиле. Но прежде чем переходить к альтернативным способам создания многопоточных приложений, все-таки рассмотрим некоторые трудности из числа тех, что возникают на пути использования потоков.


#### Совместно используемая память
---

Основная проблема работы с потоками также является и их основным преимуществом. У потоков имеется доступ ко всей памяти процесса и, следовательно, ко всем переменным. Игнорирование общего состояния может слишком легко превратиться в несогласованность.

Вам приходилось когда-нибудь быть в комнате, где у одной и той же люстры были два выключателя, на которые одновременно нажимали два разных человека? Каждый пользователь (поток) полагал, что в результате его действия будет включен свет (изменено значение переменной), но в результате, вопреки их ожиданиям, свет не загорался. А теперь представьте ситуацию, при которой эти два потока переводили бы средства между банковскими счетами или управляли бы круиз-контролем автомобиля.

Решением описанной проблемы в многопоточном программировании является *синхронизация* доступа к любому коду, выполняющему чтение значения совместно используемой переменной или (что особенно важно) запись в нее другого значения. Руthоn-библиотекой **`threading`** предлагается класс **`Lock`**, им можно воспользоваться с помощью инструкции **`with`** для создания контекста, в котором у одного потока имеется доступ к обновлению совместно используемых объектов.

В общем плане решение по синхронизации считается вполне работоспособным, но о его применении к совместно используемым данным в конкретном приложении очень легко забыть. Хуже того, ошибки, вызванные неверным использованием синхронизации, слишком сложно отследить, поскольку порядок, в котором потоки выполняют операции, не всегда одинаков и ошибка очень трудно поддается воспроизведению.

Обычно куда безопаснее осуществлять обмен данными между потоками принудительно, используя облегченную структуру, в которой уже соответствующим образом используются блокировки. Для этого в Python предлагается класс очереди - **`Queue`**. При этом запись в очередь выполняется несколькими потоками, а пользоваться результатами может только один поток. В результате получается аккуратный, многократно используемый, проверенный метод совместной работы со структурой данных несколькими потоками. Практически идентичен с описанным класс **`multiprocessing.Queue`**, который будет рассмотрен ниже, в разделе «Многопроцессная обработка данных».

Бывает так, что все эти недостатки перевешиваются одним-единственным преимуществом совместного использования памяти: быстротой. Если доступ к огромной структуре данных требуется сразу нескольким потокам, то совместно используемая память в состоянии довольно быстро обеспечить такой доступ. Но это преимущество обычно сводится на нет следующим фактом: ==в Python невозможно сделать так, чтобы два потока, работающие на разных ядрах процессора, выполняли вычисления в точности в одно и то же время.== Это подводит нас ко второй проблеме, связанной с использованием потоков.



#### Глобальная блокировка интерпретатора
---

Для эффективного управления памятью, сборкой мусора и вызовами машинного кода в собственных библиотеках в Python используется глобальная блокировка интерпретатора, или **[[GIL (Python)|GIL]]**(**global interpreter lock**). Ее невозможно отключить, и получается, что диспетчеризация потоков ограничена **GIL**: она не позволяет любым двум потокам выполнять вычисления в одно и то же время; их работа искусственно чередуется. Когда поток делает запрос к операционной системе, например для доступа к диску или сети, GIL-блокировка снимается, как только этот поток войдет в режим ожидания завершения этого запроса.

==Пренебрежительным отношением к GIL грешат в основном те, кто не понимает, что это такое и какие преимущества эта блокировка приносит Python.== Конечно, она может мешать многопоточному программированию, требующему больших вычислительных ресурсов, но на другие виды рабочих нагрузок чаще всего оказывает самое минимальное влияние. А при встрече с алгоритмом, требующим больших вычислительных затрат, помочь с управлением обработкой данных может пакет **`dask`**. Дополнительные сведения об этой альтернативе можно получить по адресу https://dask.org. Информационной подпиткой может также стать книга [Scalable Data Analysis in Python with Dask](https://www.oreilly.com/library/view/scaling-python-with/9781098119867/) М. Кашифа.

>[!tip]
>Проблемы, связанные с GIL- блокировкой в используемой большинством специалистов стандартной версии Pythoп, можно обойти с помощью ее выборочного отключения в **IronPython**. Подробности ослабления GIL-блокировки с целью выполнения интенсивной обработки данных в **`IronPython`** можно найти в книге [The Iron Python Cookbook](https://www.amazon.com/IronPython-Action-Michael-J-Foord/dp/1933988339).


##### Издержки использования потоков
---

Еще одним недостатком потоков, по сравнению с рассматриваемыми далее асинхронными подходами, являются издержки на обслуживание потока. Дело в том, что каждый поток занимает для записи своего состояния определенный объем памяти (как в процессе Python, так и в ядре операционной системы). На переключение между потоками также тратится (сравнительно небольшое) количество процессорного времени. Переключение происходит беспрепятственно, без какого-либо дополнительного программирования (нужно просто вызвать **`start()`**, и все будет сделано без вашего участия), но работа все равно должна быть где-то выполнена.

Эти издержки могут быть снижены при увеличении рабочей нагрузки за счет повторного использования потоков для выполнения не одного, а нескольких заданий. Для решения такой задачи в Python служит функция **`ThreadPool`**, которая ведет себя идентично пулу процессов. Он вскоре будет рассмотрен, поэтому отложим обсуждение до ознакомления с материалами других разделов данной главы.

А в следующем разделе займемся изучением основной альтернативы многопоточности. Возможность работы с подпроцессами операционной системы открывается благодаря потенциалу модуля **`multiprocessing`**.




## Многопроцессная обработка данных
---

Потоки работают в рамках одного процесса операционной системы, чем и обусловливается возможность их совместного доступа к общим объектам. На уровне процесса могут также выполняться конкурентные вычисления. В отличие от потоков каждый отдельно взятый процесс не может напрямую обращаться к переменным, созданным другими процессами. Польза от такой независимости выражается в том, что у любого процесса имеется своя собственная GIL-блокировка и свой собственный закрытый пул ресурсов. На современном многоядерном процессоре процесс может иметь собственное ядро, позволяющее одновременно работать с другими ядрами.

Изначально API многопроцессной обработки, **`multiprocessing`**, был разработан для имитации потокового API. Но он эволюционировал и в последних версиях Python стал еще надежнее поддерживать более широкий арсенал функций. Библиотека **`multiprocessing`** предназначена для тех случаев, когда задания с интенсивным использованием процессора должны выполняться параллельно при условии доступности нескольких ядер. Польза от многопроцессной обработки снижается, когда процессы тратят большую часть своего времени на ожидание ввода-вывода (например, при работе в сети, с диском, с базой данных или с клавиатурой), но очень хорошо проявляется при параллельных вычислениях.

При работе модуля **`multiprocessing`** запускаются новые процессы операционной системы. Получается, что для каждого процесса запускается полностью автономная копия интерпретатора Python. Например, попробуем распараллелить сложную вычислительную операцию, используя конструкции, аналогичные предоставляемым АРI-интерфейсом **`threading`**:

```python
from multiprocessing import Process, cpu_count
import time
import os


class MuchCPU(Process):
    def run(self) -> None:
        print(f"OS PID {os.getpid()}")

        s = sum(2 * i + 1 for i in range(100_000_000))


if __name__ == "__main__":
    workers = [MuchCPU() for f in range(cpu_count())]

    t = time.perf_counter()
    for p in workers:
        p.start()
    for p in workers:
        p.join()
    print(f"work took {time.perf_counter() - t:.3f} seconds")
```

Код этого примера просто заставляет центральный процессор вычислять сумму из 100 миллионов нечетных чисел. Похоже, полезной эту работу назвать довольно сложно, но она может согреть ваш ноутбук в холодную погоду!

АРI-интерфейс вам должен быть знаком: здесь реализуется подкласс **`Process`** (вместо **`Thread`**) и метод **`run`**. Данный метод перед выполнением интенсивной (хотя и бестолковой) работы выводит на экран ==*идентификатор процесса операционной системы*== (**`PID`**), являющийся уникальным номером, присваиваемым каждому процессу на компьютере.

Особое внимание следует обратить на фрагмент [[Код для самотестирования на Python|if _name_ == "_main_"]]: ==это защита кода на уровне модуля, предотвращающая запуск модуля в случае его импорта, а не запуска в качестве программы.== Этот прием рекомендуется применять повсеместно, но при использовании модуля **`multiprocessing`** без него просто не обойтись. Следуя внутренней логике, модулю **`multiprocessing`**, возможно, придется повторно импортировать ваш прикладной модуль в каждый из новых процессов, чтобы создать класс и выполнить метод **`run()`**. Если в этот самый момент позволить выполняться всему модулю, он начнет рекурсивно создавать все новые и новые процессы до истощения ресурсов системы, что приведет к сбою компьютера.

Демонстратор в примере создает по одному процессу для каждого имеющегося в компьютере процессорного ядра, а затем сам запускается на выполнение и присоединяется к каждому из этих процессов. На MacBook Pro 2020 года выпуска с четырехъядерным процессором Intel Core i5 с тактовой частотой 2 ГГц выходные данные выглядят следующим образом:

```shell
% python src/processes_1.py
OS PID 15492
OS PID 15493
OS PID 15494
OS PID 15495
OS PID 15497
OS PID 15496
OS PID 15498
OS PID 15499
work took 20.711 seconds
```

В первых восьми строках вы видите выведенные на экран экземпляром **`MuchCPU`** идентификаторы процессов. В последней строке показано, что 100 миллионов сложений могут выполняться примерно за 20 секунд. В течение этих 20 секунд все восемь ядер работали на 100 %, а вентиляторы жужжали вовсю, пытаясь рассеять тепло.

Если в **`MuchCPU`** вместо подкласса **`multiprocessing.Process`** создать подкласс **`threading.Thread`**, вывод на экран будет таким:

```shell
% python src/processes_1.py
OS PID 15772
OS PID 15772
OS PID 15772
OS PID 15772
OS PID 15772
OS PID 15772
OS PID 15772
OS PID 15772
work took 69.316 seconds
```

Здесь потоки выполняются внутри одного и того же процесса операционной системы, что занимает в три раза больше времени. На дисплее видно, что ни одно из ядер особо загружено не было, а это наводит на мысль о несбалансированном распределении работы между различными ядрами. В целом замедление было связано с издержками на GIL-блокировки при чередовании ресурсоемкой вычислительной работы. Можно было бы, конечно, ожидать, что версия с одним процессом будет работать по меньшей мере в восемь раз дольше версии с восемью процессами.

Но простая арифметика здесь не действует в силу ряда факторов: порядка обработки в Python низкоуровневых инструкций, работы диспетчера процессов операционной системы и даже работы самого оборудования. То есть что-либо прогнозировать в этом плане довольно сложно и лучше будет запланировать проведение нескольких тестов производительности с использованием нескольких программных архитектур.

Запуск и остановка отдельно взятых экземпляров **`Process`** сопряжены с солидными издержками. ==Наиболее приемлемой сложившейся практикой является организация пула рабочих процессов и назначение им задач.== Именно этот прием и будет рассмотрен далее.




### Многопроцессные пулы
---

Поскольку операционная система строго разграничивает каждый процесс, межпроцессное взаимодействие требует особого внимания из-за потребности передачи данных между отдельно взятыми процессами. Одним из весьма распространенных приемов решения этой задачи является запись файла одним и возможность его считывания другим процессом. Когда такие два процесса осуществляют чтение и запись файла в одно и то же время, следует обеспечить ожидание считывающего процесса до выдачи данных записывающим процессом. Этого можно добиться за счет выстраивания средствами операционной системы *конвейерной структуры*. Находясь в оболочке операционной системы, можно ввести следующую команду: **`ps -ef | grep python`** - и передать выходные данные из команды **`ps`** в команду **`grep`**. Эти две команды выполняются одновременно. Для пользователей Windows PowerShell существуют аналогичные виды конвейерной обработки, использующие разные имена команд. (Примеры ищите по адресу https://learn.microsoft.com/en-us/powershell/scripting/learn/ps101/06-flow-control?view=powershell-7.4.)

Пакетом многопроцессной обработки **`multiprocessing`** предоставляются дополнительные способы реализации межпроцессного взаимодействия. Способ обмена данными между процессами может быть легко завуалирован пулами. Использование пула схоже с вызовом функции: данные передаются в функцию, выполняющуюся в другом процессе или процессах, а когда работа выполнена, полученное значение возвращается. Здесь важно осознавать объем выполняемой для этого работы: объекты одного процесса переводятся в рiсklе-формат и передаются в конвейер обработки операционной системы. Затем другой процесс извлекает данные из конвейера и восстанавливает их из рiсklе-формата. Запрошенная работа выполняется в подпроцессе, после чего выдается результат. Полученный результат переводится в рiсklе-формат и передается обратно в конвейер. И наконец, исходный процесс его возвращает, предварительно переведя в исходный вид из рiсklе-формата. В совокупности это называется переводом в сериализованный рiсklе-формат, передачей и десериализацией - восстановлением из рiсklе-формата. Дополнительные сведения можно найти в [[Строки, сериализация и пути к файлам]].

На сериализованный обмен данными между процессами затрачиваются время и память. Хотелось бы провести как можно больше полезных вычислений при наименьших затратах на сериализацию. Здесь требуется идеальное соотношение размера и сложности объектов, подлежащих обмену, поэтому получается, что разным конструкциям структур данных будут соответствовать разные уровни производительности.

>[!tip]
>Спрогнозировать производительность весьма непросто. Чтобы обеспечить эффективность конкурентной работы с данными, нужно от-профилировать приложение.

Если разобраться во всех тонкостях, то создать программный код, заставляющий работать все упомянутые механизмы обработки данных, не составит особого труда. Рассмотрим задачу вычисления всех простых множителей списка случайных чисел. Это обычная составляющая различных криптографических алгоритмов (не говоря уже о вскрытии подобных алгоритмов!).

Чтобы разложить на множители 232-значные числа, используемые некоторыми алгоритмами шифрования, требуются месяцы, а возможно, и годы вычислений. Следующую реализацию, несмотря на легкость ее прочтения, нельзя признать эффективной: на разложение с ее помощью даже 100-значного числа ушли бы годы. ==Но здесь она уместна, поскольку наша цель сейчас состоит в наблюдении за использованием большого объема процессорного времени для разложения на множители девятизначных чисел:==

```python
from __future__ import annotations
from math import sqrt, ceil
import random
from multiprocessing.pool import Pool


def prime_factors(value: int) -> list[int]:
    """
    >>> set(prime_factors(42))
    {2, 3, 7}
    >>> set(prime_factors(97))
    {97}
    """
    if value in {2, 3}:
        return [value]
    factors: list[int] = []
    for divisor in range(2, ceil(sqrt(value)) + 1):
        quotient, remainder = divmod(value, divisor)
        if not remainder:
            factors.extend(prime_factors(divisor))
            factors.extend(prime_factors(quotient))
            break
    else:
        factors = [value]
    return factors


if __name__ == "__main__":
    to_factor = [random.randint(100_000_000, 1_000_000_000) for i in range(40_960)]
    with Pool() as pool:
        results = pool.map(prime_factors, to_factor)
    primes = [
        value for value, factor_list in zip(to_factor, results) if len(factor_list) == 1
    ]
    print(f"9-digit primes {primes}")
```

Остановимся на простом для понимания рекурсивном алгоритме вычисления в лоб множителей, сконцентрировав все внимание на аспектах параллельной обработки данных. Здесь создается список **`to_factor`**, состоящий из 40 960 отдельных чисел. Затем создается экземпляр **`pool`** многопроцессного пула.

==По умолчанию в этом пуле создается отдельный процесс для каждого из ядер процессора того компьютера, на котором он запущен.==

Принадлежащий пулу метод **`map()`** принимает функцию и итерируемый объект. ==Пул переводит в рiсklе-формат каждое из значений в итерируемом объекте и передает его рабочему процессу, доступному в пуле, и он уже применяет к полученному значению функцию.== Когда данный процесс завершает свою работу, он переводит в рiсklе-формат получившийся список множителей и передает его обратно в пул. Затем рабочий процесс берется за следующую работу, если таковая в пуле имеется.

Как только все имеющиеся в пуле рабочие процессы завершат обработку данных (на что может уйти некоторое время), список результатов **`results`** передается обратно исходному процессу, до сих пор терпеливо ожидавшему завершения всей работы. Результаты выполнения функции **`map()`** будут выстроены в порядке следования запросов. Это придает смысл применению функции **`zip()`** для сопоставления исходного значения с вычисленными простыми множителями.

Зачастую рациональнее воспользоваться аналогичным методом **`map_async()`**, возвращающим результат без промедления, даже если процессы все еще работают. Но здесь уже переменная **`results`** будет не списком значений, а контрактом (или сделкой, или обязательством) возвращать список значений в будущем при вызове клиентом метода **`results.get()`**. У этого будущего объекта также имеются методы **`ready()`** и **`wait()`**, позволяющие проверить, все ли результаты получены. Такой вариант хорошо подходит для обработки данных, время завершения которой сильно варьируется.

Или же, если все значения, для которых нужно получить результаты, пока что неизвестны, можно воспользоваться методом **`apply_async()`** и поставить задание в очередь. Если в пуле есть еще не задействованный процесс, он будет немедленно запущен; в противном случае пул будет сохранять задание до тех пор, пока не появится свободный рабочий процесс.

Пулы также могут быть закрыты (**closed**), при этом они будут отказываться выполнять какие-либо последующие задачи, но продолжат обрабатывать все, что на данный момент находится в очереди. Они также могут быть завершены (**terminated**), что еще больше усложняет ситуацию, поскольку в запуске любых заданий, все еще находящихся в очереди, будет отказано, хотя всем выполняемым на данный момент заданиям по-прежнему будет разрешено завершиться.

Имеет смысл задействовать определенное количество рабочих процессов, и это количество оказывается ограничено рядом соображений.

- Вычисления могут одновременно проводиться только процессами **`cpu_count()`**, при этом в режиме ожидания может находиться любое количество других процессов. Если рабочая нагрузка сопряжена с высокой интенсивностью использования центрального процессора, то повлиять на скорость вычислений величина пула рабочих процессов не сможет. Но если в рабочей нагрузке велика доля операций ввода-вывода, большой пул ускоряет выполнение работы.
- Для слишком крупных структур данных на скорость их обработки положительно влияет сокращение имеющегося в пуле количества рабочих процессов, поскольку тем самым обеспечивается более эффективное использование оперативной памяти.
- Обмен данными между процессами - слишком затратная операция, поэтому при ее осуществлении целесообразнее будет воспользоваться данными, прошедшими легкую сериализацию.
- На создание новых процессов также тратится некоторое время, поэтому пул фиксированного размера помогает свести к минимуму негативное влияние подобных затрат.

Многопроцессный пул способен существенно повысить эффективность вычислений при относительно небольших усилиях с нашей стороны. На нас возлагается ответственность за определение такой функции, которая сможет вести вычисления в параллельном режиме, и за отображение аргументов этой функции с помощью экземпляра класса **`multiprocessing.Pool`**.

Многие приложения требуют от нас не только отображения значения параметра на совокупный результат. Для них простого **`pool.map()`** может быть недостаточно. Для более сложных потоков данных используются явно выстроенные очереди незавершенной работы и вычисляемых результатов. Сейчас перейдем к рассмотрению вопросов создания системы очередей.




### Очереди
---

Возросшие потребности в повышении уровня управления обменом данными между процессами вынуждают нас обратиться к очереди, например к структуре данных в виде очереди, **`queue`**. Существует несколько вариантов, предлагающих способы отправки сообщений от одного процесса к другому или же к нескольким другим процессам. В очередь, **`queue`**, можно поставить любой объект, который может быть переведен в рiсklе-формат, но следует учесть, что перевод в рiсklе-формат сопряжен с немалыми издержками, поэтому излишне укрупнять такие объекты нецелесообразно. Чтобы проиллюстрировать применение очередей, создадим небольшую поисковую систему для текстового контента, которая хранит все соответствующие записи в оперативной памяти.

Данная поисковая система выполняет сканирование всех файлов в текущем каталоге в параллельном режиме. Для каждого ядра центрального процессора выстраивается свой собственный процесс. Каждому процессу дается указание загрузить ряд файлов в оперативную память. Итак, рассмотрим функцию, выполняющую загрузку и поиск:

```python
from pathlib import Path
from typing import List, Iterator, Optional, Union, TYPE_CHECKING

if TYPE_CHECKING:
    Query_Q = Queue[Union[str, None]]
    Result_Q = Queue[List[str]]


def search(paths: list[Path], query_q: Query_Q, results_q: Result_Q) -> None:
    print(f"PID: {os.getpid()}, paths {len(paths)}")
    lines: list[str] = []
    for path in paths:
        lines.extend(l.rstrip() for l in path.read_text().splitlines())

    while True:
        if (query_text := query_q.get()) is None:
            break
        results = [l for l in lines if query_text in l]
        results_q.put(results)
```

Следует помнить, что функция **`search()`** запускается не в основном процессе, создавшем очереди, а в отдельно взятом (фактически же она запускается в отдельно взятых процессах **`cpu_count()`**). Каждый из этих процессов запускается со списком объектов **`pathlib.Path`** и двумя объектами **`multiprocessing.Queue`**; один служит для входящих запросов, а другой - для отправки исходящих результатов. Эти очереди автоматически переводят имеющиеся в них данные в рiсklе-формат и передают их по каналу в подпроцесс. Установка двух таких очередей выполняется в основном процессе, после чего они передаются по каналу в функцию поиска внутри дочерних процессов.

==Аннотации типов отражают способ возможного получения инструментальным средством `mуру` подробной информации о структуре данных в каждой очереди. Когда **`TYPE_CHECKING`** имеет значение **`True`**, это означает включение **`mуру`** в работу и требование с его стороны достаточного объема сведений, позволяющих убедиться, что имеющиеся в приложении объекты соответствуют описаниям объектов в каждой из очередей. Когда **`ТYPE_CHECKING`** имеет значение **`False`**, это означает применение для приложений обычной среды выполнения и невозможность предоставления структурных подробностей выстроенных в очереди сообщений.==

Функция **`search()`** выполняет две разные задачи.

1. При запуске функции открываются все файлы, представленные в списке объектов **`Path`**, и считывается их содержимое. Каждая строка текста в этих файлах накапливается в списке строк **`lines`**. У подобной подготовки данных относительно затратный характер, но она выполняется всего лишь раз.
2. Инструкция **`while`** задает основной цикл обработки событий с целью проведения поиска. В этом цикле для получения запроса из своей очереди используется метод **`query_q.get()`** , после чего выполняется поиск строк. Для постановки ответа в очередь результатов в цикле используется метод **`results_q.put()`**.

В случае обработки на основе использования очереди задействуется типовой паттерн проектирования, имеющийся у инструкции **`while`**. Процесс получает из очереди значение, содержащее некую работу для выполнения, выполняет эту работу, а затем помещает результат в другую очередь. На этапы обработки и очереди можно разложить весьма большие и сложные задачи, позволяя таким образом проводить одновременное выполнение этапов и получать больше результатов за меньшее время. Описанный метод помогает также адаптировать этапы обработки и количество рабочих процессов под наиболее эффективный режим использования процессора. Основная часть приложения создает соответствующий пул рабочих процессов и их очереди. Воспользуемся шаблоном проектирования Фасад (для получения дополнительной информации [[Новые Паттерны Проектирования|«Новые паттерны проектирования»]]). Идея заключается в том, чтобы для объединения очередей и пула рабочих процессов в один объект определить класс **`DirectorySearch`**.

Получаемый в результате объект будет способен выстраивать очереди и рабочие процессы, после чего приложение сможет взаимодействовать с ними, отправляя запрос и получая ответы.

```python
from fnmatch import fnmatch
import os


class DirectorySearch:
    def __init__(self) -> None:
        self.query_queues: list[Query_Q]
        self.results_queue: Result_Q
        self.search_workers: list[Process]

    def setup_search(self, paths: list[Path], cpus: Optional[int] = None) -> None:
        if cpus is None:
            cpus = cpu_count()
        worker_paths = [paths[i::cpus] for i in range(cpus)]
        self.query_queues = [Queue() for p in range(cpus)]
        self.results_queue = Queue()

        self.search_workers = [
            Process(target=search, args=(paths, q, self.results_queue))
            for paths, q in zip(worker_paths, self.query_queues)
        ]
        for proc in self.search_workers:
            proc.start()

    def teardown_search(self) -> None:
        # Signal process termination
        for q in self.query_queues:
            q.put(None)

        for proc in self.search_workers:
            proc.join()

    def search(self, target: str) -> Iterator[str]:
        print(f"search queues={self.query_queues}")
        for q in self.query_queues:
            q.put(target)

        for i in range(len(self.query_queues)):
            for match in self.results_queue.get():
                yield match
```

Метод **`setup_search()`** подготавливает рабочие подпроцессы. Операция нарезки **`[i::cpus]`** позволяет разбить этот список на несколько равных частей. Если количество центральных процессоров равно 8, размер шага будет равен 8 и будут использоваться 8 различных значений смещения от 0 до 7. Также для отправки данных в каждый рабочий процесс создается список объектов **`Queue`**. И наконец, создается единая очередь результатов. Все это передается во все рабочие подпроцессы. Каждый из них может поставить данные в очередь, и они будут собираться в одно целое в основном процессе.

После создания очередей и запуска рабочих процессов метод **`search()`** предоставляет цель всем рабочим процессам одновременно. Теперь все они могут приступать к просмотру своих обособленных коллекций данных с целью выдачи ответов.

Поскольку поиск ведется в довольно большом количестве каталогов, чтобы найти все Раth-объекты **`*.ру`** в заданном базовом каталоге, используется функция-генератор **`all_source()`** . Функция для поиска всех исходных файлов выглядит следующим образом:

```python
def all_source(path: Path, pattern: str) -> Iterator[Path]:
    for root, dirs, files in os.walk(path):
        for skip in {".tox", ".mypy_cache", "__pycache__", ".idea"}:
            if skip in dirs:
                dirs.remove(skip)
        yield from (Path(root) / f for f in files if fnmatch(f,                            pattern))
```

Для проверки дерева каталогов с исключением файловых каталогов, заполненных ненужными нам файлами, функция **`all_source()`** использует функцию **`os.walk()`**. В этой функции для сопоставления имени файла с шаблонами подстановочных знаков, применяемых оболочкой Linux, используется модуль **`fnmatch`**. Чтобы, к примеру, найти все файлы с именами, заканчивающимися на **`.ру`**, может использоваться параметр шаблона **`'*.ру'`**. С помощью данного приема задается начальное значение методу **`setup_search()`** класса **`DirectorySearch`**.

Метод **`teardown_search()`** класса **`DirectorySearch`** помещает в каждую очередь специальное значение завершения. Не забывайте, что каждый рабочий процесс является отдельным процессом, выполняющим инструкцию **`while`** внутри функции **`search()`** и считывающим данные из очереди запросов. Когда он считывает объект **`None`**, происходит выход из инструкции **`while`** и из функции. Затем для сбора всех дочерних процессов с их попутной мягкой очисткой можно воспользоваться функцией **`join()`**. (Если не запустить **`join()`**, в некоторых дистрибутивах Linux могут остаться [[Зомби-процесс|зомби-процессы]], то есть дочерние процессы, не воссоединившиеся должным образом со своим родителем из-за его сбоя; они потребляют системные ресурсы и зачастую требуют перезагрузки компьютера.) Теперь давайте посмотрим на код, позволяющий провести поиск:

```python
from multiprocessing import Process, Queue, cpu_count
import time


if __name__ == "__main__":
    ds = DirectorySearch()
    base = Path.cwd().parent
    all_paths = list(all_source(base, "*.py"))
    ds.setup_search(all_paths)
    for target in ("import", "class", "def"):
        start = time.perf_counter()
        count = 0
        for line in ds.search(target):
            # print(line)
            count += 1
        milliseconds = 1000 * (time.perf_counter() - start)
        print(
            f"Found {count} {target!r} in {len(all_paths)} files "
            f"in {milliseconds:.3f}ms"
        )
    ds.teardown_search()
```

Этот код создает объект **`DirectorySearch`**, **`ds`**, и предоставляет все исходные пути, начиная с родителя текущего рабочего каталога, через выражение **`base = Path.cwd().parent`**. После того как рабочие процессы подготовлены, объект ds выполняет поиск нескольких распространенных строк: **`"import"`** , **`"class"`** и **`"def"`** . Обратите внимание на закомментированную инструкцию **`print(line)`**, осуществляющую вывод подходящих результатов. Интерес для нас все еще представляет производительность. В самом начале первое чтение файла занимает доли секунды. Но после того, как все файлы прочитаны, время поиска резко возрастает. На MacBookРго со 134 файлами исходного кода выводимая на экран информация выглядит так:

```shell
python src/directory search.py
PID: 36566, paths 17
PID: 36567, paths 17
PID: 36570, paths 17
PID: 36571, paths 17
PID: 36569, paths 17
PID: 36568, paths 17
PID: 36572, paths 16
PID: 36573, paths 16
Found 579 'import' in 134 files in 111.561ms
Found 832 'class' in 134 files in 1.010ms
Found 1138 'def' in 134 files in 1.224ms
```

Поиск слова *импорт* занял около 111 миллисекунд (0,111 секунды). А почему он выполнялся гораздо медленнее двух других поисков? Дело в том, что при помещении первого запроса в очередь функция **`search()`** все еще читала файлы. На производительность первого запроса повлияли однократные начальные затраты на загрузку содержимого файла в память. Следующие два запроса выполняются примерно по одной миллисекунде каждый. Это поразительно! На ноутбуке были выполнены почти 1 ООО поисков в секунду с помощью всего лишь нескольких строк кода на Python.

Приведенный пример использования очередей для снабжения данными сразу нескольких рабочих процессов представляет собой ту самую версию конструкции с одним узлом, которая может быть развита до распределенной системы. Представьте, что поисковые запросы отправляются сразу на несколько хост-компьютеров, а затем их результаты соединяются. А теперь представьте, что в центрах обработки данных Google имеется доступ к целому парку компьютеров, и тогда сможете понять, за счет чего они способны так быстро возвращать результаты поиска!

Здесь это рассматриваться не будет, но стоит отметить, что модуль **`multiprocessing`** включает в себя диспетчерский класс, благодаря которому из предыдущего кода могут быть исключены повторяющиеся фрагменты. Есть даже версия диспетчера **`multiprocessing.Manager`**, способная управлять подпроцессами в удаленных системах в целях создания простейшего распределенного приложения. Читатели, заинтересовавшиеся дальнейшим изучением этой темы, могут ознакомиться с документацией по возможностям многопроцессной обработки, предоставляемым в Руthоn-приложениях.

```python
from pytest import *
from unittest.mock import Mock, sentinel, call
import directory_search

@fixture
def mock_query_queue():
    return Mock(
        get=Mock(side_effect=["xyzzy", None])
    )

@fixture
def mock_result_queue():
    return Mock(
        put=Mock()
    )

@fixture
def mock_paths(tmp_path):
    f1 = tmp_path / "file1"
    f1.write_text("not in file1\n")
    f2 = tmp_path / "file2"
    f2.write_text("file2 contains xyzzy\n")
    return [f1, f2]


def test_search(mock_paths, mock_query_queue, mock_result_queue):
    directory_search.search(mock_paths, mock_query_queue, mock_result_queue)
    assert mock_query_queue.get.mock_calls == [call(), call()]
    assert mock_result_queue.put.mock_calls == [
        call(['file2 contains xyzzy'])
    ]


@fixture
def mock_directory(tmp_path):
    f1 = tmp_path / "file1.py"
    f1.write_text("# file1.py\n")
    d1 = tmp_path / ".tox"
    d1.mkdir()
    f2 = tmp_path / ".tox" / "file2.py"
    f2.write_text("# file2.py\n")
    return tmp_path

def test_all_source(mock_directory):
    files = list(directory_search.all_source(mock_directory, "*.py"))
    assert files == [
        mock_directory / "file1.py"
    ]


@fixture
def mock_queue(monkeypatch):
    mock_instance = Mock(
        name="mock Queue",
        put=Mock(),
        get=Mock(return_value=["line with text"])
    )
    mock_queue_class = Mock(
        return_value=mock_instance
    )
    monkeypatch.setattr(directory_search, "Queue", mock_queue_class)
    return mock_queue_class


@fixture
def mock_process(monkeypatch):
    mock_instance = Mock(
        name="mock Process",
        start=Mock(),
        join=Mock()
    )
    mock_process_class = Mock(
        return_value=mock_instance
    )
    monkeypatch.setattr(directory_search, "Process", mock_process_class)
    return mock_process_class

def test_directory_search(mock_queue, mock_process, mock_paths):
    ds_instance = directory_search.DirectorySearch()
    ds_instance.setup_search(mock_paths, cpus=2)

    assert mock_queue.mock_calls == [call(), call(), call()]
    assert mock_process.mock_calls == [
        call(
            target=directory_search.search,
            args=(mock_paths[0::2], mock_queue.return_value, mock_queue.return_value)
        ),
        call(
            target=directory_search.search,
            args=(mock_paths[1::2], mock_queue.return_value, mock_queue.return_value)
        )
    ]
    assert mock_process.return_value.start.mock_calls == [call(), call()]
    assert ds_instance.query_queues == [mock_queue.return_value, mock_queue.return_value]
    assert ds_instance.results_queue == mock_queue.return_value
    assert ds_instance.search_workers == [mock_process.return_value, mock_process.return_value ]

    result = list(ds_instance.search("text"))

    assert result == ['line with text', 'line with text']
    assert mock_queue.return_value.put.mock_calls == [call("text"), call("text")]
    assert mock_queue.return_value.get.mock_calls == [call(), call()]

    ds_instance.teardown_search()
    assert mock_queue.return_value.put.mock_calls == [call("text"), call("text"), call(None), call(None)]
    assert mock_process.return_value.join.mock_calls == [call(), call()]
```


#### Сложности, связанные с многопроцессной обработкой данных
---

Проблемы возникают не только при работе с потоками, но и при использовании многопроцессной обработки, и часть этих проблем уже была рассмотрена. Это и слишком затратный обмен данными между процессами, и, как уже упоминалось, необходимость сериализации объектов при любом взаимодействии процессов как посредством очереди, так и с помощью конвейеров операционной системы или даже совместно используемой памяти. На слишком объемную сериализацию может уходить основная часть времени. Решению проблемы могут помочь объекты, находящиеся в совместно используемой памяти, ограничивая потребности в сериализации за счет исходной настройки этой памяти. Наибольшей эффективности при многопроцессной обработке удается достичь в случае передачи между процессами относительно небольших объектов, в отношении каждого из которых необходимо проделать весьма существенный объем работы.

Совместно используемая память позволяет избежать затрат на многократно повторяемую сериализацию и десериализацию. На объекты Python, подлежащие совместному использованию, накладываются многочисленные ограничения. Совместно используемая память может повысить производительность, но также может привести и к усложнению объектов Python.

Еще одной серьезной проблемой многопроцессной обработки, как и в случае с потоками, является трудность определения того, в каком из процессов осуществляется доступ к переменной или к методу. При многопроцессной обработке рабочие процессы наследуют большое количество данных от родительского процесса. Но это не совместный доступ к данным, а получение их разовой копии. Дочерний процесс может получить копию отображения или список, после чего внести в объект изменения. А родительский процесс так и не увидит изменений, внесенных дочерним процессом.

Существенным преимуществом многопроцессных вычислений является абсолютная независимость процессов. Здесь, ввиду отсутствия совместно используемых данных, не требуется четкого управления блокировками. Кроме того, операционной системой внутренние ограничения на количество открытых файлов устанавливаются на уровне процессов, что позволяет иметь большое количество ресурсоемких процессов. При разработке приложений с прицелом на конкурентные вычисления основное внимание уделяется максимальному использованию центрального процессора для выполнения максимально возможного объема работы за минимально возможное время. Наличие великого множества вариантов всегда требует тщательного исследования решаемой задачи с целью выявления из множества доступных решений наиболее приемлемого для ее выполнения.

>[!info]
>Понятие конкурентной обработки слишком широкое, и выбрать какой то один подходящий на все случаи жизни способ ее реализации просто невозможно. Следует искать наилучшее решение для каждой отдельно взятой задачи. Тут очень важно создавать такой код, который бы легко поддавался корректировке, нас тройке и оптимизации.

Итак, мы рассмотрели два основных инструмента, обеспечивающих конкурентные вычисления в Python: потоки и процессы. ==Потоки существуют в рамках одного процесса операционной системы, совместно использующего память и другие ресурсы.== ==Процессы независимы друг от друга, из-за чего взаимодействие процессов неизбежно влечет за собой накладные расходы. Оба подхода соответствуют концепции объединения конкурирующих рабочих процессов, ожидающих своего запуска в работу и обеспечивающих результаты в некий непредсказуемый момент в будущем.== Эта абстракция доступных в будущем результатов и является тем, что формируется в рассматриваемом далее модуле **`coпcurreпt.futures`**.





## Фьючерсы
---

Пришло время освоить асинхронный способ реализации конкурентных вычислений. Концепция фьючерса, или обещания, - весьма удобная абстракция, предназначенная для описания работы в конкурентном режиме. **Фьючерс** ==- объект, который служит оболочкой для вызова функции.== Этот вызов выполняется в фоновом режиме, в потоке или в отдельном процессе. У объекта фьючерса **`future`** - есть методы для проверки завершенности вычисления и получения результатов. Можно провести аналогию с вычислением, результаты которого будут получены в будущем, что позволяет в ожидании этих результатов заниматься чем-то еще.

Дополнительную информацию ищите по адресу https://hub.packtpub.com/asynchronous-programming-futures-and-promises/.

Имеющийся в Python модуль **`concurrent.futures`** обеспечивает в зависимости от требуемого типа конкурентных вычислений либо многопроцессную обработку, **`multiprocessing`**, либо многопоточность, **`threading`**. Фьючерсы не в состоянии полностью решать проблему случайного изменения совместно используемого состояния, но их применение позволяет структурировать создаваемый код таким образом, чтобы было легче отследить причину возникновения проблемы.

==Фьючерсы могут помочь управлять границами между различными потоками или процессами.== Подобно пулу многопроцессной обработки, они оказываются незаменимы для взаимодействий по типу �вызов - ответ•, при которых обработка выполняется в другом потоке (или процессе), а затем в какой-то момент в будущем, то есть во фьючерсе (недаром он так и назван), можно будет запросить у этого фьючерса результат. Он выступает в качестве оболочки для многопроцессных пулов и пулов потоков, но при этом предоставляет более понятный API и стимулирует создание более читабельного кода.

Рассмотрим еще один пример посложнее: поиск и анализ файлов. В предыдущем разделе была реализована версия Linuх-команды **`grep`**. А теперь создадим простую версию команды **`find`**, включающую в себя более подробный анализ исходного кода Python. Начнем с аналитической части, поскольку она занимает центральное место в работе и ее нужно выполнять в конкурентном режиме:

```python
from __future__ import annotations
import argparse
import ast
from concurrent import futures
from fnmatch import fnmatch
import os
from pathlib import Path
import sys
import time
from typing import Iterator, NamedTuple


class ImportResult(NamedTuple):
    path: Path
    imports: set[str]

    @property
    def focus(self) -> bool:
        return "typing" in self.imports


class ImportVisitor(ast.NodeVisitor):
    def __init__(self) -> None:
        self.imports: set[str] = set()

    def visit_Import(self, node: ast.Import) -> None:
        # print(ast.dump(node))
        for alias in node.names:
            self.imports.add(alias.name)

    def visit_ImportFrom(self, node: ast.ImportFrom) -> None:
        # print(ast.dump(node))
        if node.module:
            self.imports.add(node.module)


def find_imports(path: Path) -> ImportResult:
    tree = ast.parse(path.read_text())
    iv = ImportVisitor()
    iv.visit(tree)
    return ImportResult(path, iv.imports)
```

Здесь присутствует определение сразу нескольких компонентов. Для начала определяется именованный кортеж **`ImportResult`**, связывающий вместе объект **`Path`** и набор строк. У него есть свойство **`focus`**, занимающееся поиском в наборе строк конкретной строки **`"typing"`**. Вскоре вы поймете, почему эта строка так важна.

Класс **`ImportVisitor`** создан с использованием модуля **`ast`**, входящего в стандартную библиотеку. [[Абстрактное синтаксическое дерево (AST)]] ==- это прошедший синтаксический анализ исходный код, взятый обычно из формального языка программирования.== Ведь в конечном счете сам код Python - всего лишь набор символов. AST для кода Python занимается группировкой текста в значимые инструкции и выражения, имена переменных и операторы, то есть во все синтаксические компоненты языка. У осмотрщика имеется способ осмотра проанализированного кода. В коде предоставлены переопределения для двух методов класса **`NodeVisitor`**, поэтому будут использоваться только два вида инструкций **`import:import х и from х import у`**. Подробности работы структуры данных каждого узла выходят за рамки данного примера, но в документации по модулю **`ast`** в стандартной библиотеке можно найти описание уникальной структуры каждой языковой конструкции Python.

Функция **`find_imports()`** считывает некий исходный код, анализирует код Python, просматривает инструкции **`import`**, а затем возвращает **`ImportResult`** с исходным путем **`Path`** и набором имен, найденных просмотрщиком. Во многих отношениях это куда рациональнее простого сопоставления паттерна для **`"import"`**. К примеру, при использовании **`ast.NodeVisitor`** будут пропущены комментарии и проигнорирован текст внутри символьных строковых литералов, то есть решатся две задачи, которые сложно было бы выполнить с применением регулярных выражений.

В функции **`find_imports()`** нет ничего особенного, но заметьте, что она не обращается ни к каким глобальным переменным. Все взаимодействие с внешней средой передается в функцию или возвращается из нее. Это не техническое требование, а, скорее, способ, позволяющий сохранить рассудок при программировании с применением фьючерсов.

Но нам ведь нужно обработать сотни файлов в десятках каталогов. Наилучший подход к ее решению заключается в одновременном запуске множества однотипных задач с заполнением ядер центрального процессора большим количеством вычислений.

```python
def main(base: Path = Path.cwd()) -> None:
    print(f"\n{base}")
    start = time.perf_counter()
    with futures.ThreadPoolExecutor(24) as pool:
        analyzers = [
            pool.submit(find_imports, path) for path in                                        all_source(base, "*.py")
        ]
        analyzed = (worker.result() for worker in                                         futures.as_completed(analyzers))
    for example in sorted(analyzed):
        print(
            f"{'->' if example.focus else '':2s} "
            f"{example.path.relative_to(base)} {example.imports}"
        )
    end = time.perf_counter()
    rate = 1000 * (end - start) / len(analyzers)
    print(f"Searched {len(analyzers)} files in {base} at                        {rate:.3f}ms/file")
```

Здесь используется та же функция **`all_source()`**, показанная ранее в данной главе, в подразделе «Очереди», требуется базовый каталог, с которого можно начать поиск, и паттерн, например, **`"*.ру"`** для поиска всех файлов с расширением `.ру`. Также здесь создан **`ThreadPoolExecutor`**, назначенный переменной pool, с двумя десятками рабочих потоков, и все они ожидают своей активизации. Список Futurе-объектов создается в объекте analyzers с помощью генератора списков, применяющего метод **`pool.submit()`** к функции поиска **`find_imports()`** и пути **`Path`** из выходных данных **`all_source()`**.

Потоки в пуле тут же приступят к работе над отправленным списком задач. Каждый поток, завершая свою работу, сохраняет результаты в объекте **`Future`** и берет на себя дополнительную нагрузку.

Тем временем на первом плане приложением используется выражение генератора для вычисления метода **`result()`** каждого Future-oбъeктa. Следует обратить внимание, что просмотр фьючерсов посетителем осуществляется с помощью генератора **`futures.as_completed()`**. Функция начинает предоставлять завершившие вычисления Futurе-объекты по мере их появления. Из этого следует, что результаты моrут следовать не в порядке их первоначального представления. Существуют и другие способы просмотра фьючерсов. На тот случай, если это важно, можно, например, подождать, пока завершатся вычисления во всех фьючерсах, а затем просмотреть их в том порядке, в котором они были отправлены.

Результаты извлекаются из каждого Future-oбъeктa. Из аннотаций типов можно понять, что это будет объект **`ImportResult`** с **`Path`** и набором строк, представляющим имена импортируемых модулей. Результаты можно отсортировать, чтобы файлы отображались в каком-то целесообразном порядке.

На MacBookPro обработка каждого файла занимает около 1 689 миллисекунд (0,001689 секунды); 24 отдельных потока легко вписываются в единый процесс, не перегружая операционную систему. Увеличение числа потоков существенно не влияет на время выполнения, то есть, предположительно, любые оставшиеся без внимания узкие места связаны не с конкурентными вычислениями, а с исходным сканированием дерева каталогов и созданием пула потоков.

А что можно сказать в отношении функции **`focus`** класса **`ImportResult`**? Чем так уж знаменателен модуль **`typing`**? Когда в процессе написания данной книги вышла новая версия `mуру`, нам пришлось просмотреть аннотации типов в каждой главе. При этом определенную помощь оказало разделение модулей на требующие тщательной проверки, с одной стороны, и не нуждающиеся в пересмотре - с другой.

И это все, что требуется для разработки приложения на основе использования фьючерсов с привязкой к операциям ввода-вывода. По сути, здесь применяются те же потоки или процессы API, которые уже рассматривались, но при этом предоставляется более понятный интерфейс и облегчается понимание границ между функциями, выполняемыми в конкурентном режиме (только не нужно пытаться из фьючерса получить доступ к глобальным переменным !).

Во многих приложениях модуль **`concurrent.futures`** является тем самым местом, с которого можно начать разработку кода на Python. Модули более низкого порядка **`threading`** и **`multiprocessin`** предлагают для весьма сложных случаев ряд дополнительных конструкций.

Применение **`run_in_executor()`** позволяет приложению для распределения всей работы между несколькими процессами или несколькими потоками использовать классы **`ProcessPoolExecutor`** или **`ThreadPoolExecutor`** модуля **`concurrent.futures`**. Тем самым обеспечивается более существенная гибкость в рамках весьма приглядного, эргономичного API.

Иногда в конкурентных вычислениях нет никакой реальной нужды. В других же случаях просто нужна возможность переключения между ожиданием доступности данных и вычислениями. Способностью чередования обработки в рамках одного и того же потока обладают асинхронные функции Python, в числе которых функции, входящие в состав модуля **`asyncio`**. Именно такой вариант конкурентных вычислений и будет темой следующего раздела.





## Библиотека **`AsyncIO`**
---

**`AsyncIO`** ==является современной библиотекой программирования конкурентных вычислений на Python.== В ней сочетаются концепция фьючерсов и цикл обработки событий с сопрограммами. Результат элегантен и прост для понимания, насколько это вообще возможно при написании адаптивных приложений, которые, как представляется, не тратят попусту время на ожидание входных данных.

С позиции работы с **аsуnс**-функциями Python ==сопрограмма== ==- это функция, ожидающая наступления того или иного события, способная также предоставлять события другим сопрограммам.== ==Сопрограммы в Python реализуются с применением выражения== **`async def`**. Функция с **`async`** должна работать в контексте **цикла обработки событий**, который переключает управление между сопрограммами, ожидающими событий. ==Нам предстоит рассмотреть несколько конструкций Python, использующих выражения ожидания== **await**, чтобы изучить ситуации, где цикл обработки событий может переключаться на выполнение другой аsуnс-функции.

Крайне важно понимать, что аsуnс-операции чередуются и, как правило, не выполняются в параллельном режиме. Максимум одна сопрограмма находится в режиме управления и обработки, а все остальные пребывают в ожидании наступления события. Идея чередования описывается как **совместная многозадачность**: приложение может обрабатывать данные, ожидая при этом поступления следующего сообщения с запросом. По мере изменения доступности данных цикл обработки событий может передавать управление одной из ожидающих сопрограмм.

**`AsyncIO`** ориентирован на сетевой ввод-вывод. Большинство сетевых приложений, особенно выполняемых на стороне сервера, тратят на ожидание поступления данных из сети слишком много времени. **`AsyncIO`** помогает добиться большей эффективности по сравнению с обработкой запросов каждого клиента в отдельном потоке, допуская работу некоторых потоков, пока другие будут находиться в режиме ожидания. Проблема в том, что потоки потребляют память и другие вычислительные ресурсы. **`AsyncIO`** использует сопрограммы для чередования циклов обработки при открытии доступа к данным.

Диспетчеризация потоков зависит от запросов операционной системы, выполняемых потоком (и в некоторой степени от чередования потоков при глобальной блокировке интерпретатора - GIL). Диспетчеризация процессов зависит от работы общего диспетчера операционной системы. Диспетчеризация как потоков, так и процессов является вытесняющей - работа потока (или процесса) может быть прервана, чтобы позволить управлять процессором другому потоку или процессу с более высоким приоритетом. Это означает, что диспетчеризация потоков непредсказуема и блокировки играют весьма важную роль, если совместно используемый ресурс собираются обновить сразу несколько потоков. Общие блокировки на уровне операционной системы нужны в том случае, если два процесса хотят обновить совместно используемый ресурс операционной системы, например файл. В отличие от потоков и процессов сопрограммы AsyncIO не являются вытесняющими, поскольку они передают управление друг другу в определенные моменты обработки явным образом, устраняя необходимость в явной блокировке совместно используемых ресурсов.

Библиотека **`asyncio`** предоставляет встроенный *цикл обработки событий*, управляющий чередованием выполнения запущенных сопрограмм. Следует все же учесть, что цикл обработки событий сопряжен с определенными издержками. Когда запускается код в аsуnс-задаче в цикле обработки событий, этот код должен возвращать управление немедленно, не осуществляя блокировку ни на вводе-выводе, ни на длительных вычислениях. При написании своего собственного кода это обстоятельство особой роли не играет, но означает, что любая стандартная библиотека или сторонние функции, блокирующие ввод-вывод, должны быть заключены в функцию **`async def`**, способную корректно обрабатывать ожидание.

При работе с **`asyncio`** приложение будет создаваться в виде набора сопрограмм, в которых для чередования управления через цикл обработки событий используется синтаксис **`async`** и **`await`**. При этом работа основной программы верхнего уровня сводится всего лишь к запуску цикла обработки событий, позволяющего затем сопрограммам передавать управление в обе стороны, чередуя ожидание и работу.




### **`AsyncIO`** в действии
---

Каноническим примером блокирующей функции является вызов **`time.sleep()`**. Вызвать функцию **`sleep()`** модуля **`time`** напрямую невозможно, поскольку это привело бы к перехвату управления и остановке цикла обработки событий. В коде ниже будет использоваться версия **`sleep()`**, имеющаяся в модуле **`asyncio`**. Применяемый в выражении await цикл обработки событий может в ожидании завершения **`sleep()`** чередовать данную работу с выполнением другой сопрограммы. Чтобы проиллюстрировать основы цикла обработки событий **AsyncIO**, воспользуемся асинхронной версией этого вызова:

```python
import asyncio
import random


async def random_sleep(counter: float) -> None:
    delay = random.random() * 5
    print(f"{counter} sleeps for {delay:.2f} seconds")
    await asyncio.sleep(delay)
    print(f"{counter} awakens, refreshed")


async def sleepers(how_many: int = 5) -> None:
    print(f"Creating {how_many} tasks")
    tasks = [asyncio.create_task(random_sleep(i)) for i in                         range(how_many)]
    print(f"Waiting for {how_many} tasks")
    await asyncio.gather(*tasks)


if __name__ == "__main__":
    asyncio.run(sleepers(5))
    print("Done with the sleepers")
```

В этом примере рассматриваются несколько особенностей **АsуnсIО** программирования. Общая обработка запускается функцией **`asyncio.run()`**. В результате запускается цикл обработки событий, выполняющий сопрограмму **`sleepers()`**. Внутри сопрограммы **`sleepers()`** создается несколько отдельно взятых задач, являющихся экземплярами сопрограммы **`random_sleep()`** с заданным значением аргумента. Функция **`random_sleep()`** использует **`asyncio.sleep()`** для имитации продолжительно выполняющегося запроса.

Поскольку все это создано с использованием функций, определяемых с помощью **`async def`** и выражения **`await`**, охватывающего **`asyncio.sleep()`**, выполнение функций **`random_sleep()`** и общей функции **`sleepers()`** чередуется. Притом что запросы **`random_sleep()`** запускаются в порядке значения их параметра **`counter`**, они завершаются в совершенно ином порядке.

Рассмотрим следующий пример:

```powershell
Creating 5 tasks
Waiting for 5 tasks      
0 sleeps for 1.06 seconds
1 sleeps for 0.03 seconds
2 sleeps for 4.70 seconds
3 sleeps for 2.38 seconds
4 sleeps for 1.20 seconds
1 awekens, refreshed
0 awekens, refreshed
4 awekens, refreshed
3 awekens, refreshed
2 awekens, refreshed
Done with the sleepers
```

Здесь видно, что самое короткое время ожидания было у функции **`random_sleep()`** со значением счетчика **`counter`**, равным 1, и ей первой было передано управление, когда завершилось выполнение выражения **`await asyncio.sleep()`**. Порядок пробуждения основан строго на произвольном интервале ожидания и способности цикла обработки событий передавать управление от сопрограммы к сопрограмме.

Асинхронным программистам не требуются излишние знания о том, что происходит внутри функции **`run()`**, но следует иметь в виду, что в ней многое делается для отслеживания, какая из сопрограмм пребывает в ожидании, а какая должна иметь управление в текущий момент времени.\

==В данном контексте задача - это объект, порядок диспетчеризации которого в цикле обработки событий известен **`asyncio`**. К таким объектам относятся:==

- сопрограммы, определенные с помощью инструкции **`async def`**;
- объекты **`asyncio.Future`**. Они практически идентичны уже упомянутым в предыдущем разделе **`concurrent.futures`**, но предназначены для использования с **`asyncio`**;
- любой объект, допускающий ожидание, то есть объект с функцией **`__аwаit__()`**.

В приведенном примере все задачи являются сопрограммами. Еще несколько задач будут показаны в последующих примерах.

Присмотритесь повнимательнее к данной сопрограмме **`sleepers()`**. Сначала в ней создаются экземпляры сопрограммы **`random_sleep()`**. Каждый из них охвачен вызовом **`asyncio.create_task()`**, который добавляет их в качестве фьючерсов в очередь задач цикла, чтобы при возвращении управления в цикл они могли выполняться и запускаться немедленно.

Управление возвращается в цикл обработки событий при каждом вызове **`await`**. В данном случае вызывается **`awaitasyncio.gather()`**, ==чтобы передавать управление другим сопрограммам до тех пор, пока не будут завершены все задачи.==

Каждая из сопрограмм **`random_sleep()`** выводит на экран начальное сообщение, затем возвращает управление циклу обработки событий на определенный промежуток времени, используя свои собственные вызовы **`await`**. Когда переход в спящий режим завершен, цикл обработки событий передает управление соответствующей задаче **`random_sleep()`**, которая перед возвратом управления выводит свое сообщение о пробуждении.

Ключевое слово **`async`** действует как документация, уведомляющая интерпретатор Python (и программиста) о том, что сопрограмма содержит вызовы **`await`**. Оно также выполняет работу по подготовке сопрограммы к запуску в цикле обработки событий. Его поведение во многом напоминает поведение декоратора, и фактически еще в Python 3.4 оно было реализовано в виде декоратора **`@asyncio.coroutine`**.



#### Чтение фьючерса AsyncIO
---

Сопрограмма **AsyncIO** последовательно выполняет каждую строку кода до тех пор, пока не встретит выражение **`await`**. После этого она возвращает управление циклу обработки событий. Затем цикл обработки событий выполняет любые другие готовые к запуску задачи, включая и ту, которую ожидала исходная сопрограмма. При каждом завершении дочерней задачи цикл обработки событий возвращает результат в сопрограмму, чтобы она могла продолжить выполнение до встречи с другим выражением ожидания **`await`** или до окончания работы и возвращения управления во внешнюю задачу.

Это позволяет создавать код, выполняемый синхронно до тех пор, пока не возникнет явная потребность в каком-либо ожидании. В результате удается избежать ничем не определяемого поведения потоков и не требуется слишком сильно беспокоиться о совместно используемом состоянии.

>[!info]
>Ограничение доступа к совместно используемому состоянию - вполне себе здравая мысль: философский принцип «не делиться ничем» способен уберечь от массы серьезных ошибок, возникающих из-за трудно прогнозируемых сроков и последовательностей выполнения чередующихся операций.
>
 Диспетчеры операционной системы следует представлять себе в виде преднамеренного и порочного зла; они будут зловредно (каким-то непонятным образом) находить и выбирать среди процессов, потоков или сопрограмм наихудшую возможную последовательность операций.

Реальная ценность **AsyncIО** заключается в открываемой нам возможности собирать логические разделы кода вместе внутри одной сопрограммы даже в случае ожидания завершения другой работы в каком-либо другом месте. Вот конкретный пример: даже притом что вызов await **`asyncio.sleep`** в сопрограмме **`random_sleep()`** позволяет много чему происходить внутри цикла обработки событий, сама сопрограмма выглядит так, будто она все делает строго по порядку. Вывод: описанная возможность считывать связанные фрагменты асинхронного кода, не беспокоясь о механизме, ожидающем завершения задач, и является основным преимуществом использования модуля **AsyncIO**.



#### **AsyncIO** для работы в сети
---

Модуль **AsyncIO** был специально разработан для использования с сетевыми сокетами, поэтому сейчас займемся тем, что с помощью модуля **`asyncio`** создадим реализацию серверной программы. Помнится, в [[Тестирование Объектно-Ориентированных Программ]] нами была создана довольно непростая серверная программа для перехвата записей журнала, отправляемых одним процессом другому процессу с применением сокетов. Тогда она приводилась в качестве примера сложного ресурса, который нам не хотелось настраивать и отключать для каждого теста.

А теперь этот пример будет переписан с целью создания на основе **`asyncio`** сервера, способного обрабатывать запросы от сравнительно большого числа клиентов. Возможности этого модуля раскроются благодаря множеству сопрограмм, и все они будут ожидать поступления регистрационных записей. При поступлении записи одна сопрограмма может сохранить ее, выполнив ряд вычислений, в то время как остальные сопрограммы будут находиться в режиме ожидания.

В [[Тестирование Объектно-Ориентированных Программ]] наш интерес заключался в написании теста для интеграции процесса сбора регистрационных записей с помощью отдельно взятых процессов клиентского приложения, занимающихся журнальными записями. При этом выстраивались схемы взаимоотношений, показанные на **рис. 14.1.**

Процесс сборщика регистрационных записей создает сервер сокетов для ожидания подключений от всех клиентских приложений. Каждым из клиентских приложений используется метод **`logging.SocketHandler`**, направляющий регистрационные сообщения на ожидающий сервер. Сервер собирает сообщения и записывает их в единый центральный файл журнала.

Этот тест был основан на примере, приведенном в [[Общие Паттерны Проектирования]] и пострадавшем из-за слабой реализации. Чтобы не усложнять материал, мы сделали так, что сервер журналов работал в каждый момент времени только с одним клиентским приложением. А сейчас пришло время вернуться к идее сервера, осуществляющего сбор регистрационных сообщений. Усовершенствованная реализация станет обрабатывать очень большое количество одновременно обращающихся клиентов, поскольку в ней будут использоваться методы **AsyncIO**.

>![[Рис. 14.1. Сборщик регистрационных записей в облаке.jpg]]
>**Рис. 14.1.** Сборщик регистрационных записей в облаке

Центральной частью этой конструкции является сопрограмма, считывающая регистрационные записи из сокета. В перечне ее действий будет ожидание байтов, составляющих заголовок, а затем декодирование заголовка для вычисления размера полезных данных. Сопрограмма считывает нужное количество байтов, составляющих полезные данные регистрационного сообщения, а затем использует отдельную сопрограмму для обработки полезных данных. Функция **`log_catcher()`** имеет следующий вид:

```python
import asyncio
import asyncio.exceptions
import json
from pathlib import Path
from typing import TextIO, Any
import pickle
import signal
import struct
import sys


SIZE_FORMAT = ">L"
SIZE_BYTES = struct.calcsize(SIZE_FORMAT)


async def log_catcher(
    reader: asyncio.StreamReader, writer: asyncio.StreamWriter
) -> None:
    count = 0
    client_socket = writer.get_extra_info("socket")
    size_header = await reader.read(SIZE_BYTES)
    while size_header:
        payload_size = struct.unpack(SIZE_FORMAT, size_header)
        bytes_payload = await reader.read(payload_size[0])
        await log_writer(bytes_payload)
        count += 1
        size_header = await reader.read(SIZE_BYTES)
    print(f"From {client_socket.getpeername()}: {count} lines")
```

В данном варианте функции **`log_catcher()`** реализуется протокол, используемый классом **`SocketHandler`** модуля **`logging`**. Каждая регистрационная запись представляет собой блок байтов, который можно разбить на заголовок и полезные данные. Чтобы получить размер сообщения, следующего за заголовком, нужно прочитать первые несколько байтов, сохраненных в **`size_header`**. Как только будет получен размер, можно будет дождаться поступления байтов полезных данных. Поскольку оба чтения являются аwаit-выражениями, пока данная функция ожидает поступления байтов заголовка и полезных данных, работают другие сопрограммы.

Функция **`log_catcher()`** вызывается сервером, предоставляющим сопрограмму с **`StreamReader`** и **`StreamWriter`**. Эти два объекта служат оболочкой для пары сокетов, созданных по протоколу [[TCP IP|ТСР/IP]]. Объект, считывающий поток данных, **`StreamReader`**, и объект, который записывает поток данных, **`StreamWriter`**, являются, собственно, объектами с поддержкой асинхронности, позволяющими использовать **`await`** при ожидании считывания байтов от клиента.

В рассматриваемой версии программы функция **`log_catcher()`** ожидает данных сокета, затем предоставляет данные другой сопрограмме, **`log_writer()`** , для преобразования и записи данных. Задача функции **`log_catcher()`** заключается в длительном ожидании с последующей передачей данных от метода считывания методу записи; кроме этого, в ней производятся внутренние вычисления с целью подсчета количества сообщений от клиента. Увеличение значения счетчика не такая уж великая, но все же работа, которую можно выполнить в ожидании поступления данных.

Функция **`serialize()`** и сопрограмма **`log_writer()`** для преобразования регистрационных записей в формат [[JSON]] и их записи в файл имеют следующий вид:

```python
TARGET: TextIO
LINE_COUNT = 0


def serialize(bytes_payload: bytes) -> str:
    object_payload = pickle.loads(bytes_payload)
    text_message = json.dumps(object_payload)
    TARGET.write(text_message)
    TARGET.write("\n")
    return text_message


async def log_writer(bytes_payload: bytes) -> None:
    global LINE_COUNT
    LINE_COUNT += 1
    result = await asyncio.to_thread(serialize, bytes_payload)
```

Функция **`serialize()`** нуждается в наличии открытого файла, **`TARGEТ`**, в который ведется запись регистрационных сообщений. Об открытии (и закрытии) файла необходимо позаботиться в каком-то другом месте приложения, соответствующие операции будут рассмотрены чуть позже. Функция **`serialize()`** используется сопрограммой **`log_writer()`**. Поскольку **`log_writer()`** является аsуnс-сопрограммой, пока она будет вести запись, друmе сопрограммы будут дожидаться предоставления им возможности чтения и декодирования входных сообщений.

Функция **`serialize()`** действительно выполняет весьма существенный объем вычислений. В этом кроется довольно серьезная проблема. Операция записи в файл может быть заблокирована, тогда она зависает в ожидании завершения некой работы, выполняемой операционной системой. Запись на диск означает передачу работы дисковому устройству и ожидание, пока устройство не просигналит о завершении операции записи. Хотя микросекунда на запись строки данных длиной 1 ООО символов может показаться величиной крайне малой, для процессора это целая вечность. Следовательно, все файловые операции будут блокировать свой поток в ожидании завершения операции. Чтобы выстроить в основном потоке корректное взаимодействие с другими сопрограммами, работа по блокировке поручается отдельно взятому потоку. Именно поэтому сопрограмма **`log_writer()`** использует для выделения данной работы в автономный поток функцию **`asyncio.to_thread()`**.

Поскольку сопрограмма **`log_writer()`** использует в этом автономном потоке await, она возвращает управление циклу обработки событий, пока поток ожидает завершения записи. Это корректное ожидание позволяет другим сопрограммам работать, пока сопрограмма **`log_writer()`** ожидает завершения работы функции **`serialize()`**.

В отдельно взятый поток передавались два вида работы:

- операции, требующие больших вычислительных затрат. Это относится к операциям **`pickle.loads()`** и **`json.dumps()`**;
- блокирующие операции операционной системы. В приведенном примере это операция **`TARGEТ.write()`**. К блокирующим операциям относится большинство запросов операционной системы, включая файловые операции. К ним не относятся операции, касающиеся различных сетевых потоков данных, которые уже являются частью модуля **`asyncio`**. Как было показано в приведенной выше функции **`log_catcher()`**, потоки уже являются корректными пользователями цикла обработки событий.

Технология передачи работы потоку позволяет убедиться, что цикл обработки событий тратит на ожидание максимально возможное время. Если какое-либо событие ожидается всеми сопрограммами, то реакция на происходящее дальше будет по возможности самой быстрой. Этот принцип множества ожидающих потоков является ключевым принципом корректного обслуживания.

Применение глобальной переменной **`LINE_COUNТ`** у кого-то может вызвать удивление. Напомним, что в предыдущих разделах уже приводились страшилки о последствиях одновременного обновления совместно используемой переменной сразу несколькими потоками. С **`asyncio`** вытеснение потоков отсутствует. И поскольку каждая сопрограмма для передачи управления другим сопрограммам через цикл обработки событий использует явные запросы ожидания, значение этой переменной можно обновить в сопрограмме **`log_writer()`**, зная, что изменение состояния в среде всех сопрограмм будет фактически атомарным, то есть иметь характер ни с кем не разделяемого обновления.

Чтобы придать примеру завершенный вид, приведем код блока импортирования:

```python
import asyncio
import asyncio.exceptions
import json
from pathlib import Path
from typing import TextIO, Any
import pickle
import signal
import struct
import sys
```

А вот так выглядит код высокоуровневого диспетчера, запускающего данный сервис:

```python
server: asyncio.AbstractServer


async def main(host: str, port: int) -> None:
    global server
    server = await asyncio.start_server(
        log_catcher,
        host=host,
        port=port,
    )

    if sys.platform != "win32":
        loop = asyncio.get_running_loop()
        loop.add_signal_handler(signal.SIGTERM, server.close)

    if server.sockets:
        addr = server.sockets[0].getsockname()
        print(f"Serving on {addr}")
    else:
        raise ValueError("Failed to create server")

    async with server:
        await server.serve_forever()
```

В функции **`main()`** имеется весьма элегантный способ автоматического создания новых объектов **`asyncio.Task`** для каждого сетевого подключения. Функция **`asyncio.start_server()`** отслеживает входящие соединения с сокетами по заданному адресу хоста и номеру порта. Для каждого подключения она с помощью сопрограммы **`log_catcher()`** создает новый экземпляр задачи **`Task`**, добавляемый в коллекцию сопрограмм цикла обработки событий. Как только сервер запущен, функция **`main()`** открывает ему возможность бесконечного предоставления услуг, для чего используется серверный метод **`serve_forever()`**.

Метод цикла **`add_signal_handler()`** нуждается в дополнительном пояснении. В операционных системах, отличных от Windows, процесс завершается по сигналу операционной системы. Сигналы имеют небольшие числовые идентификаторы и символьные имена. К примеру, у сигнала завершения имеется цифровой код, равный 15, и имя **`signal.SIGTERM`**. Когда родительским процессом завершается дочерний процесс, посылается этот сигнал. Если ничего не предпринимать, то этот сигнал просто остановит интерпретатор Python. Нажатие комбинации клавиш `Ctrl+C` становится сигналом **`SIGINT`**, который приводит к тому, что Python выдаст исключение **`KeyboardInterrupt`**.

Метод цикла **`add_signal_handler()`** позволяет проверять наличие входящих сигналов и обрабатывать эти сигналы как часть **АsуnсIО**-цикла. Нас не устраивает остановка работы с необработанным исключением. Следует завершить выполнение различных сопрограмм и разрешить нормально завершиться любым потокам записи, выполняющим функцию **`serialize()`**. С этой целью сигнал подключается к методу **`server.close()`**, что приводит к полному завершению процесса **`serve_forever()`**, позволяя при этом завершиться всем сопрограммам.

В Windows приходится работать вне цикла обработки AsyncIO. И для подключения низкоуровневых сигналов к функции, которая полностью завершит работу сервера, необходим следующий дополнительный код:

```python
if sys.platform == "win32":
    from types import FrameType

    def close_server(signum: int, frame: FrameType) -> None:
        # print(f"Signal {signum}")
        server.close()

    signal.signal(signal.SIGINT, close_server)
    signal.signal(signal.SIGTERM, close_server)
    signal.signal(signal.SIGABRT, close_server)
    signal.signal(signal.SIGBREAK, close_server)
```

Здесь определены три стандартных сигнала: **`SIGINT`**, **`SIGТERM`** и **`SIGABRT`** - и особый сигнал для Windows: **`SIGBREAK`**. Все они предназначены для закрытия сервера, завершения обработки запросов и завершения цикла обработки после окончания работы всех ожидающих выполнения сопрограмм.

Как уже было показано в предыдущем примере использования AsyncIO, основная программа также является весьма лаконичным способом запуска цикла обработки событий:

```python
if __name__ == "__main__":
    # These often have command-line or environment overrides
    HOST, PORT = "localhost", 18842

    with Path("one.log").open("w") as TARGET:
        try:
            if sys.platform == "win32":
                # https://github.com/encode/httpx/issues/914
                loop = asyncio.get_event_loop()
                loop.run_until_complete(main(HOST, PORT))
                loop.run_until_complete(asyncio.sleep(1))
                loop.close()
            else:
                asyncio.run(main(HOST, PORT))

        except (asyncio.exceptions.CancelledError, KeyboardInterrupt):
            ending = {"lines_collected": LINE_COUNT}
            print(ending)
            TARGET.write(json.dumps(ending) + "\n")
```

При ее запуске открывается файл и устанавливается значение глобальной переменной **`TARGET`**, которая используется функцией **`serialize()`**. Функция **`main()`** здесь задействуется для создания сервера, ожидающего подключения. Когда задача **`server_forever()`** отменяется с выдачей исключения **`CancelledError`** или **`Keyboardinterrupt`**, финальную итоговую строку можно поместить в файл журнала. Этой строкой подтверждается нормальное завершение всех операций и представляется доказательство пользователям, что ни одна строка не была потеряна.

Для работы под управлением Windows вместо более полноценного метода **`run()`** нужно воспользоваться методом **`run_until_complete()`**. Кроме этого, в цикл обработки событий следует поместить еще одну сопрограмму, **`asyncio.sleep()`**, позволяющую дождаться окончательной обработки от любых других сопрограмм. С практической точки зрения для анализа аргументов командной строки можно было бы воспользоваться модулем **`argparse`**. Возможно, для ограничения размеров файлов журналов стоило бы применить в **`log_writer()`** более сложный механизм обработки файлов.


##### Конструктивные соображения
---

Рассмотрим некоторые особенности создаваемой конструкции. Сначала сопрограмма **`log_writer()`** передает байты во внешний поток, выполняющий функцию **`serialize()`**, и получает данные из него. Это более рациональный подход, чем декодирование JSОN-формата в сопрограмме в основном потоке, поскольку относительно затратное по времени декодирование может происходить без остановки цикла обработки событий основного потока.

Вызов **`serialize()`** по своей сути является фьючерсом. Ранее в этой главе, в разделе "'Фьючерсы», было показано, что для использования **`concurrent.futures`** имеется несколько шаблонных строк. Но при работе с фьючерсами AsyncIO шаблоны практически отсутствуют! Когда используется выражение await **`asyncio.to_thread()`**, сопрограмма **`log_writer()`** заключает вызов функции во фьючерс, отправляемый исполнителю внутреннего пула потоков. После чего код может вернуться в цикл обработки событий до завершения фьючерса, позволяя основному потоку обрабатывать другие подключения, задачи или фьючерсы. Особую важность приобретает распределение блокирующих запросов ввода-вывода по отдельным потокам. Когда фьючерс выполнен, сопрограмма **`log_writer()`** может завершить ожидание и выполнить любую последующую обработку.

В сопрограмме **`main()`** используется функция **`start_server()`**, а сервер отслеживает запросы на подключение. Тем самым обеспечиваются специфичные для клиента АsуnсIО-потоки данных чтения и записи применительно к каждой задаче, созданной для обработки отдельно взятого подключения; задача послужит оболочкой для сопрограммы **`log_catcher()`**. Чтение из АsуnсIО-потока данных является потенциально блокирующим, поэтому его можно вызвать с помощью await. Это означает, что до начала поступления байтов будет корректное возвращение в цикл обработки событий.

Перечисленные обстоятельства могут поспособствовать анализу роста рабочей нагрузки внутри сервера. Изначально функция **`main()`** является единственной сопрограммой. Ею создается server, и теперь в коллекции ожидающих сопрограмм цикла обработки событий имеются **`main()`** и **`server`**. Как только устанавливается подключение, сервер создает новую задачу, и теперь цикл обработки событий содержит **`main()`**, **`server`** и экземпляр сопрограммы **`log_catcher()`**. Основную часть времени, прежде чем что-то сделать, все эти сопрограммы ожидают либо нового подключения к серверу, либо сообщения для **`log_catcher()`**. Как только приходит сообщение, оно декодируется и передается в **`log_writer()`**, и доступной становится еще одна сопрограмма. Что бы дальше ни происходило, приложение готово к ответу. Количество ожидающих сопрограмм ограничено доступной оперативной памятью, поэтому терпеливо ожидать выполнения своей работы может множество отдельно взятых сопрограмм.

В следующих разделах будет приведен краткий разбор приложения для ведения записей журналов, которое использует рассматриваемый сборщик регистрационных записей. Приложение не проделывает никакой полезной работы, но обладает способностью задействовать множество ядер на длительный период времени. Так вы сможете оценить возможную степень отзывчивости **АsуnсIО**-приложений.




### Демонстрация записи в журнал
---

Наше клиентское приложение - сборщик регистрационных записей ведет запись целой кучи сообщений и выполняет огромный объем вычислений. Чтобы понять, насколько приложение отзывчиво, для проведения его стресс-тестирования запустим сразу несколько его копий.

Приложение не использует **`asyncio`**, поскольку само по себе оно все-таки не что иное, как весьма надуманный демонстрационный пример интенсивной вычислительной работы с несколькими запросами ввода-вывода, послужившими для нее оболочкой. Согласно замыслу использование сопрограмм для выполнения запросов ввода-вывода с одновременным вычислением в рамках конкурентной обработки данных не имеет в этом примере никакого практического значения.

Созданное нами клиентское приложение применяет вариацию алгоритма *bogosort* к некоторым совершенно произвольным данным. Информацию об этом алгоритме сортировки ищите по адресу https://rosettacode.org/wiki/Sorting_algorithms/Вogosort. Практической ценностью алгоритм не обладает, но зато он предельно прост: в нем многократно анализируются всевозможные расстановки с целью поиска требуемой расстановки по возрастанию. Блок импортирования и абстрактный суперкласс **`Sorter`** для алгоритмов сортировки выглядят следующим образом:

```python
from __future__ import annotations
import abc
from itertools import permutations
import logging
import logging.handlers
import os
import random
import time
import sys
from typing import Iterable

logger = logging.getLogger(f"app_{os.getpid()}")


class Sorter(abc.ABC):
    def __init__(self) -> None:
        id = os.getpid()
        self.logger = logging.getLogger(f"app_{id}.                                          {self.__class__.__name__}")

    @abc.abstractmethod
    def sort(self, data: list[float]) -> list[float]:
        ...
```

Затем определяется конкретная реализация абстрактного класса **`Sorter`**:

```python
class BogoSort(Sorter):
    @staticmethod
    def is_ordered(data: tuple[float, ...]) -> bool:
        pairs: Iterable[tuple[float, float]] = zip(data, data[1:])
        return all(a <= b for a, b in pairs)

    def sort(self, data: list[float]) -> list[float]:
        self.logger.info("Sorting %d", len(data))
        start = time.perf_counter()

        ordering: tuple[float, ...] = tuple(data[:])
        permute_iter = permutations(data)
        steps = 0
        while not BogoSort.is_ordered(ordering):
            ordering = next(permute_iter)
            steps += 1

        duration = 1000 * (time.perf_counter() - start)
        self.logger.info(
            "Sorted %d items in %d steps, %.3f ms", len(data), steps,              duration
        )
        return list(ordering)
```

Метод **`is_ordered()`** класса **`BogoSort`** проверяет, правильно ли отсортирован список объектов. Метод **`sort()`** генерирует все перестановки данных в целях поиска расстановки, которая бы удовлетворяла ограничению, определяемому методом **`is_ordered()`**.

Следует заметить, что набор из **`n`** значений имеет **`n!`** перестановок, что говорит о вопиющей неэффективности данного алгоритма сортировки. Из 13 значений существует более шести миллиардов перестановок; большинству компьютеров для сортировки по порядку 13 элементов согласно данному алгоритму может потребоваться не один год.

Функция **`main()`** занимается сортировкой и записью в журнал нескольких регистрационных сообщений. Ею выполняется большой объем вычислений, при этом задействуются ресурсы центрального процессора, но не приносится практически никакой пользы. Программа **`main`** , которой можно воспользоваться для выполнения запросов к журналу, пока неэффективная сортировка тратит компьютерное время на обработку данных, выглядит следующим образом:

```python
def main(workload: int = 10, sorter: Sorter = BogoSort()) -> int:
    total = 0
    for i in range(workload):
        samples = random.randint(3, 10)
        data = [random.random() for _ in range(samples)]
        ordered = sorter.sort(data)
        total += samples
    return total


if __name__ == "__main__":
    LOG_HOST, LOG_PORT = "localhost", 18842
    socket_handler = logging.handlers.SocketHandler(LOG_HOST, LOG_PORT)
    stream_handler = logging.StreamHandler(sys.stderr)
    logging.basicConfig(handlers=[socket_handler, stream_handler],                             level=logging.INFO)

    start = time.perf_counter()
    workload = 10
    logger.info("sorting %d collections", workload)
    samples = main(workload, GnomeSort())
    end = time.perf_counter()
    logger.info("produced %d entries, taking %f s", workload * 2 + 2,                  end - start)

    logging.shutdown()
```

Сценарий верхнего уровня запускается путем создания экземпляра **`SocketHandler`**, который записывает регистрационное сообщение в показанный выше сервис сборщика сообщений. Экземпляр **`StreamHandler`** записывает сообщение в консоль. Оба объекта предоставляются в качестве обработчиков для всех определенных сервисов регистрации. После конфигурирования системы ведения регистрационных записей вызывается функция **`main()`** с произвольной рабочей нагрузкой.

На восьмиядерном MacBook Pro сценарий выполнялся с привлечением 128 рабочих процессов, и все они занимались совершенно неэффективной сортировкой произвольных чисел. Внутренней командой операционной системы под названием **`time`** рабочая нагрузка была обозначена в виде 700 % использования ядра, то есть семь из восьми ядер были заняты в полном объеме. И все же еще оставалось достаточно времени на обработку регистрационных сообщений, редактирование данного документа и воспроизведение музыки в фоновом режиме. При использовании более быстрого алгоритма сортировки были запущены 256 рабочих процессов, и примерно за 4,4 секунды сгенерированы 5632 регистрационных сообщения. Это повлекло за собой 1 280 транзакций в секунду, и все же по-прежнему использовалось только 628 % из доступных 800. У вас показатели могут получиться несколько иными. Похоже, при наличии рабочих нагрузок с интенсивной работой в сети AsyncIО прекрасно справляется с распределением драгоценного процессорного времени на сопрограмму с выполняемой работой и сводит к минимуму время, в течение которого потоки блокируются в ожидании выполнения какой-либо операции.

Важно отметить, что библиотека AsyncIO в большой степени ориентирована на использование сетевых ресурсов, включая сокеты, очереди и каналы операционной системы. Файловая система не является частью особой важности в модуле **`asyncio`** и поэтому требует для обработки (которая останется заблокированной до тех пор, пока файловая операция не будет завершена операционной системой) использования специально выделенного для нее пула потоков.

А сейчас немного отвлечемся и рассмотрим применение AsyncIО для написания клиентского приложения. Сервер здесь создаваться не будет, и цикл обработки событий будет использоваться для предоставления клиенту возможности обработки данных с высокой скоростью.



#### Использование **AsyncIO** клиентскими программами
---

Поскольку библиотека AsyncIO обладает способностью обрабатывать многие тысячи одновременных подключений, она широко применяется при реализации серверов. Но, являясь универсальной сетевой библиотекой, она также обеспечивает полную поддержку клиентских процессов. Это весьма важное обстоятельство, поскольку многие микросервисы зачастую выступают в качестве клиентов для других серверов.

Клиенты могут быть существенно проще серверов, поскольку их не нужно настраивать на ожидание входящих подключений. Функцией **`await asyncio.gather()`** можно воспользоваться для распределения большей части работы и для ожидания завершения обработки результатов.

Для этого может пригодиться метод **`asyncio.to_thread()`**, назначающий отдельно взятым потокам блокирующие запросы, позволяя тем самым основному потоку чередовать работу сопрограмм.

Можно также создавать отдельные задачи, которые чередуются с помощью цикла обработки событий. В этом случае сопрограммы, реализующие задачи, совместно занимаются диспетчеризацией чтения данных наряду с вычислениями, производимыми в отношении тех данных, которые уже были считаны.

В примере ниже для НТТР-запроса, лояльного к AsyncIO, используется библиотека `httpx`. Дополнительный пакет нужно будет установить с помощью команды `conda install https` (если в качестве диспетчера виртуальной среды используется `conda`) или команды `python -m pip install httpx`.

==Рассмотрим приложение для отправки запросов в службу погоды США, реализованное с использованием== `asyncio`. Сосредоточимся на прогнозируемых зонах, полезных для моряков в районе Чесапикского залива. И начнем с ряда определений:

```python
import asyncio
import httpx
import re
import time
from urllib.request import urlopen
from typing import Optional, NamedTuple


class Zone(NamedTuple):
    zone_name: str
    zone_code: str
    same_code: str  # Special Area Messaging Encoder

    @property
    def forecast_url(self) -> str:
        return (
            f"https://tgftp.nws.noaa.gov/data/forecasts"
            f"/marine/coastal/an/{self.zone_code.lower()}.txt"
        )
```

При наличии кортежа по имени **`Zone`** проанализируем каталог результатов морских прогнозов и создадим список экземпляров **`Zone`**, начинающийся со следующего:

```python
ZONES = [
    Zone("Chesapeake Bay from Pooles Island to Sandy Point, MD",                "ANZ531", "073531"),
    Zone("Chesapeake Bay from Sandy Point to North Beach, MD",                  "ANZ532", "073532"),
    Zone("Chesapeake Bay from North Beach to Drum Point, MD",                  "ANZ533", "073533"),
    Zone("Chesapeake Bay from Drum Point to Smith Point, VA",                  "ANZ534", "073534"),
    Zone("Tidal Potomac from Key Bridge to Indian Head, MD", "ANZ535",         "073535"),
    Zone("Tidal Potomac from Indian Head to Cobb Island, MD",                  "ANZ536", "073536"),
    Zone("Tidal Potomac from Cobb Island, MD to Smith Point, VA",               "ANZ537", "073537"),
    Zone("Patapsco River including Baltimore Harbor", "ANZ538",                  "073538"),
    Zone("Chester River to Queenstown MD", "ANZ539", "073539"),
    Zone("Eastern Bay", "ANZ540", "073540"),
    Zone(
        "Choptank River to Cambridge MD and the Little Choptank River",
        "ANZ541",
        "073541",
    ),
    Zone("Patuxent River to Broome’s Island MD", "ANZ542", "073542"),
    Zone(
        "Tangier Sound and the Inland Waters surrounding Bloodsworth            Island",
        "ANZ543",
        "073543",
    ),
]
```

В зависимости от желаемой области мореплавания могут понадобиться дополнительные или другие зоны.

Для описания предстоящей работы потребуется класс **`MarineWX`**. Это пример [[Общие Паттерны Проектирования#Паттерн Команда|паттерна Команда]], ==где каждый экземпляр является еще одним желаемым действием.== Для сбора данных из метеорологической службы в этом классе имеется метод **`run()`**:

```python
class MarineWX:
    advisory_pat = re.compile(r"\n\.\.\.(.*?)\.\.\.\n", re.M | re.S)

    def __init__(self, zone: Zone) -> None:
        super().__init__()
        self.zone = zone
        self.doc = ""

    async def run(self) -> None:
        """
        Blocking IO assigned to a task.
        with urlopen(self.zone.forecast_url) as stream:
            self.doc = stream.read().decode("UTF-8")
        """
        async with httpx.AsyncClient() as client:
            response = await client.get(self.zone.forecast_url)
        self.doc = response.text

    @property
    def advisory(self) -> str:
        if match := self.advisory_pat.search(self.doc):
            return match.group(1).replace("\n", " ")
        return ""

    def __repr__(self) -> str:
        return f"{self.zone.zone_name} {self.advisory}"
```

В этом примере метод **`run()`** посредством экземпляра класса **`AsyncClient`** из модуля **`httpx`** загружает из службы погоды текстовый документ. Обособленное свойство **`advisory()`** анализирует текст в поисках паттерна, которым помечается сообщение о морской погоде. Разделы документа метеорологической службы действительно помечены многоточиями и представляют собой текстовый блок и три точки. Система морских прогнозов разработана таким образом, чтобы обеспечить простой в обработке формат с небольшим объемом документа.

Пока во всем этом нет ничего уникального или примечательного. Нами определены хранилище информации о зоне и класс, собирающий для этой зоны данные. Важной частью здесь является функция **`main()`**. Она использует задачи AsyncIO для сбора как можно большего объема данных с наибольшей возможной скоростью.

```python
async def task_main() -> None:
    start = time.perf_counter()
    forecasts = [MarineWX(z) for z in ZONES]
    await asyncio.gather(*(asyncio.create_task(f.run()) for f in                               forecasts))
    for f in forecasts:
        print(f)
    print(
        f"Got {len(forecasts)} forecasts "
        f"in {time.perf_counter() - start:.3f} seconds"
    )


if __name__ == "__main__":
    asyncio.run(task_main())
```

При запуске в цикле событий **`asyncio`** функция **`main()`** запустит ряд задач, каждая из которых выполняет для другой зоны метод **`MarineWX.run()`**. Функция **`gather()`** ожидает, пока все эти задачи завершат работу, чтобы вернуть список фьючерсов.

В описанном случае результат фьючерса от созданных потоков фактически не нужен, нас интересуют изменения состояний, внесенные во все экземпляры **`MarineWX`**. Речь идет о коллекции Zоnе-объектов и подробной информации о прогнозе. Приведенный клиент работает довольно быстро - все 13 прогнозов были получены примерно за 300 миллисекунд.

Проект **`httpx`** поддерживает разбиение выборки необработанных данных и их обработку в отдельно взятых сопрограммах, позволяя тем самым чередовать ожидание данных с обработкой.

В этом разделе было затронуто большинство ключевых моментов **AsyncIO**, а в других - множество других примитивов организации конкурентных вычислений. ==**Конкурентность** - весьма сложная в реализации задача, и ни одно найденное решение не сможет подойти абсолютно для всех сценариев ее использования.==

Наиболее важной частью проектирования конкурентной системы является принятие решения о том, какой из доступных инструментов является приемлемым для решения конкретной поставленной задачи. Нами были рассмотрены преимущества и недостатки нескольких конкурентных систем, и теперь у вас уже имеется некоторое представление о том, какие из них являются наилучшим выбором для различных типов требований.

В следующем разделе затрагивается вопрос о возможной степени «выразительности> среды или пакета конкурентности. Будет показано решение классической задачи из области информатики с применением короткой, легкочитаемой прикладной программы, реализованной с помощью **`asyncio`**.





## Контрольная задача обедающих философов
---

У профессорско-преподавательского состава философского колледжа в старом приморском курортном городе (на Атлантическом побережье США) есть давняя традиция - по воскресным вечерам проводить совместный ужин. Еду готовят в кулинарии, принадлежащей шеф-повару Мо, но в меню неизменно присутствует блюдо со спагетти. Никто уже не помнит почему, но Мо считается великолепным шеф-поваром, который каждую неделю готовит спагетти по своему уникальному рецепту.

Философский факультет небольшой, и в нем работают всего лишь пять штатных преподавателей. К тому же они слишком бедны и могут позволить себе только пять вилок. Чтобы насладиться блюдом, каждому из сидящих за круглым обеденным столом философов нужны две вилки, и у каждого из них имеется доступ к двум ближайшим вилкам.

Данное требование о необходимости использования для еды двух вилок приводит к интересной проблеме конкурентной борьбы за ресурсы, суть которой показана на диаграмме (**рис. 14.2**).

В идеале философ, предположим, философ 4, заведующий отделением и к тому же онтолог, возьмет две ближайшие вилки, вилку 4 и вилку 0, необходимые ему для приема пищи. Поев, профессора кладут вилки на стол, чтобы немного пофилософствовать.

Но возникает проблема, ожидающая своего решения. Если каждый философ правша, то он протянет руку, возьмет вилку справа от себя и, будучи не в состоянии взять другую вилку, просто застынет. Система **зашла в тупик**, поскольку ни один из философов не может добыть ресурсы, чтобы поесть.

Одно из возможных решений могло бы вывести ситуацию из тупика за счет использования тайм-аута: если философ не может получить вторую вилку в течение нескольких секунд, он откладывает свою первую вилку, ждет несколько секунд и повторяет попытку. Если все они будут действовать в едином темпе, возникнет цикл, в котором каждый философ возьмет по одной вилке, подождет несколько секунд, отложит вилку и попробует все это проделать еще раз. Забавно, конечно, но признать это решение удовлетворительным не представляется возможным.

Более удачное решение - позволить одновременно сидеть за столом только четырем философам. Тогда была бы гарантия, что хотя бы один философ сможет взять две вилки и приступить к еде. Пока этот философ будет философствовать, вилки станут доступны двум его соседям. Кроме того, тот, кто первым закончит философствовать, может выйти из-за стола, позволяя пятому философу сесть за стол и присоединиться к разговору.

>![[Рис. 14.2. Обедающие философы.jpg]]
>**Рис. 14.2.** Обедающие философы

А как это будет выглядеть в коде? Познакомимся с философом, определяемым в виде сопрограммы:

```python
from __future__ import annotations
import asyncio
import collections
import random
from typing import List, DefaultDict, Iterator

FORKS: List[asyncio.Lock]


async def philosopher(id: int, footman: asyncio.Semaphore) -> tuple[int, float, float]:
    async with footman:
        async with FORKS[id], FORKS[(id + 1) % len(FORKS)]:
            eat_time = 1 + random.random()
            print(f"{id} eating")
            await asyncio.sleep(eat_time)
        think_time = 1 + random.random()
        print(f"{id} philosophizing")
        await asyncio.sleep(think_time)
    return id, eat_time, think_time
```

Каждому философу необходимо знать о следующих вещах:

- о его собственном уникальном идентификаторе. Это направит философов к двум ближайшим вилкам, которыми им разрешено воспользоваться;
- о **`Semaphore`** - лакее, усаживающем философов за стол. Задача лакея заключается в установке верхней границы количества людей, сидящих за столом, именно она позволяет избежать тупиковой ситуации;
- о глобальной коллекции вилок, представленной последовательностью экземпляров **`Lock`**, совместно используемой философами.

Время поедания философом спагетти конкретизируется возможностью приобретения и использования ресурсов. Все это реализовано с применением инструкций **`async with`**. Последовательность событий выглядит так, как это представлено в перечне ниже.

1. Философ получает от лакея **`Semaphore`** место за столом. Можем представить себе лакея с серебряным подносом, на котором лежат четыре жетона с надписью «можете приступать к еде». У философа, прежде чем он сможет сесть за стол, должен быть жетон. Выходя из-за стола, философ бросает свой жетон на поднос. Пятый философ с нетерпением ждет символического броска жетона от первого закончившего есть философа.
2. Философ берет вилку со своим идентификационным номером и следующую вилку с более высоким номером. Оператор, берущий числа по модулю, гарантирует, что подсчет «следующего» будет равен нулю: (4+1) % 5 равно 0.
3. Усевшись за стол и вооружившись двумя вилками, философ может насладиться поеданием спагетти. Мо часто использует для украшения оливки каламата и маринованные артишоки в виде сердечек, приводя своих клиентов в восхищение. Раз в месяц можно поесть немного анчоусов или сыра фета.
4. После еды философ высвобождает два ресурса в виде вилок. Но ужин еще не завершается. Как только философы кладут вилки на стол, они пускаются в философствования о жизни, о Вселенной и обо всем остальном.
5. И наконец, они освобождают свое место за столом, возвращая лакею жетон с надписью «можете приступать к еде>. им может завладеть философ, ожидающий своей очереди присоединиться к трапезе.

Если посмотреть на функцию **`philosopher()`**, можно заметить, что вилки являются глобальным ресурсом, а семафор - параметром. Нет никакой очевидной технической причины проводить различие между глобальной коллекцией Lосk-объектов, представляющих вилки, и **`Semaphore`**, фигурирующим в качестве параметра. Нами были показаны оба объекта, чтобы проиллюстрировать два самых распространенных варианта предоставления данных сопрограммам.

Блок импортирования данных для этого кода выглядит так:

```python
from __future__ import annotations
import asyncio
import collections
import random
from typing import List, DefaultDict, Iterator
```

А общая столовая организована следующим образом:

```python
async def main(faculty: int = 5, servings: int = 5) -> None:
    global FORKS
    FORKS = [asyncio.Lock() for i in range(faculty)]
    footman = asyncio.BoundedSemaphore(faculty - 1)
    for serving in range(servings):
        department = (philosopher(p, footman) for p in range(faculty))
        results = await asyncio.gather(*department)
        print(results)


if __name__ == "__main__":
    asyncio.run(main())
```

Сопрограмма **`main()`** создает коллекцию вилок, которая моделируется в виде Lосk-объектов, а ими может завладеть философ. Лакей представлен объектом **`BoundedSemaphore`** с ограничением на единицу меньше штатной численности преподавателей факультета, что позволяет избежать возникновения тупиковой ситуации. Для каждого обслуживания философский факультет представлен набором сопрограмм **`philosopher().Asyncio.gather()`** ожидает завершения работы всеми сопрограммами факультета (поедания спагетти и философствования).

Вся прелесть этой контрольной задачи заключается в демонстрации того, насколько интересно может быть описана обработка на данном языке программирования и в данной библиотеке. Применение пакета **`asyncio`** придает программному коду особую элегантность и позволяет ему выступать в качестве лаконичного и выразительного представления решения задачи.

Библиотекой **`concurrent.futures`** может использоваться явно заданный пул потоков **`ThreadPool`**. Это позволит приблизить код к такому же уровню ясности, но потребует несколько больших технических издержек.

Библиотеки **`threading`** и **`multiprocessing`** также могут быть непосредственно применены для обеспечения аналогичной реализации решения задачи. Работа с любой из них сопряжена с еще большими техническими издержками по сравнению с использованием библиотеки **`concurrent.futures`**. Если бы поедание спагетти или философствование включали в себя реальную вычислительную работу, а не просто приостановку, вы бы увидели, что многопроцессная версия завершилась быстрее всех, поскольку вычисления распределены между несколькими ядрами. Если бы поедание спагетти или философствование состояли в основном из ожидания завершения ввода-вывода, это было бы больше похоже на показанную здесь реализацию и использование **`asyncio`** или **`concurrent.futures`** с пулом потоков сработало бы неплохо.





## Ключевые моменты
---

Мы подробно рассмотрели многие темы, связанные с конкурентной обработкой данных в среде языка Python.

- Потоки, которые во многих случаях обладают преимуществом, связанным с их простотой. Соответствующие решения должны быть сбалансированы с учетом того, что глобальная блокировка интерпретатора, GIL, сильно мешает многопоточной работе с интенсивными вычислениями.
- Многопроцессная обработка, преимущество которой заключается в полноценном использовании всех ядер процессора. Выгода от ее использования должна быть сопоставлена и сбалансирована с издержками на межпроцессный обмен данными. Если применяется совместно используемая память, возникает сложность со способами кодировки и доступа к совместно используемым объектам.
- Применение модуля **`concurrent.futures`**, определяющего абстракцию - фьючерс. Она позволяет свести к минимуму различия с прикладным программированием, используемым для доступа к потокам или процессам. Благодаря этому упрощается переключение и выявление наиболее быстрого подхода.
- Работа с функциями async - await языка Python, поддерживаемыми пакетом AsyncIO. Поскольку эта тема относится к сопрограммам, настоящая параллельная обработка отсутствует; управляемые переключения между сопрограммами позволяют отдельно взятому потоку чередовать ожидание завершения ввода-вывода с вычислениями.
- Контрольная задача обедающих философов, отличающаяся относительной простотой, но с рядом интересных усложнений. Она может пригодиться для сравнения различных типов языковых функций и библиотек, применяемых для конкурентных вычислений.
- И возможно, самым важным наблюдением стало отсутствие тривиального универсального решения для организации конкурентной обработки данных. Самым главным является создание и количественная оценка различных решений с целью определения конструкции, которая наиболее эффективно будет использовать вычислительное оборудование.





## Резюме
---

В данной главе наше исследование объектно-ориентированного программирования завершается той самой темой, в которой ориентированность на объекты выражена не слишком отчетливо. Конкурентные вычисления - задача непростая, мы коснулись способов ее решения весьма поверхностно. И пусть базовые абстракции процессов и потоков операционной системы не предоставляют API, который хотя бы отдаленно был объектно-ориентированным, в Python предлагается целый ряд действительно неплохих объектно-ориентированных абстракций, относящихся к решаемой задаче. Объектно-ориентированный интерфейс к базовой технической стороне предоставляется пакетами **`threading`** и **`multiprocessing`**. А фьючерсы способны инкапсулировать множество разноплановых деталей в один объект. В AsyncIО используются объекты сопрограмм, позволяющие создаваемому коду выглядеть так, будто его части выполняются синхронно, скрывая тем самым неприглядные и сложные детали реализации за весьма простой абстракцией цикла.

Спасибо за прочтение четвертого издания книги «Объектно-ориентированный Python». Надеемся, вам понравился пройденный путь и теперь вы уже готовы приступить к внедрению объектно-ориентированных программных средств во все будущие проекты!