---
date of creation: 2024-07-03T16:52:00
tags:
  - Tests
  - Python/Tests
  - Python/OOP
  - Python/OOP/Tests
  - OOP/Python
  - Developing
  - Developing/Tests
  - IT/Python
  - Python/unittest
  - unittest
  - pytest
  - Tests/pytest
  - Tests/mock
  - Tests/unittest
  - Programming/Tests
  - Programming
read status: false
aliases:
  - Тесты ООП на Python
---
---
# Тестирование Объектно-Ориентированных Программ
2024-07-03



Опытные Руthоn-программисты считают тестирование одним из наиболее важных аспектов разработки программных средств. То, что данная глава расположена ближе к концу книги, вполне закономерно, поскольку в написании тестов вам пригодится весь ранее изученный материал. Здесь будут раскрыты следующие темы.

- **[[#Зачем вообще проводить тестирование|Важность модульного тестирования и разработки на основе тестирования.]]**
- **[[#Проведение модульного тестирования с помощью `unittest`|Модуль стандартной библиотеки unittest]]**.
- **[[#Проведение модульного тестирования с помощью `pytest`|Инструментальное средство pytest]]**.
- Модуль **`mock`**.
- Охват кода тестами.

А для начала рассмотрим некоторые основные причины, позволяющие осознать важность автоматизированного тестирования программных средств.





## Зачем вообще проводить тестирование
---

Важность тестирования кода не вызывает сомнений у многих программистов. Читатели, разделяющие их точку зрения, могут ограничиться беглым просмотром данного раздела и перейти к следующему, где уже гораздо конкретнее раскрывается порядок создания тестов в Python.

И вес же зачем проводить тестирование? Какой от него толк? Что будет, если от него отказаться? Для ответа на эти вопросы достаточно вспомнить историю создания вашего последнего программного кода. Неужели программа сразу же заработала как надо? И в ней не было никаких синтаксических ошибок? Не выявились никакие проблемы с логикой? В принципе, временами действительно может сразу получаться безупречный код. Но обычно на практике возникает некоторое количество очевидных синтаксических ошибок, требующих исправления, что указывает на высокую вероятность присутствия в коде не столь очевидных логических ошибок, также требующих исправления.

Чтобы убедиться в работоспособности кода, не нужен какой-то чисто формальный специальный тест. Достаточно провести самое простое тестирование: запустить программу и исправить ошибки. Наличие интерактивного интерпретатора Python и практически нулевое время компиляции позволяют быстро написать несколько строк кода, запустить программу и убедиться, что действия этих строк соответствуют ожиданиям.

Приемлемость такого подхода в начале работы над проектом со временем все больше снижается. Попытки изменения всего лишь нескольких строк кода могут совершенно непредвиденно повлиять на другие части программы, и без тестов невозможно будет выявить источник и причину неполадок. Любое переписывание кода или даже просто его легкая оптимизация могут вызвать серьезные проблемы. Кроме того, по мере роста объема программы увеличивается и число возможных путей прохода интерпретатора по ее коду, и примитивная ручная проверка работоспособности всех этих путей становится просто невозможной.

Убедить всех и, конечно, себя в работоспособности собственных программных средств можно путем создания автоматизированных тестов, являющихся программами, автоматически запускающими другие программы или их части с конкретными входными данными. Время работы этих программ, как правило, исчисляется секундами, но при этом охватывает гораздо больше потенциальных входных ситуаций, чем может принять во внимание один программист при каждом внесении каких-либо изменений.

>Функций программных средств, не поддающихся прогону при автоматизированном тестировании, просто не существует.
>				Extreme Programming Explained, [[Кент Бек]]

Необходимость создания тестов обусловливается четырьмя основными причинами:

- стремлением убедиться, что код работает в соответствии с замыслом разработчика;
- желанием удостовериться в сохранении работоспособности кода при внесении в него изменений;
- проверкой факта понимания разработчиком предъявленных требований;
- проверкой наличия у создаваемого кода поддерживаемого интерфейса.

Автоматизированные тесты при их наличии можно запускать при каждом изменении кода как на начальном этапе разработки, так и при выпусках его модифицированных версий. Тестирование позволяет подтвердить, что при добавлении или расширении функций программы ей не нанесен непреднамеренный урон.

У двух последних из вышеперечисленных пунктов имеются довольно интересные последствия. Создание тестов помогает разработать API, интерфейс или шаблон, принимаемый кодом. Таким образом, при неверном осмыслении требований создание теста позволяет выявить возникшее недоразумение. А с другой стороны, если есть сомнения, связанные с проектированием класса, можно создать тест, взаимодействующий с этим классом, получив при этом представление о наиболее естественном способе подтверждения работоспособности интерфейса. Фактически зачастую бывает полезным создать тесты еще до написания тестируемого кода.

Повышенное внимание к тестированию программного средства имеет и другие интересные последствия. Здесь будут рассмотрены три из них:

- использование тестов в качестве основы разработки;
- управление разнообразными целями тестирования;
- наличие согласованного шаблона для тестовых сценариев.

Начнем с использования тестов в качестве основы разработки.




## [[TDD|Разработка на основе тестирования]]
---

Принцип разработки на основе тестирования - *опережающее создание тестов*. При этом *непроверенный код заранее считается нерабочим*, а *непроверенным может быть только еще не написанный код*. Никакой код не создается, пока не будут созданы тесты, доказывающие его работоспособность. Первый запуск теста должен быть провальным, поскольку код еще не написан. Затем пишется код, обеспечивающий его прохождение, после чего пишется другой тест для следующего сегмента кода.

Разработка на основе тестирования может стать весьма увлекательным занятием, позволяющим создавать небольшие головоломки, требующие решения. Затем для их решения создается код. После этого создается более сложная головоломка и пишется код для решения уже новой головоломки без потребности в решении предшествующей.

Методологией, основанной на тестировании, преследуются две цели. *Во-первых*, обеспечить само написание тестов. *Во-вторых*, осмыслить через написание тестов фактический порядок использования кода. При этом выявляются потребности объектов в тех или иных методах и порядок доступности атрибутов. Это позволяет разбить исходную задачу на ряд более мелких, поддающихся тестированию задач, а затем выстроить из проверенных решений более крупные и вместе с тем уже проверенные решения. То есть создание тестов может стать частью процесса проектирования. Зачастую при написании теста для нового объекта обнаруживаются недочеты в проектировании, заставляющие учитывать новые аспекты программного средства.

Тестирование повышает качество программного обеспечения. Создание тестов, опережающее выпуск самого ПО, способствует его улучшению еще до создания окончательного варианта кода.

Весь рассматриваемый в данной книге код был пропущен через набор автоматизированных тестов. Это единственный способ обретения абсолютной уверенности в работоспособности и надежности предлагаемых здесь примеров.




### Цели тестирования
---

Тесты проводятся для достижения нескольких весьма конкретных целей. Зачастую они называются типами тестирования, но слово «ТИП» слишком активно используется в сфере разработки программных средств, поэтому примем для обозначения слово «цель». В данной главе будут рассмотрены только две цели тестирования.

- ==Проведение модульных тестов, подтверждающих изолированную работоспособность программных компонентов.== Именно с этого начнем, поскольку предполагается, что в [[Тестовая пирамида Фаулера|тестовой пирамиде Фаулера]] (Fowler's Test Pyramid) модульному тестированию придается наибольшее значение. Если различные классы и функции придерживаются своих интерфейсов и дают ожидаемые результаты, то их совокупность также будет работать хорошо и вряд ли преподнесет слишком много сюрпризов. Чтобы убедиться в выполнении в составе набора модульных тестов всех строк кода, обычно используется охватывающее их инструментальное средство.
- Проведение интеграционных тестов, которые, как и следует ожидать, позволяют подтвердить работоспособность программных компонентов, составивших единое целое. ==Иногда **интеграционные тесты** называют системными, функциональными и приемочными==. Сбой интеграционного теста зачастую означает нечеткое определение интерфейса или отсутствие в модульном тесте проверки какого-либо крайнего случая, выявляемого при интеграции с другими компонентами. Зависимость интеграционного тестирования от наличия качественных модульных тестов вряд ли вызывает сомнения, и это делает его роль второстепенной по важности.

Следует отметить, что понятие «модуль» языком Python формально не определяется, причем вполне осознанно. Модуль программного кода иногда состоит всего из одной функции или из одного класса. В таком случае они и представляют модуль. Это определение позволяет весьма гибко идентифицировать изолированные, отдельно взятые модули программного кода.

Хотя тесты преследуют множество различных целей, используемые при этом методы, как правило, схожи. Дополнительная информация по теме доступна по адресу https://www.softwaretestinghelp.com/types-of-software-testing/, где приводится достаточно длинный список из более чем 40 различных целей тестирования.

Вот высокоуровневая классификация типов тестирования программного обеспечения.
![We will see each type of testing in detail with examples.](https://www.softwaretestinghelp.com/wp-content/qa/uploads/2007/08/Classification-of-Software-testing-types.png)

Нам сейчас лучше ограничиться изучением только модульных и интеграционных тестов. Все тесты проводятся по единой схеме, поэтому далее будет рассмотрен общий шаблон тестирования.



#### Шаблоны тестирования
---

Чаще всего написание кода - задача непростая. Нужно выяснить внутреннее состояние объекта, узнать, какие изменения состояния он претерпевает, и определить другие объекты, с которыми он взаимодействует. В книге уже был представлен целый ряд общих паттернов проектирования классов. Тесты в некотором смысле проще определения классов, но, по сути, у них у всех один и тот же паттерн:

```shell
GIVEN (задано) некоторое предварительное условие или условия сценария
WHEN (когда) используется какой - либо метод класса 
THEN(тогда) произойдут какие - то изменения состояния или побочные эффекты, которые можно подтвердить
```

В ряде случаев могут оказаться сложными предварительные условия тестов, или же изменения состояния, или побочные эффекты. Подобная сложность потребует разбиения тестов на несколько шагов. В этой модели, состоящей из трех частей, важно то, что установка, выполнение и ожидаемые результаты отделены друг от друга. Модель применима к весьма широкому спектру тестов. Если нужно убедиться, что вода достаточно горячая для приготовления еще одной чашки чая, будет выполнен примерно следующий набор шагов:

```shell
GIVEN (задано) чаиник с водои на плите
AND (и) горелка выключена
WHEN (когда) открывается крышка чаиника 
THEN (тогда ) виден выходящи и пар
```

Этот паттерн идеально подходит для проверки наличия четкой установки и наблюдаемого результата.

Допустим, нужно создать функцию для вычисления среднего значения списка чисел, которые встречаются в последовательности, исключая значения **`None`**. Можно было бы начать так:

```python
def average(data: list[Optional[int]]) -> float:
	"""
	GIVEN a list, data = [1, 2, None, 3, 4]
	WHEN we compute m = average(data)
	THEN the result, m, is 2.5
	"""
```

Получился набросок определения функции с кратким видением характера ее поведения. На шаге **GIVEN** определяются данные для проведения тестирования. На шаге **WHEN** точно определяются намерения. Наконец, на шаге **THEN** описываются ожидаемые результаты. Средство автоматизированного тестирования способно сравнивать фактические результаты с заявленными ожиданиями и сообщать о непрохождении теста. Затем все это можно превратить в отдельный тестовый класс или функцию, используя предпочтительную среду тестирования. Способы реализации концепции **`unittest`** и **`pytest`** немного различаются, но основная концепция выдерживается в обеих средах. По готовности тест должен провалиться, и можно будет приступать к созданию реального кода, считая этот тест той самой линией ворот, которую нужно пересечь.

К методам, способствующим разработке тестовых сценариев, относятся эквивалентное разбиение и анализ граничных значений. Они помогают разбить область всех возможных входных данных для метода или функции на разделы. Типичным примером является определение двух разделов: «допустимые данные» и «недопустимые данные» . Исходя из характеристик разделов, значения на их границах представляют интерес для использования в тестовых сценариях. Дополнительные сведения можно найти по адресу https://www.softwaretestinghelp.com/what-is-boundary-value-analysis-and-equivalence-partitioning/.

Итак, начнем с изучения встроенной среды тестирования **`unittest`**. Недостатком этой среды считается многословность и сложный внешний вид. А преимущество заключается в том, что она является встроенной и доступной к немедленному применению без дополнительной установки.





## Проведение модульного тестирования с помощью `unittest`
---

Начнем исследование со встроенной тестовой библиотеки Python, предоставляющей общий объектно-ориентированный интерфейс для проведения модульных тестов. Неудивительно, что соответствующая библиотека Python называется **`unittest`**. Она содержит ряд инструментов для создания и запуска модульных тестов, наиболее важным из которых является класс **`TestCase`**. ( Названия-идентификаторы следуют стилю именования Java, поэтому многие имена методов не слишком похожи на используемые в языке Python.) Класс **`TestCase`** предоставляет набор методов, позволяющих сравнивать значения, настраивать тесты и очищать их по завершении.

Когда нужно создать набор модульных тестов для выполнения конкретной задачи, создается подкласс **`TestCase`** и пишутся отдельные методы для проведения тестирования. Все методы должны начинаться с имени **`test`**. При соблюдении этого соглашения тесты автоматически запускаются как часть процесса тестирования. Для простых примеров концепции **GIVEN**, **WHEN** и **THEN** можно объединить в тестовый метод. Рассмотрим простейший пример:

```python
import unittest 
  

class CheckNumbers(unittest.TestCase):
    def test_int_float(self) -> None:
        self.assertEqual(1, 1.0)
  
if __name__ == "__main__":
    unittest.main()
```

Здесь создается подкласс класса **`TestCase`** и добавляется метод, вызывающий метод **`TestCase.assertEqual()`** . Шаг **GIVEN** состоит из задания пары значений - `1` и `1.0`. Шаг **WHEN** является своеобразным вырожденным примером, поскольку новый объект не создается и изменение состояния не происходит. Шаг **THEN** является проверкой равенства двух значений.

При запуске сценария тестирования этот метод в зависимости от того, равны два параметра или нет, либо завершится успешно, либо вызовет исключение. Если запустить данный код, функция main из **`unittest`** выведет следующее сообщение:

```powershell
.
---------------------------------------------------------------------
Ran 1 test in 0.000s

OK
```

А вы знали, что числа с плавающей точкой и целые числа можно проверять на равенство?

Давайте добавим сюда еще и заведомо провальный тест:

```python
def test_str_float(self) -> None:
	self.assertEqual(1, "1")
```

Сообщение, выводимое данным кодом, носит более печальный характер, поскольку целые числа и строки не могут считаться равными друг другу:

```powershell
.F
======================================================================
FAIL: test_str_float (__main__.CheckNumbers.test_str_float)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "E:\DEVeloping_aNd_practice\OOP_PYTHON_4-th_edition\13_OOP_tests\check_numbers_test.py", line 9, in test_str_float
    self.assertEqual(1, "1")
AssertionError: 1 != '1'

----------------------------------------------------------------------
Ran 2 tests in 0.001s

FAILED (failures=1)
```

Точка в первой строке означает, что первый (ранее написанный) тест пройден успешно, а буква **`F`** после нее показывает, что второй тест не пройден. Затем, в конце, дается информационная сводка, в которой рассказывается, как и где тест провалился, а также подсчитывается количество неудач.

Даже код возврата на уровне операционной системы предоставляет полезную сводку. Код возврата равен нулю, если все тесты пройдены успешно, и не равен нулю, если какие-либо из тестов не пройдены. Это помогает при создании инструментов непрерывной интеграции: если запуск **`unittest`** будет провален, в предлагаемом изменении нужно отказать.

В одном классе **`TestCase`** может быть сколько угодно тестовых методов. Программа запуска тестов будет выполнять в качестве отдельного изолированного теста каждый из методов, имя которого начинается с **`test`**.

>[!info]
>Каждый тест должен быть полностью независим от других тестов.
>Результаты или расчеты теста не должны влиять на любой другой тест.

Чтобы тесты были изолированы друг от друга, можно создать несколько тестов с общим шагом **GIVEN**, который реализован общим методом **`setUp()`**. При этом предполагается довольно частое использование похожих классов, и для разработки тестов нужно использовать наследование, позволяющее им иметь общие функции, но при этом оставаться полностью независимыми.

Основой создания высококачественных модульных тестов является предельная минимализация каждого тестового метода и тестирование в каждом сценарии сравнительно небольшого модуля. Если не представляется возможным разбить код на небольшие тестируемые модули естественным образом, то, скорее всего, это является признаком необходимости его переработки. Способ изоляции объектов в целях тестирования рассматривается далее в разделе  *Имитация объектов с помощью моков*.

Модуль **`unittest`** требует структуризации тестов в виде определения класса. Это в некотором роде усложняет процесс. В пакете **`pytest`** предлагается более разумное представление о тестах и немного более гибкий способ построения тестов как функций, а не методов класса. Теперь посмотрим, что собой представляет **`pytest`**.





## Проведение модульного тестирования с помощью `pytest`
---

Модульные тесты могут создаваться с помощью библиотеки, предоставляющей общую структуру для тестовых сценариев и средство запуска тестов для их выполнения и протоколирования результатов. Модульные тесты специализируются на проверке в любом отдельно взятом тесте наименьшего возможного количества кода. Стандартная библиотека включает пакет **`unittest`**. Но, несмотря на его довольно широкое использование, он вынуждает создавать для каждого теста изрядное количество шаблонного кода.

В числе наиболее популярных альтернатив стандартной библиотеке **`unittest`** можно выделить такое средство, как **`pytest`**. ==Его преимущество заключается в возможности написания более мелких и понятных тестовых сценариев. Отсутствие ненужных усложнений вызывает повышенный интерес к этому альтернативному варианту.==

Поскольку **`pytest`** не входит в стандартную библиотеку, это средство необходимо скачивать и устанавливать самостоятельно. Получить его можно на домашней странице **`pytest`** по адресу https://docs.pytest.org/en/stable/, а для установки воспользоваться любым из инсталляторов.

В окне терминала нужно активировать ту виртуальную среду, в которой ведется работа. (Если, к примеру, тестирование происходит в `venv`, можно выполнить команду `python -m venv с:\path\to\myenv`.) А затем следует воспользоваться командой операционной системы, например следующей:

```shell
% python -m pip install pytest
```
Команда для Windows должна быть такой же, как команда для macOS и Linux.

Средство **`pytest`** использует структуру теста, существенно отличающуюся от той, что применяется в модуле **`unittest`**. От тестовых сценариев не требуется быть подклассами **`unittest.TestCase`**. Вместо этого **`pytest`** опирается на факт принадлежности функций Python к объектам первого класса, что позволяет любой надлежаще названной функции вести себя как тест. Вместо подтверждения равенства с помощью целого набора специализированных методов этим средством для проверки результатов используется инструкция **`assert`**. Таким образом упрощаются тесты и их понимание и, следовательно, облегчается их сопровождение.

При запуске **`pytest`** это средство начинает работать в текущей папке и приступает к поиску любых модулей или подпакетов с именами, предваряемыми префиксом **`test_`**. (С обязательным присутствием символа **`_`**. ) Если какие-либо функции в данном модуле также начинаются с **`test`** (при этом символ **`_`** для них не требуется), они будут выполняться как отдельно взятые тесты. Кроме того, если в модуле есть какие-либо классы, имя которых начинается с **`Test`**, любые методы этих классов, начинающиеся с **`test`**, также будут выполняться в тестовой среде.

Поиск, как ни удивительно, также ведется в папке с именем **`tests`**. Из-за этого код обычно разбивается на две папки: в каталоге **`src/`** содержится рабочий модуль, библиотека или приложение, а в каталоге **`test/`** - все тестовые сценарии.

Перенесем простой пример **`unittest`**, написанный ранее, в **`pytest`**, используя следующий код:

```python
def test_int_float() -> None:
	assert 1 == 1.0
```

Для выполнения точно такого же теста были написаны две строки более удобного для восприятия кода по сравнению с теми шестью строками, которые были нужны в нашем первом примере модульного тестирования.

Но создавать тесты на основе классов здесь также не запрещено. Классы могут пригодиться для применения групп связанных тестов или тестов, которым требуется доступ к связанным атрибутам или методам класса. В следующем примере показан расширенный класс с заведомо проходимым и непроходимым тестами, так нам можно будет убедиться, что вывод сведений об ошибке здесь информативнее, чем тот, который предоставлялся модулем **`unittest`**:

```python
class TestNumbers:
    def test_int_float(self) -> None:
        assert 1 == 1.0

    def test_str_float(self) -> None:
        assert 1 == "1"
```

Заметьте, что классу не нужно служить расширением каких-либо специальных объектов, которые будут обнаружены в качестве тестового сценария (хотя в **`pytest`** без проблем запускаются стандартные тестовые сценарии **`TestCases`** из арсенала **`unittest`**). При запуске команды **`python -m pytesttests/< имя_фaйлa >`** результат будет иметь следующий вид:

```bash
% python -m pytest tests/test_check_number.py
================= test session starts ==============================
platform win32 -- Python 3.11.8, pytest-8.2.2, pluggy-1.5.0
rootdir: D:\Developing_and_practice\OOP_Python_4-th_edition\13_OOP_tests
collected 2 items                                                                                                                                                                        
tests\test_check_number.py .F    [100%]
================== FAILURES ======================================== 
____________TestNumbers.test_str_float _____________________________

self = <test_check_number.TestNumbers object at 0x000001EFA4AA56D0>

    def test_str_float(self) -> None:
>       assert 1 == "1"
E       AssertionError: assert 1 == '1'

tests\test_check_number.py:6: AssertionError
================================================================================ short test summary info =================================
FAILED tests/test_check_number.py::TestNumbers::test_str_float - AssertionError: assert 1 == '1'
============================================================================== 1 failed, 1 passed in 0.11s ===============================
```

Выведенная на экран информация начинается с полезных сведений о платформе и интерпретаторе. Они могут пригодиться для обмена или обсуждения ошибок в разных системах. В третьей строке сообщается имя тестируемого файла (если выбрано сразу несколько тестируемых модулей, то все они будут отображаться), за которым следует уже знакомая последовательность **`.F`**, встречавшаяся при работе с модулем **`unittest`**. Символ точки (**`.`**) указывает на пройденный тест, а буква **`F`** - на непройденный.

После выполнения всех тестов для каждого из них выводится информация об ошибках. В ней представлены сводка локальных переменных (в данном примере только одна переменная: переданный в функцию параметр **`self`**), исходный код, в котором произошли ошибки, и сводка сообщений об ошибках. Кроме того, при выдаче исключений, отличных от **`Assertion Error`**, средство **`pytest`** предоставит полную трассировку, включая ссылки на исходный код.

Если тест пройден успешно, **`pytest`** подавляет вывод из функции **`print()`**. Это может пригодиться для отладки тестов, поскольку, когда тест проваливается, в него можно добавить инструкции **`print()`** , чтобы проверить значения тех или иных переменных и атрибутов в ходе выполнения теста.

Если тест не пройден, эти значения выводятся на экран, помогая выявить недочеты. Но после успешного прохождения теста вывод функции **`print()`** не отображается и его легко будет проигнорировать. То есть очищать вывод теста путем удаления функций **`print()`** не понадобится. Если из-за последующих изменений тесты снова не будут пройдены, отладочный вывод тут же снова будет доступен.

Примечательно, что подобное использование инструкции **`assert`** создает потенциальную проблему для mуру. При использовании инструкции **`assert`** средство **`mуру`** может проверить типы и предупредить нас о потенциальной проблеме с **`assert 1 == "1"`**. Этот код вряд ли будет приемлемым, и он не пройдет не только модульный тест, но и проверку **`mуру`**.

Ну что ж, поддержка со стороны **`pytest`** шагов **WHEN** и **THEN** с использованием функции и инструкции **`assert`** рассмотрена. Осталось выяснить, как можно справиться с шагом **GIVEN**. Для задания предварительных условий теста с помощью шага **GIVEN** существует два способа. Начнем с того, который предназначен для простых случаев.




### Функции настройки и демонтажа `pytest`
---

Средством **`pytest`** поддерживаются возможности установки и демонтажа, подобные методам, используемым в **`unittest`**, но при этом предоставляется большая гибкость. Соответствующие основные функции будут вкратце изучены сейчас. А в следующем разделе предстоит рассмотрение весьма эффективных возможностей использования [[Фикстуры|фикстур]](fixtures), предоставляемых средством **`pytest`**.

Если тесты создаются на основе классов, можно воспользоваться двумя методами: **`setup_method()`** и **`teardown_method()`**. Они вызываются до и после каждого тестового метода в классе с целью выполнения задач по настройке и очистке соответственно.

Кроме этого, средством **`pytest`** предоставляются и другие функции настройки и демонтажа, позволяющие расширить возможности контроля над выполнением кода подготовки и очистки. Предполагается, что методы **`setup_class()`** и **`teardown_class()`** будут методами класса, принимающими один аргумент, который представляет данный класс (аргумента **`self`** нет, поскольку нет экземпляра; вместо этого предоставляется класс). Эти методы запускаются средством **`pytest`** не при каждом тестовом прогоне, а при запуске класса.

И наконец, в нашем распоряжении имеются функции **`setup_module()`** и **`teardown_module()`**, запускаемые **`pytest`** непосредственно до и после выполнения всех тестов (в функциях или классах) в данном модуле. Они могут пригодиться для одноразовой настройки, например для создания сокета или подключения к базе данных, которые будут использоваться всеми тестами в модуле. Но здесь нужно проявить осмотрительность, поскольку можно случайно спровоцировать зависимость тестов друг от друга, если какое-то из состояний объекта не будет должным образом очищено между запусками тестов.

По данному краткому описанию трудно составить представление о том, когда именно вызываются эти методы. Поэтому рассмотрим пример, который четко иллюстрирует нужные моменты:

```python
from typing import Any, Callable
  

def setup_module(module: Any) -> None:
    print(f"setting up MODULE {module.__name__}")

  
def teardown_module(module: Any) -> None:
    print(f"tearing down MODULE {module.__name__}")
  

def test_a_function() -> None:
    print("RUNNING TEST FUNCTION")
  

class BaseTest:
    @classmethod
    def setup_class(cls: type["BaseTest"]) -> None:
        print(f"setting up CLASS {cls.__name__}\n")

    @classmethod
    def teardown_class(cls: type["BaseTest"]) -> None:
        print(f"tearing down CLASS {cls.__name__}\n")

    def setup_method(self, method: Callable[[], None]) -> None:
        print(f"setting up METHOD {method.__name__}")

    def teardown_method(self, method: Callable[[], None]) -> None:
        print(f"tearing down METHOD {method.__name__}")

  
class TestClass1(BaseTest):
    def test_method_1(self) -> None:
        print("RUNNING METHOD 1-1")

    def test_method_2(self) -> None:
        print("RUNNING METHOD 1-2")


class TestClass2(BaseTest):
    def test_method_1(self) -> None:
        print("RUNNING METHOD 2-1")

    def test_method_2(self) -> None:
        print("RUNNING METHOD 2-2")
```

Единственным предназначением класса **`BaseTest`** является извлечение четырех методов, которые в остальном идентичны двум тестовым классам, и использование наследования для сокращения объема повторяющегося кода. Итак, с позиции **`pytest`** у двух подклассов имеются не только два метода тестирования, но также два метода настройки и два метода демонтажа (один на уровне класса, один на уровне метода).\

Если запустить данные тесты с помощью **`pytest`** с отключенным подавлением вывода функции **`print()`** (путем установки флажка **`-s`** или **`--capture=no`**), будет видна очередность вызова различных функций и самих тестов:

```shell
==================== test session starts ===========================
platform win32 -- Python 3.11.8, pytest-8.2.2, pluggy-1.5.0
rootdir: D:\DeVEloping_aNd_practice\OOP_PYTHON_4-th_edition\13_OOP_tests
collected 5 items

tests\test_setup_teardown.py setting up MODULE test_setup_teardown
RUNNING TEST FUNCTION
.setting up CLASS TestClass1

setting up METHOD test_method_1
RUNNING METHOD 1-1
.tearing down METHOD test_method_1
setting up METHOD test_method_2
RUNNING METHOD 1-2
.tearing down METHOD test_method_2
tearing down CLASS TestClass1

setting up CLASS TestClass2

setting up METHOD test_method_1
RUNNING METHOD 2-1
.tearing down METHOD test_method_1
setting up METHOD test_method_2
RUNNING METHOD 2-2
.tearing down METHOD test_method_2
tearing down CLASS TestClass2

tearing down MODULE test_setup_teardown


=========================5 passed in 0.05s ==========================
```

Методы настройки и демонтажа для модуля как единого целого выполняются в начале и в конце сеанса. А между ними запускается единственная тестовая функция на уровне модуля. Потом выполняется метод настройки для первого класса, за которым следуют два теста для этого класса. Каждый из этих тестов сам по себе заключен в отдельные вызовы **`setup_method()`** и **`teardown_method()`**. После выполнения тестов вызывается метод демонтажа класса. Такая же последовательность действует и для второго класса, после чего происходит однократный вызов метода **`teardown_module()`**.

Хотя в соответствии с именами данных функций предполагается предоставление множества вариантов выполнения тестирования, зачастую будут задействоваться условия настройки, являющиеся общими сразу для нескольких тестовых сценариев. Их можно многократно использовать, применяя конструкции, основанные на композиции; в **`pytest`** такие конструкции называются фикстурами (fixtures). Именно их мы сейчас и рассмотрим.




### Фикстуры `pytest`, предназначенные для настройки и демонтажа
---

Одним из наиболее распространенных вариантов применения различных функций настройки является обеспечение подготовки для теста шага **GIVEN**. Зачастую под этим подразумевается создание объектов и обеспечение у конкретных переменных класса или модуля известных значений. Это необходимо проводить перед запуском метода тестирования.

В дополнение к набору имен специальных методов для тестового класса **`pytest`** предлагает проводить настройку тестов совершенно оригинальным методом, используя так называемые **фикстуры**. Они являются функциями построения условия **GIVEN** до выполнения шага **WHEN**.

У средства **`pytest`** имеется целый ряд встроенных фикстур. Кроме этого, фикстуры можно определять в файле конфигурации с их последующим многократным использованием, а уникальные фикстуры допустимо определять в качестве части самих тестов. Это позволяет отделить настройку тестов от их выполнения и использовать фикстуры сразу в нескольких классах и модулях.

Рассмотрим класс, выполняющий несколько вычислений, подлежащих тестированию.

```python
import collections
from typing import List, Optional, DefaultDict

class StatsList(List[Optional[float]]):
    """Stats with None objects rejected"""

    def mean(self) -> float:
        clean = list(filter(None, self))
        return sum(clean) / len(clean)

    def median(self) -> float:
        clean = list(filter(None, self))
        if len(clean) % 2:
            return clean[len(clean) // 2]
        else:
            idx = len(clean) // 2
            return (clean[idx] + clean[idx - 1]) / 2

    def mode(self) -> list[float]:
        freqs: DefaultDict[float, int] = collections.defaultdict(int)
        for item in filter(None, self):
            freqs[item] += 1
        mode_freq = max(freqs.values())
        modes = [item for item, value in freqs.items()
                 if value == mode_freq]
        return modes
```

Данный класс расширяет встроенный класс **`list`** путем добавления трех методов статистической сводки: **`mean()`**, **`median()`**  и **`mode()`**. Каждому методу нужен некоторый набор доступных для использования данных; конфигурация **`StatsList`** с известными данными и будет тестируемой фикстурой.

Для использования фикстуры с целью создания предварительного условия **GIVEN** в тестовую функцию в качестве параметра добавляется имя фикстуры. При запуске теста имена параметров тестовой функции будут располагаться в коллекции фикстур, и эти функции создания фикстур будут выполняться в автоматическом режиме.

Например, чтобы протестировать класс **`StatsList`**, требуется многократное предоставление списка допустимых целых чисел. Соответствующие тесты можно написать следующим образом:

```python
import pytest
from stats import StatsList


@pytest.fixture
def valid_stats() -> StatsList:
    return StatsList([1, 2, 2, 3, 3, 4])


def test_mean(valid_stats: StatsList) -> None:
    assert valid_stats.mean() == 2.5


def test_median(valid_stats: StatsList) -> None:
    assert valid_stats.median() == 2.5
    valid_stats.append(4)
    assert valid_stats.median() == 3


def test_mode(valid_stats: StatsList) -> None:
    assert valid_stats.mode() == [2, 3]
    valid_stats.remove(2)
    assert valid_stats.mode() == [3]
```
```powershell
python -m pytest --capture=no tests/test_stats.py
======================== test session starts=========================
platform win32 -- Python 3.11.8, pytest-8.2.2, pluggy-1.5.0
rootdir: D:\DEVELoping_and_practice\OOP_PY_4-th_edition\13_OOP_tests
collected 3 items                                               

tests\test_stats.py ...

======================== 3 passed in 0.03s ==========================
```

Каждая из трех тестовых функций принимает параметр с именем **`valid_stats`**, создающийся средством **`pytest`**, в результате чего автоматически вызывается функция **`valid_stats`**. В функцию добавлен декоратор **`@руtеst.fixture`**, позволяющий **`pytest`** использовать ее особым образом.

Разумеется, имена должны совпадать. Среда выполнения **`pytest`** ищет те функции с декоратором **`@fixture`**, которые совпадают с именем параметра.

Возможности фикстур гораздо шире, чем только возвращение простых объектов. Для предоставления весьма полезных методов и атрибутов, изменяющих поведение фикстуры, в фабрику фикстур может передаваться объект **`request`**. Тест, запрашивающий фикстуру, позволяет четко определять такие атрибуты объекта **`request`**, как **`module`**, **`cls`** и **`function`**. Атрибут **`config`** объекта **`request`** предназначен для проверки аргументов командной строки и многих других данных конфигурации.

Если фикстура реализуется в виде генератора, она может также запускать код очистки после каждого запуска теста. В результате получается эквивалент метода демонтажа для каждой фикстуры. Им можно воспользоваться для очистки файлов, закрытия соединений, пустых списков или сброса очередей. Для модульных тестов с изолированными элементами применение имитирующего объекта представляется более рациональным замыслом, чем выполнение демонтажа объекта, имеющего внутреннее состояние. Далее, в разделе «Имитация объектов с помощью моков>. описан более простой подход, идеально подходящий для модульного тестирования.

При проведении интеграционных тестов может потребоваться протестировать какой-либо код, создающий, удаляющий или обновляющий файлы. При записи файлов с возможностью их последующего удаления часто используется фикстура **`pytest tmp_path`**, что избавляет от необходимости выполнять демонтаж в самом тесте. Потребности в демонтаже при модульном тестировании возникают довольно редко, но он может пригодиться для остановки тех подпроцессов или удаления тех изменений базы данных, которые являются частью интеграционного теста. Подобная ситуация будет показана в текущем разделе чуть позже. А сначала рассмотрим небольшой пример фикстуры с возможностью настройки и демонтажа.

Чтобы осмыслить замысел фикстуры, выполняющей как настройку, так и демонтаж, проанализируем небольшой программный код, создающий резервную копию файла и записывающий новый файл с контрольной суммой существующего файла:

```python
import tarfile
from pathlib import Path
import hashlib


def checksum(source: Path, checksum_path: Path) -> None:
    if checksum_path.exists():
        backup = checksum_path.with_stem(f"(old)                                      {checksum_path.stem}")
        backup.write_text(checksum_path.read_text())
    checksum = hashlib.sha256(source.read_bytes())
    checksum_path.write_text(f"{source.name}                                               {checksum.hexdigest()}\n")
```

Есть два возможных сценария.

- Исходный файл действительно существует, и в каталог добавляется новая контрольная сумма.
- Существует как исходный файл, так и файл контрольной суммы. В данном случае делается резервная копия старой контрольной суммы и записывается новая контрольная сумма.

Не станем здесь тестировать оба сценария, покажем, как фикстура может создавать, а затем удалять файлы, необходимые для тестовой последовательности. Сосредоточимся на втором сценарии, поскольку он сложнее первого. Разобьем тестирование на две части и начнем с фикстуры:

```python
import checksum_writer
import pytest
from pathlib import Path
from typing import Iterator
import sys


@pytest.fixture
def working_directory(tmp_path: Path) -> Iterator[tuple[Path, Path]]:
    working = tmp_path / "some_directory"
    working.mkdir()
    source = working / "data.txt"
    source.write_bytes(b"Hello, world!\n")
    checksum = working / "checksum.txt"
    checksum.write_text("data.txt Old_Checksum")
    
    yield source, checksum
    
    checksum.unlink()
    source.unlink()

```

Работа этого кода основана на применении инструкции **`yield`**. Фактически фикстура является генератором, выдающим один результат и ожидающим следующего запроса значения. Первым результатом становится выполнение целого ряда шагов: создание рабочего каталога, создание в нем исходного файла, а затем создание старого файла контрольной суммы. Инструкция **`yield`** предоставляет два пути к тесту и ожидает следующий запрос. Этими действиями завершается настройка условия **GIVEN** для теста.

По завершении тестовой функции **`pytest`** предпримет попытку получения из упомянутой фикстуры одного последнего элемента. Это позволит функции разъединить файлы, удалив их. Отсутствие возвращаемого значения сигнализирует об окончании итерации. Помимо использования протокола генератора, в фикстуре **`working_directory`** используется *руtеst-фикстура* **`tmp_path`**, имеющая целью создание временного рабочего местоположения для данного теста.

Тест, использующий фикстуру **`work_directory`**, имеет следующий вид:

```python
@pytest.mark.skipif(sys.version_info < (3, 9), reason="requires python3.9 feature")
def test_checksum(working_directory: tuple[Path, Path]) -> None:
    source_path, old_checksum_path = working_directory
    checksum_writer.checksum(source_path, old_checksum_path)
    backup = old_checksum_path.with_stem(f"(old) {old_checksum_path.stem}")
    assert backup.exists()
    assert old_checksum_path.exists()
    name, checksum = old_checksum_path.read_text().rstrip().split()
    assert name == source_path.name
    assert (
        checksum == "d9014c4624844aa5bac314773d6b689a"
        "d467fa4e1d1a50a1b8a99d5a95f72ff5"
    )
```

Что примечательно, в тесте имеется условие пропуска **`skipif`**, поскольку в Python 3.8 данный тест работать не будет по причине того, что метод **`with_stem()`** объекта **`Path`** не является частью старой реализации **`pathlib`**. То есть тест существует, но при этом отмечается его непригодность для конкретной версии Python. Дополнительно эта ситуация будет рассмотрена далее в этой же главе, в подразделе � Пропуск тестов с помощью **`pytest`**•.

Ссылка на фикстуру **`work_directory`** заставляет **`pytest`** выполнять функцию фикстуры, которая предоставляет тестовому сценарию два пути, используемые как часть условия **GIVEN** перед тестированием. На шаге **WHEN** вычисляется значение функции **`checksum_writer.checksum()`** с этими двумя путями. Шаги **THEN** представляют собой последовательность инструкций **`assert`**, позволяющих убедиться, что файлы созданы с ожидаемыми значениями. После запуска теста для получения из фикстуры другого элемента средством **`pytest`** будет использоваться метод **`next()`**; это действие производится кодом после выполнения инструкции **`yield`**, что приводит к проведению демонтажа по окончании теста.

При тестировании изолированных друг от друга компонентов потребность в частом применении функции демонтажа фикстуры не возникает. Но для интеграционных тестов в условиях совместного использования сразу нескольких компонентов может потребоваться остановка процессов или удаление файлов. В следующем разделе будет рассмотрена фикстура посложнее. Этот тип фикстур может использоваться более чем одним тестовым сценарием.




### Более сложные фикстуры
---

Для создания фикстуры, рассчитанной более чем на один тест, можно передать параметр области видимости. Это пригодится при настройке высокозатратной операции, которая может повторно использоваться в нескольких тестах, но только при условии, что повторное использование ресурсов не нарушает атомарную или модульную природу теста: на нее не должен полагаться или оказывать свое влияние ни один из модульных тестов.

В качестве примера определим сервер, являющийся частью клиент-серверного приложения. Необходимо, чтобы сразу несколько веб-серверов отправляли свои журнальные сообщения в один централизованный журнал. В дополнение к изолированным модульным тестам следует иметь интеграционный тест, который позволит убедиться в правильной интеграции веб-сервера и сборщика журналов друг с другом. Интеграционный тест должен запускать и останавливать сервер сбора журналов. Пирамида тестирования, таким образом, состоит как минимум из трех уровней. Модульные тесты будут основой, проверяющей каждый компонент по отдельности. Интеграционные тесты станут серединой пирамиды, обеспечивающей правильную интеграцию компонентов друг с другом. Системный или приемочный тест явит собой вершину пирамиды, гарантирующую, что весь набор программного средства выполняет заявленные функции.

Рассмотрим сервер сбора журналов, принимающий сообщения и записывающий их в один центральный файл. Эти сообщения определяются в модуле ведения журнала **`SocketHandler`**. Каждое сообщение может быть представлено в виде блока байтов с заголовком и полезным информационным наполнением. Структура с использованием фрагментов блока байтов показана в таблице ниже.

Сообщение определяется следующим образом.

| Начало фрагмента | Конец фрагмента | Значение     | Модуль и функция Python для разбора |
| ---------------- | --------------- | ------------ | ----------------------------------- |
| 0                | 4               | payload_size | **`struct.unpack(">L", bytes)`**    |
| 4                | payload_size+4  | payload      | **`pickle.loads(bytes)`**           |
