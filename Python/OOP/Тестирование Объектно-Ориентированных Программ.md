---
date of creation: 2024-07-03T16:52:00
tags:
  - Tests
  - Python/Tests
  - Python/OOP
  - Python/OOP/Tests
  - OOP/Python
  - Developing
  - Developing/Tests
  - IT/Python
  - Python/unittest
  - unittest
  - pytest
  - Tests/pytest
  - Tests/mock
  - Tests/unittest
  - Programming/Tests
  - Programming
read status: true
aliases:
  - Тесты ООП на Python
---
---
# Тестирование Объектно-Ориентированных Программ




Опытные Руthоn-программисты считают тестирование одним из наиболее важных аспектов разработки программных средств. То, что данная глава расположена ближе к концу книги, вполне закономерно, поскольку в написании тестов вам пригодится весь ранее изученный материал. Здесь будут раскрыты следующие темы.

- **[[#Зачем вообще проводить тестирование|Важность модульного тестирования и разработки на основе тестирования.]]**
- **[[#Проведение модульного тестирования с помощью `unittest`|Модуль стандартной библиотеки unittest]]**.
- **[[#Проведение модульного тестирования с помощью `pytest`|Инструментальное средство pytest]]**.
- **[[#Имитация объектов с помощью моков|Модуль mock]].
- **[[#Тестирование и разработка|Охват кода тестами]]**.

А для начала рассмотрим некоторые основные причины, позволяющие осознать важность автоматизированного тестирования программных средств.





## Зачем вообще проводить тестирование
---

Важность тестирования кода не вызывает сомнений у многих программистов. Читатели, разделяющие их точку зрения, могут ограничиться беглым просмотром данного раздела и перейти к следующему, где уже гораздо конкретнее раскрывается порядок создания тестов в Python.

И вес же зачем проводить тестирование? Какой от него толк? Что будет, если от него отказаться? Для ответа на эти вопросы достаточно вспомнить историю создания вашего последнего программного кода. Неужели программа сразу же заработала как надо? И в ней не было никаких синтаксических ошибок? Не выявились никакие проблемы с логикой? В принципе, временами действительно может сразу получаться безупречный код. Но обычно на практике возникает некоторое количество очевидных синтаксических ошибок, требующих исправления, что указывает на высокую вероятность присутствия в коде не столь очевидных логических ошибок, также требующих исправления.

Чтобы убедиться в работоспособности кода, не нужен какой-то чисто формальный специальный тест. Достаточно провести самое простое тестирование: запустить программу и исправить ошибки. Наличие интерактивного интерпретатора Python и практически нулевое время компиляции позволяют быстро написать несколько строк кода, запустить программу и убедиться, что действия этих строк соответствуют ожиданиям.

Приемлемость такого подхода в начале работы над проектом со временем все больше снижается. Попытки изменения всего лишь нескольких строк кода могут совершенно непредвиденно повлиять на другие части программы, и без тестов невозможно будет выявить источник и причину неполадок. Любое переписывание кода или даже просто его легкая оптимизация могут вызвать серьезные проблемы. Кроме того, по мере роста объема программы увеличивается и число возможных путей прохода интерпретатора по ее коду, и примитивная ручная проверка работоспособности всех этих путей становится просто невозможной.

Убедить всех и, конечно, себя в работоспособности собственных программных средств можно путем создания автоматизированных тестов, являющихся программами, автоматически запускающими другие программы или их части с конкретными входными данными. Время работы этих программ, как правило, исчисляется секундами, но при этом охватывает гораздо больше потенциальных входных ситуаций, чем может принять во внимание один программист при каждом внесении каких-либо изменений.

>Функций программных средств, не поддающихся прогону при автоматизированном тестировании, просто не существует.
>				Extreme Programming Explained, [[Кент Бек]]

Необходимость создания тестов обусловливается четырьмя основными причинами:

- стремлением убедиться, что код работает в соответствии с замыслом разработчика;
- желанием удостовериться в сохранении работоспособности кода при внесении в него изменений;
- проверкой факта понимания разработчиком предъявленных требований;
- проверкой наличия у создаваемого кода поддерживаемого интерфейса.

Автоматизированные тесты при их наличии можно запускать при каждом изменении кода как на начальном этапе разработки, так и при выпусках его модифицированных версий. Тестирование позволяет подтвердить, что при добавлении или расширении функций программы ей не нанесен непреднамеренный урон.

У двух последних из вышеперечисленных пунктов имеются довольно интересные последствия. Создание тестов помогает разработать API, интерфейс или шаблон, принимаемый кодом. Таким образом, при неверном осмыслении требований создание теста позволяет выявить возникшее недоразумение. А с другой стороны, если есть сомнения, связанные с проектированием класса, можно создать тест, взаимодействующий с этим классом, получив при этом представление о наиболее естественном способе подтверждения работоспособности интерфейса. Фактически зачастую бывает полезным создать тесты еще до написания тестируемого кода.

Повышенное внимание к тестированию программного средства имеет и другие интересные последствия. Здесь будут рассмотрены три из них:

- использование тестов в качестве основы разработки;
- управление разнообразными целями тестирования;
- наличие согласованного шаблона для тестовых сценариев.

Начнем с использования тестов в качестве основы разработки.




## [[TDD|Разработка на основе тестирования]]
---

Принцип разработки на основе тестирования - *опережающее создание тестов*. При этом *непроверенный код заранее считается нерабочим*, а *непроверенным может быть только еще не написанный код*. Никакой код не создается, пока не будут созданы тесты, доказывающие его работоспособность. Первый запуск теста должен быть провальным, поскольку код еще не написан. Затем пишется код, обеспечивающий его прохождение, после чего пишется другой тест для следующего сегмента кода.

Разработка на основе тестирования может стать весьма увлекательным занятием, позволяющим создавать небольшие головоломки, требующие решения. Затем для их решения создается код. После этого создается более сложная головоломка и пишется код для решения уже новой головоломки без потребности в решении предшествующей.

Методологией, основанной на тестировании, преследуются две цели. *Во-первых*, обеспечить само написание тестов. *Во-вторых*, осмыслить через написание тестов фактический порядок использования кода. При этом выявляются потребности объектов в тех или иных методах и порядок доступности атрибутов. Это позволяет разбить исходную задачу на ряд более мелких, поддающихся тестированию задач, а затем выстроить из проверенных решений более крупные и вместе с тем уже проверенные решения. То есть создание тестов может стать частью процесса проектирования. Зачастую при написании теста для нового объекта обнаруживаются недочеты в проектировании, заставляющие учитывать новые аспекты программного средства.

Тестирование повышает качество программного обеспечения. Создание тестов, опережающее выпуск самого ПО, способствует его улучшению еще до создания окончательного варианта кода.

Весь рассматриваемый в данной книге код был пропущен через набор автоматизированных тестов. Это единственный способ обретения абсолютной уверенности в работоспособности и надежности предлагаемых здесь примеров.




### Цели тестирования
---

Тесты проводятся для достижения нескольких весьма конкретных целей. Зачастую они называются типами тестирования, но слово «ТИП» слишком активно используется в сфере разработки программных средств, поэтому примем для обозначения слово «цель». В данной главе будут рассмотрены только две цели тестирования.

- ==Проведение модульных тестов, подтверждающих изолированную работоспособность программных компонентов.== Именно с этого начнем, поскольку предполагается, что в [[Тестовая пирамида Фаулера|тестовой пирамиде Фаулера]] (Fowler's Test Pyramid) модульному тестированию придается наибольшее значение. Если различные классы и функции придерживаются своих интерфейсов и дают ожидаемые результаты, то их совокупность также будет работать хорошо и вряд ли преподнесет слишком много сюрпризов. Чтобы убедиться в выполнении в составе набора модульных тестов всех строк кода, обычно используется охватывающее их инструментальное средство.
- Проведение интеграционных тестов, которые, как и следует ожидать, позволяют подтвердить работоспособность программных компонентов, составивших единое целое. ==Иногда **интеграционные тесты** называют системными, функциональными и приемочными==. Сбой интеграционного теста зачастую означает нечеткое определение интерфейса или отсутствие в модульном тесте проверки какого-либо крайнего случая, выявляемого при интеграции с другими компонентами. Зависимость интеграционного тестирования от наличия качественных модульных тестов вряд ли вызывает сомнения, и это делает его роль второстепенной по важности.

Следует отметить, что понятие «модуль» языком Python формально не определяется, причем вполне осознанно. Модуль программного кода иногда состоит всего из одной функции или из одного класса. В таком случае они и представляют модуль. Это определение позволяет весьма гибко идентифицировать изолированные, отдельно взятые модули программного кода.

Хотя тесты преследуют множество различных целей, используемые при этом методы, как правило, схожи. Дополнительная информация по теме доступна по адресу https://www.softwaretestinghelp.com/types-of-software-testing/, где приводится достаточно длинный список из более чем 40 различных целей тестирования.

Вот высокоуровневая классификация типов тестирования программного обеспечения.
![We will see each type of testing in detail with examples.](https://www.softwaretestinghelp.com/wp-content/qa/uploads/2007/08/Classification-of-Software-testing-types.png)

Нам сейчас лучше ограничиться изучением только модульных и интеграционных тестов. Все тесты проводятся по единой схеме, поэтому далее будет рассмотрен общий шаблон тестирования.



#### Шаблоны тестирования
---

Чаще всего написание кода - задача непростая. Нужно выяснить внутреннее состояние объекта, узнать, какие изменения состояния он претерпевает, и определить другие объекты, с которыми он взаимодействует. В книге уже был представлен целый ряд общих паттернов проектирования классов. Тесты в некотором смысле проще определения классов, но, по сути, у них у всех один и тот же паттерн:

```shell
GIVEN (задано) некоторое предварительное условие или условия сценария
WHEN (когда) используется какой - либо метод класса 
THEN(тогда) произойдут какие - то изменения состояния или побочные эффекты, которые можно подтвердить
```

В ряде случаев могут оказаться сложными предварительные условия тестов, или же изменения состояния, или побочные эффекты. Подобная сложность потребует разбиения тестов на несколько шагов. В этой модели, состоящей из трех частей, важно то, что установка, выполнение и ожидаемые результаты отделены друг от друга. Модель применима к весьма широкому спектру тестов. Если нужно убедиться, что вода достаточно горячая для приготовления еще одной чашки чая, будет выполнен примерно следующий набор шагов:

```shell
GIVEN (задано) чаиник с водои на плите
AND (и) горелка выключена
WHEN (когда) открывается крышка чаиника 
THEN (тогда ) виден выходящи и пар
```

Этот паттерн идеально подходит для проверки наличия четкой установки и наблюдаемого результата.

Допустим, нужно создать функцию для вычисления среднего значения списка чисел, которые встречаются в последовательности, исключая значения **`None`**. Можно было бы начать так:

```python
def average(data: list[Optional[int]]) -> float:
	"""
	GIVEN a list, data = [1, 2, None, 3, 4]
	WHEN we compute m = average(data)
	THEN the result, m, is 2.5
	"""
```

Получился набросок определения функции с кратким видением характера ее поведения. На шаге **GIVEN** определяются данные для проведения тестирования. На шаге **WHEN** точно определяются намерения. Наконец, на шаге **THEN** описываются ожидаемые результаты. Средство автоматизированного тестирования способно сравнивать фактические результаты с заявленными ожиданиями и сообщать о непрохождении теста. Затем все это можно превратить в отдельный тестовый класс или функцию, используя предпочтительную среду тестирования. Способы реализации концепции **`unittest`** и **`pytest`** немного различаются, но основная концепция выдерживается в обеих средах. По готовности тест должен провалиться, и можно будет приступать к созданию реального кода, считая этот тест той самой линией ворот, которую нужно пересечь.

К методам, способствующим разработке тестовых сценариев, относятся эквивалентное разбиение и анализ граничных значений. Они помогают разбить область всех возможных входных данных для метода или функции на разделы. Типичным примером является определение двух разделов: «допустимые данные» и «недопустимые данные» . Исходя из характеристик разделов, значения на их границах представляют интерес для использования в тестовых сценариях. Дополнительные сведения можно найти по адресу https://www.softwaretestinghelp.com/what-is-boundary-value-analysis-and-equivalence-partitioning/.

Итак, начнем с изучения встроенной среды тестирования **`unittest`**. Недостатком этой среды считается многословность и сложный внешний вид. А преимущество заключается в том, что она является встроенной и доступной к немедленному применению без дополнительной установки.





## Проведение модульного тестирования с помощью `unittest`
---

Начнем исследование со встроенной тестовой библиотеки Python, предоставляющей общий объектно-ориентированный интерфейс для проведения модульных тестов. Неудивительно, что соответствующая библиотека Python называется **`unittest`**. Она содержит ряд инструментов для создания и запуска модульных тестов, наиболее важным из которых является класс **`TestCase`**. ( Названия-идентификаторы следуют стилю именования Java, поэтому многие имена методов не слишком похожи на используемые в языке Python.) Класс **`TestCase`** предоставляет набор методов, позволяющих сравнивать значения, настраивать тесты и очищать их по завершении.

Когда нужно создать набор модульных тестов для выполнения конкретной задачи, создается подкласс **`TestCase`** и пишутся отдельные методы для проведения тестирования. Все методы должны начинаться с имени **`test`**. При соблюдении этого соглашения тесты автоматически запускаются как часть процесса тестирования. Для простых примеров концепции **GIVEN**, **WHEN** и **THEN** можно объединить в тестовый метод. Рассмотрим простейший пример:

```python
import unittest 
  

class CheckNumbers(unittest.TestCase):
    def test_int_float(self) -> None:
        self.assertEqual(1, 1.0)
  
if __name__ == "__main__":
    unittest.main()
```

Здесь создается подкласс класса **`TestCase`** и добавляется метод, вызывающий метод **`TestCase.assertEqual()`** . Шаг **GIVEN** состоит из задания пары значений - `1` и `1.0`. Шаг **WHEN** является своеобразным вырожденным примером, поскольку новый объект не создается и изменение состояния не происходит. Шаг **THEN** является проверкой равенства двух значений.

При запуске сценария тестирования этот метод в зависимости от того, равны два параметра или нет, либо завершится успешно, либо вызовет исключение. Если запустить данный код, функция main из **`unittest`** выведет следующее сообщение:

```powershell
.
---------------------------------------------------------------------
Ran 1 test in 0.000s

OK
```

А вы знали, что числа с плавающей точкой и целые числа можно проверять на равенство?

Давайте добавим сюда еще и заведомо провальный тест:

```python
def test_str_float(self) -> None:
	self.assertEqual(1, "1")
```

Сообщение, выводимое данным кодом, носит более печальный характер, поскольку целые числа и строки не могут считаться равными друг другу:

```powershell
.F
======================================================================
FAIL: test_str_float (__main__.CheckNumbers.test_str_float)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "E:\DEVeloping_aNd_practice\OOP_PYTHON_4-th_edition\13_OOP_tests\check_numbers_test.py", line 9, in test_str_float
    self.assertEqual(1, "1")
AssertionError: 1 != '1'

----------------------------------------------------------------------
Ran 2 tests in 0.001s

FAILED (failures=1)
```

Точка в первой строке означает, что первый (ранее написанный) тест пройден успешно, а буква **`F`** после нее показывает, что второй тест не пройден. Затем, в конце, дается информационная сводка, в которой рассказывается, как и где тест провалился, а также подсчитывается количество неудач.

Даже код возврата на уровне операционной системы предоставляет полезную сводку. Код возврата равен нулю, если все тесты пройдены успешно, и не равен нулю, если какие-либо из тестов не пройдены. Это помогает при создании инструментов непрерывной интеграции: если запуск **`unittest`** будет провален, в предлагаемом изменении нужно отказать.

В одном классе **`TestCase`** может быть сколько угодно тестовых методов. Программа запуска тестов будет выполнять в качестве отдельного изолированного теста каждый из методов, имя которого начинается с **`test`**.

>[!info]
>Каждый тест должен быть полностью независим от других тестов.
>Результаты или расчеты теста не должны влиять на любой другой тест.

Чтобы тесты были изолированы друг от друга, можно создать несколько тестов с общим шагом **GIVEN**, который реализован общим методом **`setUp()`**. При этом предполагается довольно частое использование похожих классов, и для разработки тестов нужно использовать наследование, позволяющее им иметь общие функции, но при этом оставаться полностью независимыми.

Основой создания высококачественных модульных тестов является предельная минимализация каждого тестового метода и тестирование в каждом сценарии сравнительно небольшого модуля. Если не представляется возможным разбить код на небольшие тестируемые модули естественным образом, то, скорее всего, это является признаком необходимости его переработки. Способ изоляции объектов в целях тестирования рассматривается далее в разделе  *Имитация объектов с помощью моков*.

Модуль **`unittest`** требует структуризации тестов в виде определения класса. Это в некотором роде усложняет процесс. В пакете **`pytest`** предлагается более разумное представление о тестах и немного более гибкий способ построения тестов как функций, а не методов класса. Теперь посмотрим, что собой представляет **`pytest`**.





## Проведение модульного тестирования с помощью [[pytest]]
---

Модульные тесты могут создаваться с помощью библиотеки, предоставляющей общую структуру для тестовых сценариев и средство запуска тестов для их выполнения и протоколирования результатов. Модульные тесты специализируются на проверке в любом отдельно взятом тесте наименьшего возможного количества кода. Стандартная библиотека включает пакет **`unittest`**. Но, несмотря на его довольно широкое использование, он вынуждает создавать для каждого теста изрядное количество шаблонного кода.

В числе наиболее популярных альтернатив стандартной библиотеке **`unittest`** можно выделить такое средство, как [[pytest]]. ==Его преимущество заключается в возможности написания более мелких и понятных тестовых сценариев. Отсутствие ненужных усложнений вызывает повышенный интерес к этому альтернативному варианту.==

Поскольку **`pytest`** не входит в стандартную библиотеку, это средство необходимо скачивать и устанавливать самостоятельно. Получить его можно на домашней странице **`pytest`** по адресу https://docs.pytest.org/en/stable/, а для установки воспользоваться любым из инсталляторов.

В окне терминала нужно активировать ту виртуальную среду, в которой ведется работа. (Если, к примеру, тестирование происходит в `venv`, можно выполнить команду `python -m venv с:\path\to\myenv`.) А затем следует воспользоваться командой операционной системы, например следующей:

```shell
% python -m pip install pytest
```
Команда для Windows должна быть такой же, как команда для macOS и Linux.

Средство **`pytest`** использует структуру теста, существенно отличающуюся от той, что применяется в модуле **`unittest`**. От тестовых сценариев не требуется быть подклассами **`unittest.TestCase`**. Вместо этого **`pytest`** опирается на факт принадлежности функций Python к объектам первого класса, что позволяет любой надлежаще названной функции вести себя как тест. Вместо подтверждения равенства с помощью целого набора специализированных методов этим средством для проверки результатов используется инструкция **`assert`**. Таким образом упрощаются тесты и их понимание и, следовательно, облегчается их сопровождение.

При запуске **`pytest`** это средство начинает работать в текущей папке и приступает к поиску любых модулей или подпакетов с именами, предваряемыми префиксом **`test_`**. (С обязательным присутствием символа **`_`**. ) Если какие-либо функции в данном модуле также начинаются с **`test`** (при этом символ **`_`** для них не требуется), они будут выполняться как отдельно взятые тесты. Кроме того, если в модуле есть какие-либо классы, имя которых начинается с **`Test`**, любые методы этих классов, начинающиеся с **`test`**, также будут выполняться в тестовой среде.

Поиск, как ни удивительно, также ведется в папке с именем **`tests`**. Из-за этого код обычно разбивается на две папки: в каталоге **`src/`** содержится рабочий модуль, библиотека или приложение, а в каталоге **`test/`** - все тестовые сценарии.

Перенесем простой пример **`unittest`**, написанный ранее, в **`pytest`**, используя следующий код:

```python
def test_int_float() -> None:
	assert 1 == 1.0
```

Для выполнения точно такого же теста были написаны две строки более удобного для восприятия кода по сравнению с теми шестью строками, которые были нужны в нашем первом примере модульного тестирования.

Но создавать тесты на основе классов здесь также не запрещено. Классы могут пригодиться для применения групп связанных тестов или тестов, которым требуется доступ к связанным атрибутам или методам класса. В следующем примере показан расширенный класс с заведомо проходимым и непроходимым тестами, так нам можно будет убедиться, что вывод сведений об ошибке здесь информативнее, чем тот, который предоставлялся модулем **`unittest`**:

```python
class TestNumbers:
    def test_int_float(self) -> None:
        assert 1 == 1.0

    def test_str_float(self) -> None:
        assert 1 == "1"
```

Заметьте, что классу не нужно служить расширением каких-либо специальных объектов, которые будут обнаружены в качестве тестового сценария (хотя в **`pytest`** без проблем запускаются стандартные тестовые сценарии **`TestCases`** из арсенала **`unittest`**). При запуске команды **`python -m pytesttests/< имя_фaйлa >`** результат будет иметь следующий вид:

```bash
% python -m pytest tests/test_check_number.py
================= test session starts ==============================
platform win32 -- Python 3.11.8, pytest-8.2.2, pluggy-1.5.0
rootdir: D:\Developing_and_practice\OOP_Python_4-th_edition\13_OOP_tests
collected 2 items                                                                                                                                                                        
tests\test_check_number.py .F    [100%]
================== FAILURES ======================================== 
____________TestNumbers.test_str_float _____________________________

self = <test_check_number.TestNumbers object at 0x000001EFA4AA56D0>

    def test_str_float(self) -> None:
>       assert 1 == "1"
E       AssertionError: assert 1 == '1'

tests\test_check_number.py:6: AssertionError
================================================================================ short test summary info =================================
FAILED tests/test_check_number.py::TestNumbers::test_str_float - AssertionError: assert 1 == '1'
============================================================================== 1 failed, 1 passed in 0.11s ===============================
```

Выведенная на экран информация начинается с полезных сведений о платформе и интерпретаторе. Они могут пригодиться для обмена или обсуждения ошибок в разных системах. В третьей строке сообщается имя тестируемого файла (если выбрано сразу несколько тестируемых модулей, то все они будут отображаться), за которым следует уже знакомая последовательность **`.F`**, встречавшаяся при работе с модулем **`unittest`**. Символ точки (**`.`**) указывает на пройденный тест, а буква **`F`** - на непройденный.

После выполнения всех тестов для каждого из них выводится информация об ошибках. В ней представлены сводка локальных переменных (в данном примере только одна переменная: переданный в функцию параметр **`self`**), исходный код, в котором произошли ошибки, и сводка сообщений об ошибках. Кроме того, при выдаче исключений, отличных от **`Assertion Error`**, средство **`pytest`** предоставит полную трассировку, включая ссылки на исходный код.

Если тест пройден успешно, **`pytest`** подавляет вывод из функции **`print()`**. Это может пригодиться для отладки тестов, поскольку, когда тест проваливается, в него можно добавить инструкции **`print()`** , чтобы проверить значения тех или иных переменных и атрибутов в ходе выполнения теста.

Если тест не пройден, эти значения выводятся на экран, помогая выявить недочеты. Но после успешного прохождения теста вывод функции **`print()`** не отображается и его легко будет проигнорировать. То есть очищать вывод теста путем удаления функций **`print()`** не понадобится. Если из-за последующих изменений тесты снова не будут пройдены, отладочный вывод тут же снова будет доступен.

Примечательно, что подобное использование инструкции **`assert`** создает потенциальную проблему для mуру. При использовании инструкции **`assert`** средство **`mуру`** может проверить типы и предупредить нас о потенциальной проблеме с **`assert 1 == "1"`**. Этот код вряд ли будет приемлемым, и он не пройдет не только модульный тест, но и проверку **`mуру`**.

Ну что ж, поддержка со стороны **`pytest`** шагов **WHEN** и **THEN** с использованием функции и инструкции **`assert`** рассмотрена. Осталось выяснить, как можно справиться с шагом **GIVEN**. Для задания предварительных условий теста с помощью шага **GIVEN** существует два способа. Начнем с того, который предназначен для простых случаев.




### Функции настройки и демонтажа `pytest`
---

Средством **`pytest`** поддерживаются возможности установки и демонтажа, подобные методам, используемым в **`unittest`**, но при этом предоставляется большая гибкость. Соответствующие основные функции будут вкратце изучены сейчас. А в следующем разделе предстоит рассмотрение весьма эффективных возможностей использования [[Фикстуры|фикстур]](fixtures), предоставляемых средством **`pytest`**.

Если тесты создаются на основе классов, можно воспользоваться двумя методами: **`setup_method()`** и **`teardown_method()`**. Они вызываются до и после каждого тестового метода в классе с целью выполнения задач по настройке и очистке соответственно.

Кроме этого, средством **`pytest`** предоставляются и другие функции настройки и демонтажа, позволяющие расширить возможности контроля над выполнением кода подготовки и очистки. Предполагается, что методы **`setup_class()`** и **`teardown_class()`** будут методами класса, принимающими один аргумент, который представляет данный класс (аргумента **`self`** нет, поскольку нет экземпляра; вместо этого предоставляется класс). Эти методы запускаются средством **`pytest`** не при каждом тестовом прогоне, а при запуске класса.

И наконец, в нашем распоряжении имеются функции **`setup_module()`** и **`teardown_module()`**, запускаемые **`pytest`** непосредственно до и после выполнения всех тестов (в функциях или классах) в данном модуле. Они могут пригодиться для одноразовой настройки, например для создания сокета или подключения к базе данных, которые будут использоваться всеми тестами в модуле. Но здесь нужно проявить осмотрительность, поскольку можно случайно спровоцировать зависимость тестов друг от друга, если какое-то из состояний объекта не будет должным образом очищено между запусками тестов.

По данному краткому описанию трудно составить представление о том, когда именно вызываются эти методы. Поэтому рассмотрим пример, который четко иллюстрирует нужные моменты:

```python
from typing import Any, Callable
  

def setup_module(module: Any) -> None:
    print(f"setting up MODULE {module.__name__}")

  
def teardown_module(module: Any) -> None:
    print(f"tearing down MODULE {module.__name__}")
  

def test_a_function() -> None:
    print("RUNNING TEST FUNCTION")
  

class BaseTest:
    @classmethod
    def setup_class(cls: type["BaseTest"]) -> None:
        print(f"setting up CLASS {cls.__name__}\n")

    @classmethod
    def teardown_class(cls: type["BaseTest"]) -> None:
        print(f"tearing down CLASS {cls.__name__}\n")

    def setup_method(self, method: Callable[[], None]) -> None:
        print(f"setting up METHOD {method.__name__}")

    def teardown_method(self, method: Callable[[], None]) -> None:
        print(f"tearing down METHOD {method.__name__}")

  
class TestClass1(BaseTest):
    def test_method_1(self) -> None:
        print("RUNNING METHOD 1-1")

    def test_method_2(self) -> None:
        print("RUNNING METHOD 1-2")


class TestClass2(BaseTest):
    def test_method_1(self) -> None:
        print("RUNNING METHOD 2-1")

    def test_method_2(self) -> None:
        print("RUNNING METHOD 2-2")
```

Единственным предназначением класса **`BaseTest`** является извлечение четырех методов, которые в остальном идентичны двум тестовым классам, и использование наследования для сокращения объема повторяющегося кода. Итак, с позиции **`pytest`** у двух подклассов имеются не только два метода тестирования, но также два метода настройки и два метода демонтажа (один на уровне класса, один на уровне метода).\

Если запустить данные тесты с помощью **`pytest`** с отключенным подавлением вывода функции **`print()`** (путем установки флажка **`-s`** или **`--capture=no`**), будет видна очередность вызова различных функций и самих тестов:

```shell
==================== test session starts ===========================
platform win32 -- Python 3.11.8, pytest-8.2.2, pluggy-1.5.0
rootdir: D:\DeVEloping_aNd_practice\OOP_PYTHON_4-th_edition\13_OOP_tests
collected 5 items

tests\test_setup_teardown.py setting up MODULE test_setup_teardown
RUNNING TEST FUNCTION
.setting up CLASS TestClass1

setting up METHOD test_method_1
RUNNING METHOD 1-1
.tearing down METHOD test_method_1
setting up METHOD test_method_2
RUNNING METHOD 1-2
.tearing down METHOD test_method_2
tearing down CLASS TestClass1

setting up CLASS TestClass2

setting up METHOD test_method_1
RUNNING METHOD 2-1
.tearing down METHOD test_method_1
setting up METHOD test_method_2
RUNNING METHOD 2-2
.tearing down METHOD test_method_2
tearing down CLASS TestClass2

tearing down MODULE test_setup_teardown


=========================5 passed in 0.05s ==========================
```

Методы настройки и демонтажа для модуля как единого целого выполняются в начале и в конце сеанса. А между ними запускается единственная тестовая функция на уровне модуля. Потом выполняется метод настройки для первого класса, за которым следуют два теста для этого класса. Каждый из этих тестов сам по себе заключен в отдельные вызовы **`setup_method()`** и **`teardown_method()`**. После выполнения тестов вызывается метод демонтажа класса. Такая же последовательность действует и для второго класса, после чего происходит однократный вызов метода **`teardown_module()`**.

Хотя в соответствии с именами данных функций предполагается предоставление множества вариантов выполнения тестирования, зачастую будут задействоваться условия настройки, являющиеся общими сразу для нескольких тестовых сценариев. Их можно многократно использовать, применяя конструкции, основанные на композиции; в **`pytest`** такие конструкции называются фикстурами (fixtures). Именно их мы сейчас и рассмотрим.




### Фикстуры `pytest`, предназначенные для настройки и демонтажа
---

Одним из наиболее распространенных вариантов применения различных функций настройки является обеспечение подготовки для теста шага **GIVEN**. Зачастую под этим подразумевается создание объектов и обеспечение у конкретных переменных класса или модуля известных значений. Это необходимо проводить перед запуском метода тестирования.

В дополнение к набору имен специальных методов для тестового класса **`pytest`** предлагает проводить настройку тестов совершенно оригинальным методом, используя так называемые **фикстуры**. Они являются функциями построения условия **GIVEN** до выполнения шага **WHEN**.

У средства **`pytest`** имеется целый ряд встроенных фикстур. Кроме этого, фикстуры можно определять в файле конфигурации с их последующим многократным использованием, а уникальные фикстуры допустимо определять в качестве части самих тестов. Это позволяет отделить настройку тестов от их выполнения и использовать фикстуры сразу в нескольких классах и модулях.

Рассмотрим класс, выполняющий несколько вычислений, подлежащих тестированию.

```python
import collections
from typing import List, Optional, DefaultDict

class StatsList(List[Optional[float]]):
    """Stats with None objects rejected"""

    def mean(self) -> float:
        clean = list(filter(None, self))
        return sum(clean) / len(clean)

    def median(self) -> float:
        clean = list(filter(None, self))
        if len(clean) % 2:
            return clean[len(clean) // 2]
        else:
            idx = len(clean) // 2
            return (clean[idx] + clean[idx - 1]) / 2

    def mode(self) -> list[float]:
        freqs: DefaultDict[float, int] = collections.defaultdict(int)
        for item in filter(None, self):
            freqs[item] += 1
        mode_freq = max(freqs.values())
        modes = [item for item, value in freqs.items()
                 if value == mode_freq]
        return modes
```

Данный класс расширяет встроенный класс **`list`** путем добавления трех методов статистической сводки: **`mean()`**, **`median()`**  и **`mode()`**. Каждому методу нужен некоторый набор доступных для использования данных; конфигурация **`StatsList`** с известными данными и будет тестируемой фикстурой.

Для использования фикстуры с целью создания предварительного условия **GIVEN** в тестовую функцию в качестве параметра добавляется имя фикстуры. При запуске теста имена параметров тестовой функции будут располагаться в коллекции фикстур, и эти функции создания фикстур будут выполняться в автоматическом режиме.

Например, чтобы протестировать класс **`StatsList`**, требуется многократное предоставление списка допустимых целых чисел. Соответствующие тесты можно написать следующим образом:

```python
import pytest
from stats import StatsList


@pytest.fixture
def valid_stats() -> StatsList:
    return StatsList([1, 2, 2, 3, 3, 4])


def test_mean(valid_stats: StatsList) -> None:
    assert valid_stats.mean() == 2.5


def test_median(valid_stats: StatsList) -> None:
    assert valid_stats.median() == 2.5
    valid_stats.append(4)
    assert valid_stats.median() == 3


def test_mode(valid_stats: StatsList) -> None:
    assert valid_stats.mode() == [2, 3]
    valid_stats.remove(2)
    assert valid_stats.mode() == [3]
```
```powershell
python -m pytest --capture=no tests/test_stats.py
======================== test session starts=========================
platform win32 -- Python 3.11.8, pytest-8.2.2, pluggy-1.5.0
rootdir: D:\DEVELoping_and_practice\OOP_PY_4-th_edition\13_OOP_tests
collected 3 items                                               

tests\test_stats.py ...

======================== 3 passed in 0.03s ==========================
```

Каждая из трех тестовых функций принимает параметр с именем **`valid_stats`**, создающийся средством **`pytest`**, в результате чего автоматически вызывается функция **`valid_stats`**. В функцию добавлен декоратор **`@руtеst.fixture`**, позволяющий **`pytest`** использовать ее особым образом.

Разумеется, имена должны совпадать. Среда выполнения **`pytest`** ищет те функции с декоратором **`@fixture`**, которые совпадают с именем параметра.

Возможности фикстур гораздо шире, чем только возвращение простых объектов. Для предоставления весьма полезных методов и атрибутов, изменяющих поведение фикстуры, в фабрику фикстур может передаваться объект **`request`**. Тест, запрашивающий фикстуру, позволяет четко определять такие атрибуты объекта **`request`**, как **`module`**, **`cls`** и **`function`**. Атрибут **`config`** объекта **`request`** предназначен для проверки аргументов командной строки и многих других данных конфигурации.

Если фикстура реализуется в виде генератора, она может также запускать код очистки после каждого запуска теста. В результате получается эквивалент метода демонтажа для каждой фикстуры. Им можно воспользоваться для очистки файлов, закрытия соединений, пустых списков или сброса очередей. Для модульных тестов с изолированными элементами применение имитирующего объекта представляется более рациональным замыслом, чем выполнение демонтажа объекта, имеющего внутреннее состояние. Далее, в разделе «Имитация объектов с помощью моков>. описан более простой подход, идеально подходящий для модульного тестирования.

При проведении интеграционных тестов может потребоваться протестировать какой-либо код, создающий, удаляющий или обновляющий файлы. При записи файлов с возможностью их последующего удаления часто используется фикстура **`pytest tmp_path`**, что избавляет от необходимости выполнять демонтаж в самом тесте. Потребности в демонтаже при модульном тестировании возникают довольно редко, но он может пригодиться для остановки тех подпроцессов или удаления тех изменений базы данных, которые являются частью интеграционного теста. Подобная ситуация будет показана в текущем разделе чуть позже. А сначала рассмотрим небольшой пример фикстуры с возможностью настройки и демонтажа.

Чтобы осмыслить замысел фикстуры, выполняющей как настройку, так и демонтаж, проанализируем небольшой программный код, создающий резервную копию файла и записывающий новый файл с контрольной суммой существующего файла:

```python
import tarfile
from pathlib import Path
import hashlib


def checksum(source: Path, checksum_path: Path) -> None:
    if checksum_path.exists():
        backup = checksum_path.with_stem(f"(old)                                      {checksum_path.stem}")
        backup.write_text(checksum_path.read_text())
    checksum = hashlib.sha256(source.read_bytes())
    checksum_path.write_text(f"{source.name}                                               {checksum.hexdigest()}\n")
```

Есть два возможных сценария.

- Исходный файл действительно существует, и в каталог добавляется новая контрольная сумма.
- Существует как исходный файл, так и файл контрольной суммы. В данном случае делается резервная копия старой контрольной суммы и записывается новая контрольная сумма.

Не станем здесь тестировать оба сценария, покажем, как фикстура может создавать, а затем удалять файлы, необходимые для тестовой последовательности. Сосредоточимся на втором сценарии, поскольку он сложнее первого. Разобьем тестирование на две части и начнем с фикстуры:

```python
import checksum_writer
import pytest
from pathlib import Path
from typing import Iterator
import sys


@pytest.fixture
def working_directory(tmp_path: Path) -> Iterator[tuple[Path, Path]]:
    working = tmp_path / "some_directory"
    working.mkdir()
    source = working / "data.txt"
    source.write_bytes(b"Hello, world!\n")
    checksum = working / "checksum.txt"
    checksum.write_text("data.txt Old_Checksum")
    
    yield source, checksum
    
    checksum.unlink()
    source.unlink()

```

Работа этого кода основана на применении инструкции **`yield`**. Фактически фикстура является генератором, выдающим один результат и ожидающим следующего запроса значения. Первым результатом становится выполнение целого ряда шагов: создание рабочего каталога, создание в нем исходного файла, а затем создание старого файла контрольной суммы. Инструкция **`yield`** предоставляет два пути к тесту и ожидает следующий запрос. Этими действиями завершается настройка условия **GIVEN** для теста.

По завершении тестовой функции **`pytest`** предпримет попытку получения из упомянутой фикстуры одного последнего элемента. Это позволит функции разъединить файлы, удалив их. Отсутствие возвращаемого значения сигнализирует об окончании итерации. Помимо использования протокола генератора, в фикстуре **`working_directory`** используется *руtеst-фикстура* **`tmp_path`**, имеющая целью создание временного рабочего местоположения для данного теста.

Тест, использующий фикстуру **`work_directory`**, имеет следующий вид:

```python
@pytest.mark.skipif(sys.version_info < (3, 9), reason="requires python3.9 feature")
def test_checksum(working_directory: tuple[Path, Path]) -> None:
    source_path, old_checksum_path = working_directory
    checksum_writer.checksum(source_path, old_checksum_path)
    backup = old_checksum_path.with_stem(f"(old) {old_checksum_path.stem}")
    assert backup.exists()
    assert old_checksum_path.exists()
    name, checksum = old_checksum_path.read_text().rstrip().split()
    assert name == source_path.name
    assert (
        checksum == "d9014c4624844aa5bac314773d6b689a"
        "d467fa4e1d1a50a1b8a99d5a95f72ff5"
    )
```

Что примечательно, в тесте имеется условие пропуска **`skipif`**, поскольку в Python 3.8 данный тест работать не будет по причине того, что метод **`with_stem()`** объекта **`Path`** не является частью старой реализации **`pathlib`**. То есть тест существует, но при этом отмечается его непригодность для конкретной версии Python. Дополнительно эта ситуация будет рассмотрена далее в этой же главе, в подразделе � Пропуск тестов с помощью **`pytest`**•.

Ссылка на фикстуру **`work_directory`** заставляет **`pytest`** выполнять функцию фикстуры, которая предоставляет тестовому сценарию два пути, используемые как часть условия **GIVEN** перед тестированием. На шаге **WHEN** вычисляется значение функции **`checksum_writer.checksum()`** с этими двумя путями. Шаги **THEN** представляют собой последовательность инструкций **`assert`**, позволяющих убедиться, что файлы созданы с ожидаемыми значениями. После запуска теста для получения из фикстуры другого элемента средством **`pytest`** будет использоваться метод **`next()`**; это действие производится кодом после выполнения инструкции **`yield`**, что приводит к проведению демонтажа по окончании теста.

При тестировании изолированных друг от друга компонентов потребность в частом применении функции демонтажа фикстуры не возникает. Но для интеграционных тестов в условиях совместного использования сразу нескольких компонентов может потребоваться остановка процессов или удаление файлов. В следующем разделе будет рассмотрена фикстура посложнее. Этот тип фикстур может использоваться более чем одним тестовым сценарием.




### Более сложные фикстуры
---

Для создания фикстуры, рассчитанной более чем на один тест, можно передать параметр области видимости. Это пригодится при настройке высокозатратной операции, которая может повторно использоваться в нескольких тестах, но только при условии, что повторное использование ресурсов не нарушает атомарную или модульную природу теста: на нее не должен полагаться или оказывать свое влияние ни один из модульных тестов.

==В качестве примера определим сервер, являющийся частью клиент-серверного приложения. Необходимо, чтобы сразу несколько веб-серверов отправляли свои журнальные сообщения в один централизованный журнал. В дополнение к изолированным модульным тестам следует иметь интеграционный тест, который позволит убедиться в правильной интеграции веб-сервера и сборщика журналов друг с другом. Интеграционный тест должен запускать и останавливать сервер сбора журналов.== Пирамида тестирования, таким образом, состоит как минимум из трех уровней. Модульные тесты будут основой, проверяющей каждый компонент по отдельности. Интеграционные тесты станут серединой пирамиды, обеспечивающей правильную интеграцию компонентов друг с другом. Системный или приемочный тест явит собой вершину пирамиды, гарантирующую, что весь набор программного средства выполняет заявленные функции.

Рассмотрим сервер сбора журналов, принимающий сообщения и записывающий их в один центральный файл. Эти сообщения определяются в модуле ведения журнала **`SocketHandler`**. Каждое сообщение может быть представлено в виде блока байтов с заголовком и полезным информационным наполнением. Структура с использованием фрагментов блока байтов показана в таблице ниже.

Сообщение определяется следующим образом.

| Начало фрагмента | Конец фрагмента | Значение     | Модуль и функция Python для разбора |
| ---------------- | --------------- | ------------ | ----------------------------------- |
| 0                | 4               | payload_size | **`struct.unpack(">L", bytes)`**    |
| 4                | payload_size+4  | payload      | **`pickle.loads(bytes)`**           |

Размер заголовка показан в виде четырехбайтного фрагмента, но размер, указанный здесь, может ввести в заблуждение. Заголовок формально и официально определяется строкой формата, используемой модулем struct вида **`">L"`** . В модуле **`struct`** имеется функция **`calcsize()`** , позволяющая вычислить фактическую длину из строки формата. Вместо использования литерала 4, полученного из размера формата **`">L"`** , код будет получать размер, **`size_bytes`**, из строки формата размера, **`size_format`**. Использование одного подходящего источника **`size_format`** для обеих частей информации соответствует принципу проектирования « Не повторяйся >>.

Ниже приводится буфер примера со встроенным в него сообщением от модуля ведения журнала **`logging`**. Первая строка - заголовок с размером полезного информационного наполнения в виде четырехбайтного значения. Следующие строки представляют собой данные, отобранные для сообщения журнала:

Чтобы прочитать эти сообщения, сначала нужно получить байты размера полезной нагрузки. Затем становится возможным потреблять следующую полезную нагрузку. Сокет-сервер, читающий заголовки и полезные данные и записывающий их в файл, имеет следующий вид:

```python
import json
from pathlib import Path
import socketserver
from typing import TextIO
import pickle
import struct
import sys


class LogDataCatcher(socketserver.BaseRequestHandler):
    log_file: TextIO
    count: int = 0
    size_format = ">L"
    size_bytes = struct.calcsize(size_format)

    def handle(self) -> None:
        size_header_bytes =                                                      self.request.recv(LogDataCatcher.size_bytes)
        while size_header_bytes:
            payload_size = struct.unpack(LogDataCatcher.size_format,                                         size_header_bytes)
            print(f"{size_header_bytes=} {payload_size=}",                               file=sys.stderr)
            payload_bytes = self.request.recv(payload_size[0])
            print(f"{len(payload_bytes)=}", file=sys.stderr)
            payload = pickle.loads(payload_bytes)
            LogDataCatcher.count += 1
            print(f"{self.client_address[0]} {LogDataCatcher.count}                                         {payload!r}")
            self.log_file.write(json.dumps(payload) + "\n")
            try:
                size_header_bytes =                                                       self.request.recv(LogDataCatcher.size_bytes)
            except (ConnectionResetError, BrokenPipeError):
                break


def main(host: str, port: int, target: Path) -> None:
    with target.open("w") as unified_log:
        LogDataCatcher.log_file = unified_log
        with socketserver.TCPServer((host, port), LogDataCatcher) as             server:
            server.serve_forever()


if __name__ == "__main__":
    HOST, PORT = "localhost", 18842
    main(HOST, PORT, Path("one.log"))
```

Объект **`socketserver.TCPServer`** отслеживает запросы на подключение, исходящие от клиента. При подключении клиента объектом создается экземпляр класса **`LogDataCatcher`** и запускается метод этого объекта **`handle()`** , предназначенный для сбора данных от подключившегося клиента. Метод **`handle()`** в два этапа декодирует размер и полезную нагрузку. Сначала он считывает несколько байтов для определения размера полезной нагрузки. Для декодирования этих байтов в нужное числовое значение **`payload_size`** он использует метод **`struct.unpack()`** , а затем для получения полезной нагрузки считывает заданное количество байтов. Руthоn-объект будет загружен из байтов полезной нагрузки методом **`pickle.loads()`**. А с помощью метода **`json.dumps()`** будет выполнена сериализация в JSОN-нотацию и запись в открытый файл. Как только сообщение окажется обработано, код попытается прочитать следующие несколько байтов, чтобы понять, имеются ли еще данные, ожидающие обработки. Этот сервер будет принимать сообщения от клиента до тех пор, пока соединение не будет разорвано, в результате чего возникнет ошибка чтения и выход из цикла выполнения инструкции **`while`**.

Такой сервер сбора регистрационных записей может принимать сообщения журналов от приложения из любого места в сети. Здесь приведен однопоточный пример реализации, то есть одновременно обрабатывается только один клиент. Для создания многопоточного сервера можно воспользоваться дополнительными миксинами, принимающими сообщения из нескольких источников. В приведенном примере основное внимание уделяется тестированию одного приложения, зависящего от этого сервера.

Для полноты картины рассмотрим основной сценарий запуска сервера:

```python
if __name__ == "__main__":
    HOST, PORT = "localhost", 18842
    main(HOST, PORT, Path("one.log"))
```

Здесь предоставляются IР-адрес хоста, номер порта и файл, в который следует записывать все сообщения. В реальной работе для передачи этих значений приложению можно было бы рассмотреть возможность использования модуля **`argparse`** и словаря **`os.environ`**. Но в этой реализации они задаются конкретными значениями.

Приложение `remote_logging_app.ру`, передающее журнальные записи на сервер, отслеживающий журнальные файлы, имеет следующий вид:

```python
import logging
import logging.handlers
import time
import sys
from math import factorial

logger = logging.getLogger("app")


def work(i: int) -> int:
    logger.info("Factorial %d", i)
    f = factorial(i)
    logger.info("Factorial(%d) = %d", i, f)
    return f


if __name__ == "__main__":
    HOST, PORT = "localhost", 18842
    socket_handler = logging.handlers.SocketHandler(HOST, PORT)
    stream_handler = logging.StreamHandler(sys.stderr)
    logging.basicConfig(handlers=[socket_handler, stream_handler],                           level=logging.INFO)

    for i in range(10):
        work(i)

    logging.shutdown()
```

В приложении создаются два обработчика журналов. Экземпляр **`SocketHandler`** открывает сокет и порт с конкретным номером на заданном сервере и начинает запись байтов. Байты включают заголовки и полезные данные. Экземпляр **`StreamHandler`** ведет запись в окно терминала; это исходный обработчик журнала, который был бы достаточен, если бы не создавались никакие специальные обработчики. Регистратор настраивается с обоими обработчиками, позволяющими отправлять каждое сообщение журнала как на консоль, так и на потоковый сервер, собирающий сообщения. А в чем заключается реальная работа? В математических расчетах факториала числа. При каждом запуске приложения им должно выводиться 20 сообщений журнала.

Чтобы протестировать совместную работу клиента и сервера, нужно запустить сервер в отдельном процессе. Не хотелось бы проводить его многократный запуск и остановку (поскольку на это уходит много времени), поэтому он запускается один раз и используется в нескольких тестах. Весь процесс разбит на две части и начинается с двух фикстур:

```python
from __future__ import annotations
import logging
from pathlib import Path
import pytest
import subprocess
import signal
import sys
import time
import remote_logging_app
from typing import Iterator, Any

@pytest.fixture
def logging_config() -> Iterator[None]:
    HOST, PORT = "localhost", 18842
    socket_handler = logging.handlers.SocketHandler(HOST, PORT)
    remote_logging_app.logger.addHandler(socket_handler)
    yield
    socket_handler.close()
    remote_logging_app.logger.removeHandler(socket_handler)

```

Фикстура **`log_catcher`** запускает в качестве подпроцесса сервер **`log_catcher.ру`**. Для этого в дeкopaтope **`@fixture`** задана область видимости **`"session"`** , означающая, что все делается один раз для всего сеанса тестирования. Область видимости задается одним из строковых значений **`"function"`** , **`"class"`** , **`"module"`**, **`"package"`** или **`"session"`** , при этом предоставляются различные места создания и многократного использования фикстуры. При запуске выдерживается небольшая пауза (250 мс), позволяющая гарантировать нормальный запуск другого процесса. Когда выполнение кода фикстуры дойдет до инструкции **`yield`**, описанная часть настройки теста **GIVEN** будет выполнена.

Фикстура **`logging_config`** занимается изменением конфигурации журнала для тестируемого модуля **`remote_logging_app`**. Функция **`work()`** в модуле **`remote_logging_app.ру`**, судя по коду, ожидает объект регистрационной записи на уровне модуля. Этой тестовой фикстурой создается объект **`SocketHandler`**, который добавляется в **`logger`**, и затем выполняется инструкция **`yield`**.

После того как в условие **GIVEN** внесли свой вклад обе эти фикстуры, можно определить тестовые сценарии, содержащие шаги **WHEN**. Рассмотрим два примера для двух похожих сценариев:

```python
def test_1(log_catcher: None, logging_config: None) -> None:
    for i in range(10):
        r = remote_logging_app.work(i)


def test_2(log_catcher: None, logging_config: None) -> None:
    for i in range(1, 10):
        r = remote_logging_app.work(52 * i)
```

Для этих двух сценариев требуются две фикстуры. Фикстура **`log_catcher`** с областью видимости сеанса (session) вводится в действие однократно и используется для обоих тестов. А у фикстуры **`logging_config`** область видимости по умолчанию, то есть она готова к действию для каждой тестовой функции.

Определение фикстуры как **`Iterator[None]`** намекает на использование типа **`None`**. То есть на то, что у инструкции **`yield`** нет возвращаемого значения. Для таких тестов операция настройки, запуская процесс, подготавливает общую среду выполнения.

Когда тестовая функция завершается, после выполнения инструкции **`yield`** работа фикстуры **`logging_config`** возобновляется. (Данная фикстура является итератором, и для попытки получения от нее второго значения используется функция **`next()`**.) Это приводит к закрытию и удалению обработчика с полным разрывом сетевого соединения, поддерживающего процесс захвата журналов.

При окончательном завершении тестирования фикстура **`log_catcher`** может завершить дочерний процесс. Чтобы облегчить отладку, на экран выводится любая информация, а чтобы понять, что тест сработал, проверяется код возврата операционной системы. Поскольку процесс был завершен (посредством **`р.terminate()`**), код возврата должен иметь значение **`signal.SIGТERM`**. Другие значения кода возврата, особенно код возврата, равный единице, будут означать, что сборщик журналов дал сбой и тест провалился.




### Пропуск тестов с помощью `pytest`
---

Иногда по тем или иным причинам возникает потребность в пропуске тестов в **`pytest`**: тестируемый код еще не написан, тест выполняется только на определенных интерпретаторах или в операционных системах или тест занимает много времени и должен запускаться только при вполне определенных обстоятельствах. В предыдущем разделе, напомним, был приведен пример теста, который не мог работать в Python 3.8, и его нужно было пропустить.

Разумеется, пропускать тесты во всех этих местах зачастую желательно только в случае выполнения или невыполнения определенного условия. Поскольку функция **`skip()`** способна выполняться в любом месте кода Python, ее можно выполнить внутри инструкции **`if`**. Например, написать следующий тест:

```python
import sys
import pytest


def test_simple_skip() -> None:
    if sys.platform != "ios":
        pytest.skip("Test works only on Pythonista for ios")

    import location  # type: ignore [import]

    img = location.render_map_snapshot(36.8508, -76.2859)
    assert img is not None
```

Этот тест будет пропущен в большинстве операционных систем. Для iOS он должен работать на Python-пopтe Pythonista. В нем показано, как добиться пропуска теста в тех или иных условиях, и, поскольку оператором **`if`** может быть проверено любое допустимое условие, для организации пропуска тестов открывается широкий круг возможностей. Для проверки версии интерпретатора Python зачастую используется значение **`sys.version_info`**, для проверки версии операционной системы - **`sys.platform`**, а для проверки свежести версии используемого модуля - **`some_library.__version__`**.

Поскольку наиболее часто пропуск тестов в зависимости от условия применяется в отношении отдельно взятого метода или функции, **`pytest`** предоставляет удобный декоратор, позволяющий сделать это в одну строку. Декоратор принимает одну строку, которая содержит любой исполняемый код Python, возвращающий логическое значение. Например, следующий тест будет работать только на Python версии 3.9 или выше:

```python
import pytest
import sys


@pytest.mark.skipif(
    sys.version_info < (3, 9), reason="requires 3.9, Path.removeprefix()"
)
def test_feature_python39() -> None:
    file_name = "(old) myfile.dat"
    assert file_name.removeprefix("(old) ") == "myfile.dat"
```

Декоратор **`pytest.mark.skipif`** помечает тот тест, который может быть не пройден. Если тест успешно пройден, он будет записан как непройденный (но это неправда!). Если он не будет пройден, поступит сообщение об ожидаемом поведении. В случае **`skipif`** условный аргумент указывать не обязательно. Если он не указан, тест будет помечен как непройденный при любых условиях.

В среде **`pytest`**, помимо упомянутых здесь, имеется множество других функций, и разработчики постоянно добавляют новые инновационные способы упрощения тестирования. Подробную документацию по этой теме можно найти на веб-сайте разработчиков по адресу https://docs.pytest.org/.

>[!info]
>В дополнение к собственной тестовой инфраструктуре инструментальное средство pytest может находить и запускать тесты, определенные с помощью стандартной библиотеки **`uпittest`**. То есть при переходе с **`unittest`** на **`pytest`** переписывать все старые тесты не нужно.

Мы рассмотрели использование фикстур для настройки и демонтажа сложной среды тестирования. Это пригодится для целого ряда интеграционных тестов, но наиболее удачным подходом может стать имитация объекта, на создание которого уйдет слишком много усилий, или имитация рискованной операции. Кроме того, для модульных тестов не нужна никакая операция демонтажа. Модульный тест изолирует каждый программный компонент в виде отдельно взятого модуля, подлежащего тестированию. То есть, чтобы изолировать тестируемый модуль, все объекты интерфейса будут часто заменяться имитациями, называемыми моками (**mocks**). И далее нам предстоит разобраться с тем, что же такое мокобъекты, предназначенные для изоляции модулей и имитации использования слишком затратных ресурсов.





## Имитация объектов с помощью моков
---

==Выявлять и устранять ошибки проще при решении отдельно взятых задач. К примеру, с ходу выяснить, почему автомобиль, работающий на бензине, не заводится, может быть сложно, поскольку в нем имеется множество взаимосвязанных частей. Если тест не проходит, раскрытие многочисленных взаимосвязей затрудняет диагностику проблемы. Зачастую требуется изолировать элементы, предоставляя упрощенные имитации. По сути, есть две причины заменить работоспособный код имитирующими его объектами (или моками).==

- Самой распространенной причиной является необходимость изоляции тестируемого модуля. Нужно создать взаимодействующие классы и функции, позволяющие протестировать один неизвестный компонент в среде известных,  надежных тестовых фикстур.
- Иногда нужно протестировать код, для которого требуется объект, причем использование этого объекта либо обойдется слишком дорого, либо повлечет за собой неоправданные риски. К примеру, настройка и демонтаж с целью тестирования общих баз данных, файловых систем и облачных инфраструктур может обойтись слишком дорого.

Случается, что все перечисленное приводит к необходимости разработки API с тестируемым интерфейсом. Проектирование для удобства тестирования зачастую означает также разработку более удобного интерфейса. В частности, при этом требуется раскрыть предположения о взаимодействующих классах, позволяющие внедрить мок-объект вместо экземпляра реального класса приложения.

Представьте, к примеру, что имеется некий код, отслеживающий состояния авиарейсов во внешнем хранилище типа <<КЛЮЧ-значение» (например, в **`redis`** или в **`memcache`**), чтобы можно было сохранять их метки времени и самый последний статус. Для реализации потребуется rеdis-клиент, не требующий написания модульных тестов. Клиент может быть установлен с помощью команды **`python -m pip install redis`**:

```shell
python -m pip install redis    
Collecting redis
  Downloading redis-5.0.7-py3-none-any.whl.metadata (9.3 kB)
Downloading redis-5.0.7-py3-none-any.whl (252 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 252.1/252.1 kB 552.1 kB/s eta 0:00:00
Installing collected packages: redis
Successfully installed redis-5.0.7
```

Если потребуется запустить этот код с реальным redis-cepвepoм, нужно будет загрузить и установить **`redis`**. Делается это следующим образом.

1. Загрузить рабочий стол Docker, чтобы упростить управление этим приложением. См. https://www.docker.com/products/docker-desktop.
2. Запустить из окна терминала команду `docker pull redis`, чтобы загрузить образ redis-cepвepa. Этим способом можно воспользоваться для создания и запуска Dосkеr-контейнера.
3. Затем можно запустить сервер, воспользовавшись командой `docker run - р 6379 : 6379 redis`. Это приведет к запуску контейнера с изображением `redis`, после чего им можно будет воспользоваться для интеграционного тестирования.

Можно обойтись и без dосkеr-контейнера, выполнив шаги, зависящие от используемой платформы. В следующих примерах предполагается использование dосkеr-контейнера; внесение незначительных изменений, необходимых для перехода на платформозависимую установку **`Redis`**, оставлено читателю в качестве упражнения.

Программный код ниже позволяет сохранять статус на кэш-сервере **`redis`**:

```python
import datetime
import redis
from enum import Enum


class Status(str, Enum):
    CANCELLED = "CANCELLED"
    DELAYED = "DELAYED"
    ON_TIME = "ON TIME"


class FlightStatusTracker:
    def __init__(self) -> None:
        self.redis = redis.Redis(host="127.0.0.1", port=6379, db=0)  

    def change_status(self, flight: str, status: Status) -> None:
        if not isinstance(status, Status):
            raise ValueError(f"{status!r} is not a valid Status")
        key = f"flightno:{flight}"
        now = datetime.datetime.now(tz=datetime.timezone.utc)
        value = f"{now.isoformat}|{status.value}"
        self.redis.set(key, value)  

    def get_status(self, flight: str) -> tuple[datetime.datetime, Status]:
        key = f"flightno:{flight}"
        value = self.redis.get(key).decode("utf-8")
        text_timestamp, text_status = value.split("|")
        timestamp = datetime.datetime.fromisoformat(text_timestamp)
        status = Status(text_status)
        return timestamp, status
```

В классе **`Status`** дается определение перечислению четырех строковых значений. Чтобы получить конечную ограниченную область действительных значений, предоставлены символические имена вида **`Status.CANCELLED`**. Фактические значения, хранящиеся в базе данных, будут строками типа **`"CANCELLED"`** . Они на данный момент совпадают с символами, используемыми в приложении. В перспективе область значений может расшириться или измениться, но хотелось бы, чтобы символические имена в приложении были отделены от строк, появляющихся в базе данных. Обычно в **`Enum`** используются числовые коды, но их трудно запомнить.

В методе **`change_status()`** много чего нужно протестировать. Проверяется принадлежность значения аргумента **`status`** к одному из экземпляров перечисления **`Status`**, но можно было бы и расширить наши действия. Нужно убедиться, что отсутствие смысла в аргументе **`flight`** вызывает выдачу соответствующей ошибки. Еще важнее наличие теста на правильный формат ключа и значения при вызове метода **`set()`** для объекта **`redis`**.

Вместо проверки интеграции с redis-cepвepoм нужно ограничиться проверкой вызова метода **`set()`** соответствующее количество раз и с соответствующими аргументами. Чтобы заменить проблемный метод объектом, поддающимся интроспективе, в текстах можно воспользоваться объектами **`Мосk()`**. Использование **`Mock`** показано в следующем примере:

```python
import datetime
import flight_status_redis
from unittest.mock import Mock, patch, call
import pytest


@pytest.fixture
def mock_redis() -> Mock:
    mock_redis_instance = Mock(set=Mock(return_value=True))
    return mock_redis_instance


@pytest.fixture
def tracker(
    monkeypatch: pytest.MonkeyPatch, mock_redis: Mock
) -> flight_status_redis.FlightStatusTracker:
    """Depending on the test scenario, this may require a running          REDIS server."""
    fst = flight_status_redis.FlightStatusTracker()
    monkeypatch.setattr(fst, "redis", mock_redis)
    return fst


def test_monkeypatch_class(
    tracker: flight_status_redis.FlightStatusTracker, mock_redis: Mock
) -> None:
    # with patch.object(tracker, "redis", mock_redis):
    with pytest.raises(ValueError) as ex:
        tracker.change_status("AC101", "lost")  # type: ignore [arg-type]
    assert ex.value.args[0] == "'lost' is not a valid Status"
    assert mock_redis.set.call_count == 0
```

В приведенном тесте применяется диспетчер контекста **`raises()`** , позволяющий убедиться, что при передаче неподходящего аргумента выдается нужное исключение. Кроме того, в нем для экземпляра **`redis`** создается объект **`Mock`**, который будет использоваться **`FlightStatusTracker`**.

В мок-объекте содержится атрибут **`set`**, являющийся мок-методом, неизменно возвращающим значение **`True`**. Но тест проверяет, что вызов метода **`redis.set()`** никогда не состоится. Если подтвердится именно этот факт, он будет означать, что в код обработки исключений вкралась ошибка.

Обратите внимание на способ перехода к мок-объекту. Для проверки фиктивного метода **`set()`** объекта **`Mock`**, созданного фикстурой **`mock_redis`**, используется вызов **`mock_redis.set`**. А **`call_count`** является атрибутом, поддерживаемым всеми объектами **`Mock`**.

Конечно, для замены в ходе тестирования реального объекта мок-объектом можно воспользоваться кодом вида **`flt.redis = mock_redis`**. Но это чревато проблемами. Простая замена значения или даже замена метода класса срабатывает только для уничтожаемых объектов, создаваемых для каждой тестовой функции. Если нужно подменять элементы на уровне модуля, то повторного импортирования модуля не будет. Гораздо более универсальным решением является применение для временного внедрения мок-объекта так называемого патчера. В данном примере для внесения временного изменения в объект **`FlightStatusTracker`** послужила руtеst-фикстура **`monkeypatch`**, имеющая свой собственный автоматический механизм демонтажа по окончании теста, что позволяет обращаться к пропатченным этой фикстурой модулям и классам, не внося разлад в другие тесты.

Описанный тестовый пример будет с меткой **`mуру`**. Инструментальное средство **`mуру`** противится использованию строкового значения аргумента в качестве параметра состояния функции **`change_status()`** , ведь значение, несомненно, должно быть экземпляром перечисления Status. Чтобы отключить проверку типа аргумента, проводимую туру, можно добавить специальный комментарий **`# type : ignore[arg-type]`**.



#### Дополнительные методы патчинга
---

Порой внедрение специальной функции или метода требуется только на время проведения одного-единственного теста. И при этом совершенно не нужно создавать сложный мок-объект, применяемый в нескольких тестах. Скорее, понадобится всего лишь небольшой мок-объект для одного теста. Тогда, может, и не потребуется использование всех возможностей фикстуры **`monkeypatch`**. Например, если нужно проверить форматирование метки времени в Мосk-методе, необходимо точно знать, что именно вернет **`datetime.datetime.now()`**. Но возвращаемое значение меняется от запуска к запуску. Следует создать какой-то способ его привязки к определенному значению даты и времени, чтобы можно было провести тестирование предопределенным образом.

```python
def test_patch_class(
        tracker: src.flight_status_redis.FlightStatusTracker,                mock_redis: Mock
) -> None:
    fake_now = datetime.datetime(2020, 10, 26, 23, 24, 25)
    utc = datetime.timezone.utc
    with patch("src.flight_status_redis.datetime") as mock_datetime:
        mock_datetime.datetime =                                                                 Mock(now=Mock(return_value=fake_now))
        mock_datetime.timezone = Mock(utc=utc)
        tracker.change_status(
            "AC101", src.flight_status_redis.Status.ON_TIME
        )    mock_datetime.datetime.datetime.now.assert_called_once_with(tz=utc)
    expected = f"2020-10-26T23:24:25|ON TIME"
    mock_redis.set.assert_called_once_with("flightno:AC101",                                                    expected)
```

Временная настройка библиотечной функции на конкретное значение - то самое место, где необходим патчинг. В дополнение к фикстуре **`monkeypatch`** библиотека **`unittest.mock`** предоставляет диспетчер контекста патчинга **`patch`**, позволяющий подменять атрибуты существующих библиотек мок-объектами. Когда менеджер контекста завершает работу, исходный атрибут автоматически восстанавливается, чтобы не оказывать влияния на другие тестовые сценарии.

Диспетчер контекста **`patch()`** возвращает мок-объект, используемый для замены произвольного объекта. В данном случае заменяемым объектом был весь модуль **`datetime`** из модуля **`flight_status_redis`**. При определении **`mock_datetime.datetime`** класс **`datetime`** внутри сымитированного **`datetime`** модуля был подменен нашим собственным мок-объектом, который теперь определяет один атрибут - **`now`**. Поскольку атрибут **`utcnow`** представляет собой Мосk-объект, возвращающий значение, он ведет себя как метод и возвращает фиксированное, заведомо известное значение **`fake_now`**. Когда интерпретатор выходит из диспетчера контекста патчинга, восстанавливается исходная функциональность **`datetime`**.

После вызова метода **`change_status()`** с заведомо известными значениями для того, чтобы убедиться, что функция **`now()`** действительно вызывалась только один раз с ожидаемыми аргументами (в данном случае вообще без аргументов), используется метод **`assert_called_once_with()`** объекта **`Mock`**. В мок-методе **`redis.set`** также используется метод **`assert_called_once_with()`**, позволяющий убедиться в том, что он вызывается с аргументами, отформатированными ожидаемым образом. В дополнение к **`called_once_with`** (*вызван единожды с*) можно также проверить полный список сделанных мок-вызовов. Этот список доступен в атрибуте **`mock_calls`** объекта **`Mock`**.

>[!tip]
>Имитация дат, позволяющая получать предопределенные результаты тестирования, является широко распространенным сценарием патчинга. Этот прием применим к любому объекту, имеющему состояние, но особенно важен для внешних ресурсов (таких как часы), существующих вне нашего приложения.
Для особого случая использования `datetime` и `time` такие пакеты, как `freezeguп`, могут упростить нужный «[[Обезьяний патчинг (monkeypatching)|обезьяний патчинг]]», открывая доступ к заведомо известной фиксированной дате.

Патчи, созданные в данном примере, преднамеренно наделены широкой областью действия. Мок-объектом был подменен весь модуль **`datetime`**. В таком случае при применении какого-либо метода, не подвергнутого специальному патчингу, может произойти незапланированное использование функций **`datetime`** (например, при имитации метода **`now()`**), и возвращение Мосk-объектов способно привести к сбою тестируемого кода.

Предыдущий пример также показывает, как создание программного кода, пригодного к тестированию, принуждает к определению конструкции API. У фикстуры **`tracker`** имеется одна интересная особенность: ею создается объект **`FlightStatusTracker`**, устанавливающий подключение к **Redis**. После подключения к **`Redis`** произойдет его подмена. Но при запуске тестирования данного кода выяснится, что подключение к **Redis** создается каждым тестом. И если Redis-cepвep не запущен, некоторые тесты могут остаться не пройденными. Чрезмерные требования к внешним ресурсам свидетельствуют о непригодности модульного теста. Тест может быть не пройден по одной из двух Причин: либо не работает программный код, либо в силу некой скрытой внешней зависимости не работают сами модульные тесты. Выявление истинной причины рискует превратиться в сущий кошмар.

Проблема может быть решена путем имитации класса **`redis.Redis`**. Мок-объектом для этого класса возвращается имитируемый экземпляр метода **`setUp`**. Но рациональнее все-таки основательнее переосмыслить саму реализацию. Вместо создания rеdis-экземпляра внутри **`__init__`** нужно возложить на пользователя его добавление, как показано в следующем примере:

```python
def __init__(
	self,
	redis_instance: Optional[redis.Connection] = None
) -> None:
	self.redis = (
		redis_instance
		if redis_instance
		else redis.Redis(host="127.0.0.1", port=6379, db=0)
	)
```

Это позволит полностью отказаться от создания метода **Redis**, передавая подключение в ходе тестирования. Кроме того, любому клиентскому коду будет позволено обращаться к **`FlightStatusTracker`** с целью передачи своего собственного rеdis -экземпляра. На это может существовать масса причин: возможно, такой экземпляр уже был создан для других частей кода, или же создана оптимизированная реализация API **`redis`**; также вполне вероятно, что такой экземпляр уже имеется для регистрации параметров во внутренних клиентских системах отслеживания. При создании модульных тестов раскрывается сценарий использования, который с самого начала придает API дополнительную гибкость, а она может быть очень нужна в силу того, что клиенты предъявят вполне ожидаемые требования поддержки их специфических нужд.

Это было кратким введением в удивительный мир подменяемого кода. Мокобъекты стали частью стандартной библиотеки **`unittest`** начиная с версии Python 3.3. Из показанных выше примеров следует, что их также можно использовать с **`pytest`** и другими средами тестирования. Мок-объекты обладают и другими, более интересными функциями, которыми, возможно, придется воспользоваться по мере усложнения программного кода. Например, чтобы предложить мок-объекту имитировать существующий класс с целью выдачи ошибки при попытке программного кода получить доступ к несуществующему в имитируемом классе атрибуту, можно воспользоваться аргументом **`spec`**. Или для возвращения создаваемым мок-объектом при каждом его вызове разных значений передать ему в качестве аргумента **`side_effect`** соответствующий список. Параметр **`side_effect`** весьма универсален: им также пользуются для выполнения при вызове мок-объекта произвольных функций или же для выдачи исключения.

==Смысл модульного тестирования в том, чтобы удостовериться в работоспособности каждого модуля в изолированном режиме.== Зачастую в качестве модуля выступает отдельный класс, и нужно имитировать все, с чем он взаимодействует. Порой имеется некое сочетание классов или же так называемый фасад, с помощью которого могут быть протестированы как единый модуль сразу несколько классов приложения вместе. И тем не менее существует четкая граница между уместностью и неуместностью применения мок-объектов. Если для понимания того, как можно имитировать зависимости какого-либо внешнего модуля или класса (который был создан не нами), нужно в него внедриться, то это уже будет перебор.

>[!info]
>Не нужно изучать особенности реализации классов, не относящихся к создаваемому приложению, чтобы выяснить способы имитации взаимодействующих с ними объектов. Вместо этого лучше имитировать весь класс, от которого зависит данное приложение.
>
>Обычно в результате предоставляется имитация всей базы данных или внешнего API.

В реализации идеи имитации объектов можно пойти еще дальше. Есть одна специализированная фикстура, которой можно воспользоваться при желании убедиться в нетронутости данных. Давайте посмотрим, что она собой представляет.



#### Объект `sentinel`

Во многих проектах встречается класс со значениями атрибутов, которые могут быть предоставлены в качестве параметров другим объектам, причем в этом классе отсутствует реальная обработка этих объектов. Например, классу может быть предоставлен объект **`Path`**, а затем этот класс предоставляет принятый объект функции операционной системы. Получается, что созданный класс не занимается ничем, кроме промежуточного сохранения объекта. С точки зрения модульного тестирования для тестируемого класса объект непрозрачен - создаваемый класс не обращается внутрь объекта, к состоянию или к методам.

Для создания непрозрачных объектов в модуле **`unittest.mock`** имеется удобный объект **`sentinel`**, ==которым можно воспользоваться в тестовых сценариях, чтобы убедиться, что приложение сохранило и переслало объект нетронутым.==

Рассмотрим класс **`FileChecksum`**, сохраняющий объект, вычисленный функцией **`sha256()`** модуля **`hashlib`**:

```python
class FileChecksum:
	def __init__(self, source: Path) -> None:
		self.source = source
		self.checksum = hashlib.sha256(source.read_bytes())
```

Этот код можно изолировать от других модулей, чтобы провести модульное тестирование. Для модуля **`hashlib`** будет создан мок-объект, а для результата **`sentinel`**:

```python
from unittest.mock import Mock, sentinel


@pytest.fixture
def mock_hashlib(monkeypatch) -> Mock:
	mocked_hashlib = Mock(sha256=Mock(return_value=sentinel.checksum))
	monkeypatch.setattr(checksum_writer, "hashlib", mocked_hashlib)
	return mocked_hashlib


def test_file_checksum(mock_hashlib, tmp_path) -> None:
	source_file = tmp / "some_file"
	source_file.write_text("")
	cw = checksum_writer.FileChecksum(source_file)
	assert cw.source == source_file
	assert cw.checksum == sentinel.checksum
```

Нашим объектом **`mocked_hashlib`** предоставляется метод **`sha256`**, возвращающий уникальный объект **`sentinel.checksum`**. У этого объекта, созданного объектом **`sentinel`**, крайне небольшое число методов или атрибутов. В качестве уникального объекта может быть взято любое имя атрибута; в данном случае выбрано имя **`"checksum"`**. Полученный объект предназначен исключительно для проверки на равенство. Объект **`sentinel`** в тестовом сценарии позволяет убедиться, что класс **`FileChecksum`** не делает с предоставленными ему объектами ничего неожиданного для разработчика.

Тестовым сценарием создается объект **`FileChecksum`**. Тест призван подтвердить, что файл был предоставлен в значении аргумента **`source_file`**. Тест также подтверждает, что контрольная сумма соответствует значению исходного объекта **`sentinel`**. Это позволяет убедиться в том, что экземпляр **`FileChecksum`** правильно сохранил результат вычисления контрольной суммы и предоставил его как значение атрибута контрольной суммы **`checksum`**.

Если изменить реализацию класса **`FileChecksum`**, чтобы, к примеру, воспользоваться свойствами вместо прямого доступа к атрибуту, тест подтвердит, что контрольная сумма рассматривалась в качестве непрозрачного объекта, полученного из функции **`hashlib.sha256()`**, и не подвергалась какой-либо иной обработке.

Итак, к настоящему моменту мы рассмотрели две среды модульного тестирования: встроенный пакет **`unittest`** и внешний пакет **`pytest`**. Обе они делают возможным создание понятных и простых тестов, способных подтвердить работоспособность приложения. При этом весьма важно тестировщику иметь четкую цель, определяющую необходимый объем тестирования. В Python есть простой в использовании пакет охвата, предоставляющий одvн объективный показатель качества и полноты тестирования.




### Как определить, достаточен ли объем тестирования
---

Уже понятно, что не протестированный код следует считать неработоспособным. ==Но как узнать, насколько качественно код протестирован? Как узнать, какая часть кода попала под тестирование, а какая - нет?== Первый вопрос важнее, но ответить на него труднее. Даже если известно, что протестирована каждая строка кода приложения, неизвестно, правильно ли это все протестировано. Например, если создать статистический тест, проверяющий только то, что происходит при предоставлении списка целых чисел, он все равно не будет пройден, если для списка используются числа с плавающей точкой, строковые значения или какие-либо созданные вами объекты. Обязанность создания полноценных наборов тестов по-прежнему возлагается на программиста.

Ответ на второй вопрос - какая часть кода была охвачена тестированием легко получить путем проверки. **Охват кода** сводится к подсчету количества строк кода, выполняемых программой. Из полного количества строк становится понятно, какой процент кода действительно был протестирован или охвачен. Если дополнительно имеется индикатор, сообщающий, какие строки не были протестированы, будет проще написать новые тесты, чтобы с более высокой вероятностью гарантировать бес проблемность этих пока непроверенных строк.

Наиболее востребованный инструмент контроля охвата кода тестированием называется вполне ожидаемо - [[coverage|coverage.ру]]. Его, как и большинство других сторонних библиотек, можно установить с помощью команды **`python -m pip install coverage`**.

Объем данной книги не позволяет рассмотреть все особенности API инструмента выявления степени охвата. Здесь ограничимся рассмотрением ряда типовых примеров. При наличии Руthоn-сценария, запускающего все созданные модульные тесты (возможно, с использованием **`unittest.main`**, **`unittest discover`** или **`pytest`**), анализ охвата конкретного файла модульного теста можно получить запуском следующей команды:

```zsh
% export PYTHONPATH=$(pwd)/src:$PYTHONPATH
% coverage run -m pytest tests/test_coverage.py
```

Результатом выполнения команды станет создание файла по имени **`.coverage`**, содержащего данные о прогоне.

Пользователи Windows-oбoлoчки Poweгshell могут сделать следующее:

```powershell
> $ENV:PYTHONPATH = "$pwd\src" + ";" + $PYTHONPATH
> coverage run -m pytest tests/test_coverage.py
```

Теперь для анализа степени охвата кода можно воспользоваться командой `coverage report`:

```bash
% coverage report
```

Полученный вывод выглядит, например, так:

```shell
Name                     Stmts    Miss    Cover
--------------------------------------------------
src/stats.py                 19      11      42%
tests/test_coverage.py        7       0     100%
--------------------------------------------------
TOTAL                        26      11      58%
```

В данном отчете перечислены выполненные файлы (наш модульный тест и импортированный им модуль), количество строк кода в каждом проверяемом файле и количество строк кода, выполненных тестом. Затем эти два числа сопоставляются, чтобы оценить объем охваченного кода. Неудивительно, что здесь был выполнен весь тестирующий код, но при этом только часть кода модуля **`stats`**.

Если команде **`report`** передать ключ **`-m`**, будет добавлен столбец, показывающий номера тех строк, которые были пропущены при выполнении теста. Вывод будет таким:

```shell
Name                     Stmts    Miss    Cover        Missing
----------------------------------------------------------------
src/stats.py                 19      11      42%   18-23, 26-31
tests/test_coverage.py        7       0     100%
----------------------------------------------------------------
TOTAL                        26      11      58%
```

Перечисленные здесь диапазоны строк показывают строки кода в модуле **`stats`**, не выполненные в ходе тестирования.

В коде примера применен тот же созданный ранее в данной главе модуль **`stats`**. Но в нем намеренно используется такой тест, который пропускает в процессе тестирования фрагменты кода весьма солидного объема.

Этот тест выглядит следующим образом:

```python
import pytest
from stats import StatsList


@pytest.fixture
def valid_stats() -> StatsList:
	return StatsList([1, 2, 2, 3, 3, 4])


def test_mean(valid_stats: StatsList) -> None:
	assert valid_stats.mean() == 2.5
```

В тесте не проходят проверку функции **`median`** и **`mode`**, которым соответствуют номера строк, показанные в выводе команды **`coverage`** пропущенными.

Текстовый отчет дает вполне достаточный объем информации, но если воспользоваться командой **`coverage html`**, можно будет получить еще более полезный и информативный НТМL-отчет, который доступен для просмотра в браузере. В интерактивном отчете имеется целый ряд полезных фильтров, которые можно будет задействовать. На веб-странице выделяются протестированные и не протестированные строки кода.


НТМL-отчет создан с помощью pytest с использованием модуля **`coverage`**. Для этого командой **`python - m pip install pytest-cov`** был предварительно установлен плагин, принадлежащий pytest и предназначенный для оценки степени охвата кода. Этот плагин добавляет в **`pytest`** несколько ключей командной строки, наиболее полезным из которых является **`--cover-report`**. Для него могут устанавливаться значения **`html`**, **`report`** или **`annotate`** (последний фактически изменяет исходный код, чтобы выделить любые неохваченные строки).

В дерево аналитики охвата полезно включить не только дерево каталога `src`. У крупного проекта подчас бывает весьма непростой каталог тестирования, включающий дополнительные инструменты и поддерживающие библиотеки. В ходе разработки проекта может появиться какой-то уже устаревший, но еще не удаленный тестовый или вспомогательный код.

К сожалению, будь у нас возможность получить отчет о степени охвата применительно к данному разделу главы, стало бы понятно, что из рассмотрения выпала весьма солидная часть всего того, что нужно было бы знать об охвате кода! Для управления кодом анализа охвата из наших собственных программ (или из наборов тестов) можно использовать API охвата. Кроме того, **`coverage.ру`** принимает множество не описанных здесь параметров конфигурации. Также мы не рассматривали разницу между охватом инструкций и охватом ветвлений (последнее гораздо полезнее и используется по умолчанию в самых свежих версиях **`coverage.ру`**) или же другие стили анализа охвата кода.

Следует понимать, что только достижения 100%-ного охвата еще недостаточно! То, что инструкция протестирована, еще не значит, что она как следует протестирована для всех возможных входных данных. Метод анализа крайних значений включает в себя рассмотрение пяти значений для охвата крайних случаев: значения ниже минимума, значения минимума, значения где-то посередине, максимального значения и значения выше максимального. Четкого диапазона для нечисловых типов может и не быть, но подобные рекомендации могут быть адаптированы к другим структурам данных. Например, для списков и сопоставлений эта рекомендация зачастую предполагает тестирование с пустыми списками или сопоставление с неожиданными ключами. Разобраться с более сложными тестовыми сценариями поможет пакет **`Hypothesis`** (https://pypi.org/project/hypothesis/).

Важность тестирования трудно переоценить. Подход к разработке, основанный на тестировании, побуждает составлять представление о программном средстве с помощью вполне очевидных, поддающихся тестированию целей. Сложные задачи должны быть разложены на отдельно взятые, поддающиеся тестированию решения. Нередко в тестовом коде оказывается больше строк, чем в реальном коде приложения. Краткий, но запутанный алгоритм иногда лучше всего объяснить на примерах, и каждый пример должен быть тестовым сценарием.




### Тестирование и разработка
---

Модульные тесты помогают разработчикам во множестве аспектов. Ключевым из них является отладка проблемных мест приложения. Когда складывается представление о работоспособности каждого модуля в изолированном режиме, любые оставшиеся проблемы, как правило, оказываются связаны с неподходящим использованием межкомпонентного интерфейса. При поиске основной причины возникшей проблемы подборка успешно пройденных тестов служит совокупностью указателей, направляющих разработчика в дебри не протестированной функциональности в пограничных областях между компонентами.

Возникновение проблемы зачастую связано с одной из следующих причин.

- Один из создателей нового класса не смог разобраться в интерфейсе стыковки своего класса с уже существующим классом и использовал этот интерфейс неподобающим образом. Это указывает на необходимость составления и запуска нового модульного теста, отражающего подходящий способ использования интерфейса. Новый тест должен привести к сбою нового программного кода в расширенном наборе тестов. Полезно также провести интеграционный тест, но он не сыграет такую же важную роль, как новый мо;1ульный тест, сориентированный на тонкости исrюльзования интерфейса.
- Интерфейс не получил достаточно подробного описания, и обеим использующим его сторонам необходимо прийти к соглашению о его должном применении. В таком случае обеим этим сторонам потребуется проведение дополнительных модульных тестов, показывающих должное состояние и интерфейса. Оба класса должны провалить новые модульные тесты и быть после этого доработаны. Кроме того, для подтверждения нужной согласованности в работе этих двух классов может быть применен интеграционный тест.

Замысел предусматривает использование тестовых сценариев для управления процессом разработки. Недоработка или инцидент должны быть оформлены в виде провального тестового сценария. После того как задача будет конкретно выражена в форме тестового сценария, будет получена возможность создавать или переделывать программный модуль до тех пор, пока не будут пройдены все тесты.

Если ошибки все же возникают, то чаще всего приводится в исполнение следующий план, основанный на тестировании.

1. Написать тест (или несколько тестов), позволяющий смоделировать предполагаемый недочет или же доказать его наличие. Такой тест, конечно же, не будет пройден. Чем сложнее приложение, тем труднее для него определить конкретные шаги по воссозданию недочета в изолированном фрагменте кода; такая работа ценится очень высоко, поскольку для нее требуется доскональное знание создаваемого программного средства и способность выразить это знание в виде тестового сценария.
2. Затем написать код, способный пройти тесты. Если тесты были исчерпывающими, недочет будет устранен и станет понятно, что не нанесено никакого нового вреда в стремлении что-либо исправить.

Ценность разработки на основе тестирования выражается еще и в положительном влиянии тестовых сценариев на дальнейшее совершенствование программного продукта. Созданные тесты позволяют улучшать программный код до бесконечности и при этом пребывать в полной уверенности, что вносимые изменения не нанесут вреда ничему, что подвергалось тестированию. Кроме того, абсолютно понятно, что все переделки будут завершены, только когда будут пройдены все тесты.

Разумеется, тестам и не может быть проверено абсолютно все, что нужно; сопровождение программного кода или же его реструктуризация все же могут привести к недочетам, которые трудно выявить при тестировании. Автоматизированные тесты не являются абсолютной защитой от ошибок. Как сказал [[Эдсгер Дейкстра|Э.В. Дейкстра]], «тестирование программы может использоваться для демонстрации наличия ошибок, но только не для демонстрации их отсутствия!». У нас должны быть веские доказательства состоятельности алгоритма, а также тестовые сценарии, покрывающие отсутствие каких-либо проблем.





## Ключевые моменты
---

- Важность модульного тестирования и разработки на основе тестирования как способа убедиться в том, что приложение работает в соответствии с ожиданиями разработчиков.
- Первоочередное использование при тестировании модуля **`unittest`**, обусловленное его принадлежностью к стандартной библиотеке и легкой доступностью. Модуль представляется немного многословным, но в остальном неплохо подходит для подтверждения работоспособности создаваемого программного средства.
- Инструментальное средство **`pytest`**, требующее отдельной установки, но позволяющее создавать менее сложные тесты, чем те, что были получены с использованием модуля **`unittest`**. Но более важной здесь представляется концепция фикстур, способствующая созданию тестов для самых разнообразных сценариев.
- Мок-модуль, являющийся частью пакета unittest и служащий для создания мок-объектов, основное предназначение которых - более качественная изоляция тестируемого модуля программного кода. Изолируя каждый фрагмент кода, можно сосредоточиться на подтверждении его работоспособности и наличии надлежащего интерфейса. Это упростит задачу составления комбинации компонентов.
- Степень охвата кода, являющаяся весьма полезным показателем адекватности проводимого тестирования. Простое стремление к достижению числовых показателей не может послужить заменой размышлениям, но позволяет подтвердить, что разработка сценариев велась максимально тщательно и со всем вниманием.

Были рассмотрены несколько разновидностей тестов с применением разнообразных инструментальных средств.

- Модульные тесты с использованием пакета **`unittest`** или пакета **`pytest`**, зачастую с применением мок-объектов с целью изоляции фикстуры или тестируемого модуля.
- Интеграционные тесты, также с использованием **`unittest`** и **`pytest`**. Эти тесты предназначены для тестирования более полных интегрированных коллекций компонентов.
- Чтобы убедиться, что типы данных используются должным образом, в статическом анализе может применяться **`mуру`**. Такой тест позволяет убедиться в приемлемости программного средства. Существуют и другие виды статических тестов, и для дополнительного анализа можно обратиться к таким инструментам, как **`flake8`**, **`pylint`** и **`pyflakes`**.

Для проведения тех или иных исследований понадобится множество дополнительных типов тестирования. У каждого отдельно взятого типа тестирования есть конкретная цель или подход, позволяющий убедиться в работоспособности программного средства. К примеру, при проведении теста производительности выясняется, достаточно ли быстро работает программный продукт и насколько приемлем объем потребляемых им ресурсов.

Важность тестирования трудно переоценить. Без автоматизированных тестов программный продукт нельзя считать полноценным или даже пригодным к использованию. Начиная путь его создания с разработки тестовых сценариев, мы определяем его ожидаемое поведение в понятиях конкретности, измеримости, достижимости, ориентированности на результаты и отслеживаемости, из чего и складывается аббревиатура SMART(specific, measurable, achievable, гesultsbased и trackable).





## Резюме
---

Наконец-то была затронута и успешно изучена самая важная тема, касающаяся программирования на Python: автоматизированное тестирование. Разработка на основе тестирования считается наиболее рациональной практикой программирования. Модуль стандартной библиотеки **`unittest`** предоставляет отличное готовое решение для проведения тестирования, а среда **`pytest`** содержит еще целый ряд синтаксических построений на языке Python. Чтобы сымитировать в тестах сложные классы, можно воспользоваться мок-объектами. Степень охвата кода тестированием позволяет оценить, какая часть кода обрабатывалась тестами, но она не даст гарантий, что протестировано именно то, что действительно нужно.

В [[Конкурентная Обработка Данных]] перейдем к совершенно другой теме: конкурентным вычислениям.